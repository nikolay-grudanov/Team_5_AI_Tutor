folder_name,filename,page_number,text_length,tokens,processing_time,error
o-predelnom-mnogomernom-raspredelenii,page_002.png,2,0,0,0.05935168266296387,"Error code: 400 - {'error': 'Trying to keep the first 18393 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a larger context length, or provide a shorter input'}"
o-predelnom-mnogomernom-raspredelenii,page_004.png,4,0,0,0.0570065975189209,"Error code: 400 - {'error': 'Trying to keep the first 11360 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a larger context length, or provide a shorter input'}"
o-predelnom-mnogomernom-raspredelenii,page_001.png,1,0,0,0.09237217903137207,"Error code: 400 - {'error': 'Trying to keep the first 18136 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a larger context length, or provide a shorter input'}"
o-predelnom-mnogomernom-raspredelenii,page_003.png,3,0,0,0.14755463600158691,"Error code: 400 - {'error': 'Trying to keep the first 17616 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a larger context length, or provide a shorter input'}"
standartizatsiya-i-kachestvo-zhizni,page_001.png,1,0,0,0.061469078063964844,"Error code: 400 - {'error': 'Trying to keep the first 20465 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a larger context length, or provide a shorter input'}"
standartizatsiya-i-kachestvo-zhizni,page_002.png,2,0,0,0.08432936668395996,"Error code: 400 - {'error': 'Trying to keep the first 24361 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a larger context length, or provide a shorter input'}"
standartizatsiya-i-kachestvo-zhizni,page_003.png,3,0,0,0.1076807975769043,"Error code: 400 - {'error': 'Trying to keep the first 19765 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a larger context length, or provide a shorter input'}"
Книга_Python_К_вершинам_мастерства_Рамальо_Лучано,page_001.png,1,0,0,0.10467791557312012,"Error code: 400 - {'error': 'Trying to keep the first 16265 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a larger context length, or provide a shorter input'}"
Книга_Python_К_вершинам_мастерства_Рамальо_Лучано,page_002.png,2,0,0,0.056508779525756836,"Error code: 400 - {'error': 'Trying to keep the first 22904 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a larger context length, or provide a shorter input'}"
Книга_Python_К_вершинам_мастерства_Рамальо_Лучано,page_003.png,3,0,0,0.061937808990478516,"Error code: 400 - {'error': 'Trying to keep the first 16793 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a larger context length, or provide a shorter input'}"
Книга_Python_К_вершинам_мастерства_Рамальо_Лучано,page_004.png,4,0,0,0.07433772087097168,"Error code: 400 - {'error': 'Trying to keep the first 17114 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a larger context length, or provide a shorter input'}"
Книга_Python_К_вершинам_мастерства_Рамальо_Лучано,page_005.png,5,0,0,0.06807827949523926,"Error code: 400 - {'error': 'Trying to keep the first 23854 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a larger context length, or provide a shorter input'}"
