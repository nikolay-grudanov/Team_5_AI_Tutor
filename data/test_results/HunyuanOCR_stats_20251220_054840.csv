folder_name,filename,page_number,text_length,tokens,processing_time,error
o-predelnom-mnogomernom-raspredelenii,page_001.png,1,0,0,0.03714466094970703,"Error code: 400 - {'error': {'message': ""'max_tokens' or 'max_completion_tokens' is too large: 2048. This model's maximum context length is 2048 tokens and your request has 14 input tokens (2048 > 2048 - 14). None"", 'type': 'BadRequestError', 'param': None, 'code': 400}}"
o-predelnom-mnogomernom-raspredelenii,page_002.png,2,0,0,0.03695321083068848,"Error code: 400 - {'error': {'message': ""'max_tokens' or 'max_completion_tokens' is too large: 2048. This model's maximum context length is 2048 tokens and your request has 14 input tokens (2048 > 2048 - 14). None"", 'type': 'BadRequestError', 'param': None, 'code': 400}}"
o-predelnom-mnogomernom-raspredelenii,page_003.png,3,0,0,0.03742694854736328,"Error code: 400 - {'error': {'message': ""'max_tokens' or 'max_completion_tokens' is too large: 2048. This model's maximum context length is 2048 tokens and your request has 14 input tokens (2048 > 2048 - 14). None"", 'type': 'BadRequestError', 'param': None, 'code': 400}}"
o-predelnom-mnogomernom-raspredelenii,page_004.png,4,0,0,0.03560996055603027,"Error code: 400 - {'error': {'message': ""'max_tokens' or 'max_completion_tokens' is too large: 2048. This model's maximum context length is 2048 tokens and your request has 14 input tokens (2048 > 2048 - 14). None"", 'type': 'BadRequestError', 'param': None, 'code': 400}}"
standartizatsiya-i-kachestvo-zhizni,page_001.png,1,0,0,0.042821645736694336,"Error code: 400 - {'error': {'message': ""'max_tokens' or 'max_completion_tokens' is too large: 2048. This model's maximum context length is 2048 tokens and your request has 14 input tokens (2048 > 2048 - 14). None"", 'type': 'BadRequestError', 'param': None, 'code': 400}}"
standartizatsiya-i-kachestvo-zhizni,page_002.png,2,0,0,0.04185318946838379,"Error code: 400 - {'error': {'message': ""'max_tokens' or 'max_completion_tokens' is too large: 2048. This model's maximum context length is 2048 tokens and your request has 14 input tokens (2048 > 2048 - 14). None"", 'type': 'BadRequestError', 'param': None, 'code': 400}}"
standartizatsiya-i-kachestvo-zhizni,page_003.png,3,0,0,0.040155649185180664,"Error code: 400 - {'error': {'message': ""'max_tokens' or 'max_completion_tokens' is too large: 2048. This model's maximum context length is 2048 tokens and your request has 14 input tokens (2048 > 2048 - 14). None"", 'type': 'BadRequestError', 'param': None, 'code': 400}}"
Книга_Python_К_вершинам_мастерства_Рамальо_Лучано,page_001.png,1,0,0,0.17055058479309082,"Error code: 400 - {'error': {'message': ""'max_tokens' or 'max_completion_tokens' is too large: 2048. This model's maximum context length is 2048 tokens and your request has 14 input tokens (2048 > 2048 - 14). None"", 'type': 'BadRequestError', 'param': None, 'code': 400}}"
Книга_Python_К_вершинам_мастерства_Рамальо_Лучано,page_002.png,2,0,0,0.3113894462585449,"Error code: 400 - {'error': {'message': ""'max_tokens' or 'max_completion_tokens' is too large: 2048. This model's maximum context length is 2048 tokens and your request has 14 input tokens (2048 > 2048 - 14). None"", 'type': 'BadRequestError', 'param': None, 'code': 400}}"
Книга_Python_К_вершинам_мастерства_Рамальо_Лучано,page_003.png,3,0,0,0.18835926055908203,"Error code: 400 - {'error': {'message': ""'max_tokens' or 'max_completion_tokens' is too large: 2048. This model's maximum context length is 2048 tokens and your request has 14 input tokens (2048 > 2048 - 14). None"", 'type': 'BadRequestError', 'param': None, 'code': 400}}"
Книга_Python_К_вершинам_мастерства_Рамальо_Лучано,page_004.png,4,0,0,0.17418169975280762,"Error code: 400 - {'error': {'message': ""'max_tokens' or 'max_completion_tokens' is too large: 2048. This model's maximum context length is 2048 tokens and your request has 14 input tokens (2048 > 2048 - 14). None"", 'type': 'BadRequestError', 'param': None, 'code': 400}}"
Книга_Python_К_вершинам_мастерства_Рамальо_Лучано,page_005.png,5,0,0,0.2263941764831543,"Error code: 400 - {'error': {'message': ""'max_tokens' or 'max_completion_tokens' is too large: 2048. This model's maximum context length is 2048 tokens and your request has 14 input tokens (2048 > 2048 - 14). None"", 'type': 'BadRequestError', 'param': None, 'code': 400}}"
