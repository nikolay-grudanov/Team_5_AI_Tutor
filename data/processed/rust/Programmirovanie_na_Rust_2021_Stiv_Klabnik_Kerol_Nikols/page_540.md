---
source_image: page_540.png
page_number: 540
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 23.96
tokens: 7462
characters: 1796
timestamp: 2025-12-24T10:59:52.719043
finish_reason: stop
---

Превращение однопоточного сервера в многопоточный

Прямо сейчас сервер обрабатывает каждый запрос по очереди, то есть он не обрабатывает второе соединение до тех пор, пока не завершится обработка первого. Если бы сервер получал все больше и больше запросов, то такое последовательное выполнение было бы все менее и менее оптимальным. Если сервер получит запрос, обработка которого занимает много времени, то последующие запросы должны будут ждать завершения продолжительного запроса, даже если новые могут обрабатываться быстро. Нам потребуется это исправить, но сначала рассмотрим указанную проблему на практике.

Моделирование медленного запроса в текущей реализации сервера

Мы рассмотрим, каким образом запрос с медленной обработкой влияет на другие запросы, выполняемые в текущей реализации сервера. В листинге 20.10 реализована обработка запроса ресурса /sleep со смоделированным медленным ответом, из-за которого сервер перед ответом будет засыпать на 5 секунд.

Листинг 20.10. Моделирование медленного запроса путем распознавания запроса /sleep и засыпания на 5 секунд

src/main.rs
use std::thread;
use std::time::Duration;
// --пропуск--

fn handle_connection(mut stream: TcpStream) {
    // --пропуск--

    let get = b"GET / HTTP/1.1\r\n";
    let sleep = b"GET /sleep HTTP/1.1\r\n";

    let (status_line, filename) = if buffer.starts_with(get) {
        ("HTTP/1.1 200 OK\r\n\r\n", "hello.html")
    } else if buffer.starts_with(sleep) {
        thread::sleep(Duration::from_secs(5));
        ("HTTP/1.1 200 OK\r\n\r\n", "hello.html")
    } else {
        ("HTTP/1.1 404 НЕ НАЙДЕНО\r\n\r\n", "404.html")
    };

    // --пропуск--
}

Этот код немного запутан, но как модель он достаточно хорош. Мы создали второй запрос sleep ①, данные которого сервер распознает. Мы добавили else if