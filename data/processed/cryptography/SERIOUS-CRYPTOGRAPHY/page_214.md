---
source_image: page_214.png
page_number: 214
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 45.48
tokens: 8024
characters: 2957
timestamp: 2025-12-24T09:16:16.752545
finish_reason: stop
---

Действительно, если \( N \) — непростое число, то у него должен быть хотя бы один множитель, меньший \( \sqrt{N} \), поскольку если бы оба множителя \( p \) и \( q \) были больше \( \sqrt{N} \), то их произведение было бы больше \( \sqrt{N} \times \sqrt{N} = N \). Так, если \( N = 100 \), то оба множителя \( p \) и \( q \) не могут быть больше 10, потому что иначе их произведение было бы больше 100. Либо \( p \), либо \( q \) должно быть меньше \( \sqrt{N} \).

А какова сложность проверки только простых чисел, меньших \( \sqrt{N} \)? Теорема о распределении простых чисел утверждает, что существует приблизительно \( N / \log N \) простых чисел, меньших \( N \). Следовательно, существует приблизительно \( \sqrt{N} / \log \sqrt{N} \) простых чисел, меньших \( \sqrt{N} \). Поскольку \( \sqrt{N} = 2^{n/2} \), а \( 1 / \log \sqrt{N} = 1 / (n/2) = 2n \), получается, что существует приблизительно \( 2^{n/2} / n \) возможных простых множителей и, значит, сложность равна \( O(2^{n/2} / n) \). Это быстрее, чем проверять все простые числа, но все равно мучительно медленно — порядка \( 2^{120} \) операций для 256-битового числа. Совершенно неподъемное вычисление.

Самый быстрый алгоритм факторизации — общий метод решета числового поля (general number field sieve — GNFS), который я не буду здесь описывать, потому что для его понимания требуется владение нетривиальным математическим аппаратом. Грубая оценка сложности GNFS — \( \exp(1.91 \times n^{1/3} (\log n)^{2/3}) \), где \( \exp(...) \) — другое обозначение экспоненциальной функции \( e^x \), а \( e \) — постоянная Эйлера, равная приблизительно 2.718. Но получить точную оценку сложности GNFS для заданного размера числа трудно. Поэтому приходится опираться на эвристические оценки, показывающие, как растет безопасность при увеличении \( n \). Например:

• для факторизации 1024-битового числа, имеющего два простых множителя длиной примерно по 500 бит, требуется порядка \( 2^{70} \) элементарных операций;
• для факторизации 2048-битового числа, имеющего два простых множителя длиной примерно по 1000 бит, требуется порядка \( 2^{90} \) элементарных операций, т. е. приблизительно в миллион раз больше, чем для 1024-битового числа.

Согласно имеющимся оценкам, для достижения 128-битовой безопасности число должно содержать по меньшей мере 4096 бит. Заметим, что к этим оценкам следует относиться с долей скептицизма, и не все исследователи с ними согласны. Взгляните на экспериментальные результаты, демонстрирующие фактическую стоимость факторизации:

• в 2005 году, после примерно 18 месяцев вычислений на кластере из 80 процессоров (эквивалент 75 лет вычислений на одном процессоре) удалось факторизовать 663-битовое (200 десятичных цифр) число;
• в 2009 году после двух лет вычислений с использованием нескольких сотен процессоров, что эквивалентно примерно 2000 лет вычислений на одном процессоре, другая группа исследователей факторизовала 768-битовое (232 десятичные цифры) число.