---
source_image: docs_tutorials-evolution_list_topics_ml-finetuning__finetune-example.jpg
page_number: 0
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 12.79
tokens: 6106
characters: 2798
timestamp: 2025-12-24T06:03:08.470253
finish_reason: stop
---

Дообучение готовой модели из Huggingface

С помощью этого руководства вы запустите процесс дообучения модели mistralai/Ministral-8B-Instruct-2410.

Вы будете использовать следующие сервисы:

• Secret Management — безопасное хранилище секретов.
• ML Finetuning — сервис для дообучения моделей.
• Huggingface — платформа для публикации и использования моделей машинного обучения.

Шаги:

1. Создайте секрет с токеном Huggingface.
2. Запустите дообучение модели и проверьте результат.

Перед началом работы

Зарегистрируйтесь в личном кабинете Cloud.ru.

Если вы уже зарегистрированы, войдите под своей учетной записью.

1. Создайте секрет с токеном Huggingface

1. Создайте токен Huggingface.
   a. Войдите или зарегистрируйтесь на https://huggingface.co.
   b. Перейдите в раздел Access Tokens.
   c. Нажмите Create new token.
   d. Выберите тип Write.
   e. Введите название токена.
   f. Нажмите Create token.
   g. Скопируйте токен и сохраните его, например в блокнот. После закрытия страницы он будет недоступен.

2. Создайте секрет в Secret Management со следующими параметрами:
   a. В поле Название укажите название секрета, например hf-token .
   b. В поле Значение вставьте токен, полученный в личном кабинете Huggingface.

2. Запустите дообучение модели

1. Перейдите в AI Factory → ML Finetuning.
2. Нажмите Дообучить модель.
   a. В поле Репозиторий с моделью укажите название модели mistralai/Ministral-8B-Instruct-2410 .

Примечание
Перед началом дообучения убедитесь, что у вас есть доступ к модели, проверив ее карточку на Huggingface.

Для модели mistralai/Ministral-8B-Instruct-2410 запрашивать специальный доступ не нужно.

b. В поле Токен доступа выберите секрет hf-token .
c. В поле Репозиторий модели укажите репозиторий для загрузки дообученной модели my-org/ministral-finetuned .
d. В поле Датасет укажите репозиторий датасета tatsu-lab/alpaca .
e. В поле Метод обучения выберите LoRA .
f. Укажите гиперпараметры обучения:
   • Learning rate — 0.0001 .
   • Epoch — 3 .
   • Gradient accumulation — 4 .
   • Batch size per device — 16 .
   • Training precision — bf16 .
   • Logging steps — 50 .
   • Save steps — 500 .
   • Max samples — 100000 .
g. Нажмите Запустить дообучение.

3. Проверьте результат дообучения в логах:
   a. Перейдите в AIFactory → ML Finetuning.
   b. Нажмите на название модели.
   c. Перейдите на вкладку Логи.

Что дальше

Вы создали секрет с токеном Huggingface, запустили процесс дообучения модели в сервисе ML Finetuning и проверили модель в Huggingface. Полученные навыки помогут интегрировать внешние модели и данные в облачную инфраструктуру Cloud.ru, а также автоматизировать процесс дообучения.

Узнавайте больше о прикладных сценариях и примерах решения бизнес-задач, получайте навыки управления облаком, выполняя практические руководства.