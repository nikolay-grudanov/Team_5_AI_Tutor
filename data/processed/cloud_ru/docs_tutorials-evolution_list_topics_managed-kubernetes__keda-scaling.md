---
source_image: docs_tutorials-evolution_list_topics_managed-kubernetes__keda-scaling.jpg
page_number: 0
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 87.92
tokens: 13997
characters: 9230
timestamp: 2025-12-24T05:56:06.595978
finish_reason: stop
---

### Event-driven масштабирование в Managed Kubernetes с помощью KEDA

С помощью этого руководства вы развернете инфраструктуру Managed Kubernetes и установите решение KEDA для event-driven автоматического масштабирования приложений.

Вы настроите масштабирование Kubernetes Job на основе сообщений из очереди RabbitMQ, что позволит реализовать обработку событий и горизонтальное масштабирование без привязки к метрикам потребления ресурсов.

В результате вы получите решение для асинхронной обработки задач в Kubernetes с использованием KEDA.

Вы будете использовать следующие сервисы:

- **Managed Kubernetes** — сервис управления кластерами Kubernetes на вычислительных ресурсах облака.
- **Artifact Registry** для хранения, совместного использования и управления Docker-образами и Helm-чартами.
- **Виртуальные машины** — сервис для создания виртуальных машин, используемых для управления кластерами и запуска утилит администрирования.
- **KEDA** — платформа для событийного масштабирования приложений в Kubernetes на основе внешних триггеров, таких как очередь сообщений и базы данных.

Шаги:

1. Сгенерируйте ключи доступа для интеграции.
2. Разверните ресурсы в облаке.
3. Подготовьте окружение виртуальной машины.
4. Создайте кластер Managed Kubernetes и подключитесь к нему.
5. Создайте репозиторий Artifact Registry.
6. Установите MongoDB через Helm.
7. Установите RabbitMQ через Helm.
8. Установите KEDA.
9. Загрузите образы контейнеров в приватный реестр Artifact Registry.
10. Разверните приложение в Kubernetes.
11. Проверьте работу автоматического масштабирования KEDA.

Перед началом работы

Зарегистрируйтесь в личном кабинете Cloud.ru.

Если вы уже зарегистрированы, войдите под своей учетной записью.

1. Сгенерируйте ключи доступа для интеграции

На этом этапе получите ключи для программного доступа к ресурсам облачной платформы, которые потребуются для интеграции с Managed Kubernetes и приватным реестром Artifact Registry.

1. Сгенерируйте ключи доступа Key ID и Key Secret для своего аккаунта.
2. Сохраните значения Key ID и Key Secret в надежном месте, чтобы использовать их при загрузке образов контейнеров и подключении к кластеру Managed Kubernetes.

2. Разверните ресурсы в облаке

Этот шаг включает подготовку подсети, NAT-шлюза и виртуальной машины для последующей работы и управления кластером.

1. Создайте подсеть для размещения кластера Managed Kubernetes.
2. Создайте SNAT-шлюз в той же зоне доступности, что и подсеть.
3. Создайте виртуальную машину с подсетью с публичным IP-адресом. Выберите ранее созданную подсеть для подключения.

3. Подготовьте окружение виртуальной машины

На этом этапе настройте окружение для управления облачной инфраструктурой и кластером Kubernetes.

1. Подключитесь к виртуальной машине по SSH, используя соответствующий SSH-клиент.
2. Установите необходимые инструменты для работы с Managed Kubernetes:
   a. kubectl
   b. cloudlogin
3. Установите Git и клонируйте репозиторий демоприложения:
   a. Установите Git для ОС на базе Ubuntu/Debian:
      ```sh
      sudo apt update && sudo apt install -y git
      ```
   b. Клонируйте репозиторий демоприложения:
      ```sh
      git clone https://gitverse.ru/sedgll/keda-p2
      ```
4. Установите Docker:
   ```sh
   curl -fsSL https://get.docker.com -o get-docker.sh
   sudo sh /get-docker.sh
   sudo groupadd docker
   sudo usermod -aG docker $USER
   newgrp docker
   ```
5. Установите Helm:
   ```sh
   curl -fsSL --output get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3
   chmod 700 get_helm.sh
   ./get_helm.sh
   ```

4. Создайте кластер Managed Kubernetes и подключитесь к нему

На этом этапе разверните кластер Kubernetes.

1. Создайте кластер в сервисе Managed Kubernetes:
   • Название: Cluster-keda.
   • Количество мастер-узлов: 1.
   • Конфигурация мастер-узла: 2 vCPU, 4 ГБ RAM.
   • Публичный IP: включен.
2. Создайте группу узлов
   • Гарантированная доля vCPU: 10%.
   • vCPU: 2.
   • RAM, ГБ: 4.
   • Количество узлов: 1.
3. Дождитесь окончания создания кластера.
4. Убедитесь, что в личном кабинете статус кластера — «Запущено».
5. Подключитесь к кластеру с управляющей виртуальной машины.

5. Создайте репозиторий Artifact Registry

На этом шаге создайте приватный реестр в сервисе Artifact Registry.

6. Установите MongoDB через Helm

На этом шаге вы установите MongoDB в кластер Managed Kubernetes.

1. Установите MongoDB с помощью Helm:
   ```sh
   helm install mongodb oci://registry-1.docker.io/bitnamicharts/mongodb --set useStatefulSet=true --set ...
   ```
2. Проверьте статус развертывания MongoDB:
   ```sh
   kubectl get pods
   ```
3. Дождитесь, пока все поды MongoDB перейдут в состояние «Running».

7. Установите RabbitMQ через Helm

На этом шаге установите очередь сообщений RabbitMQ с помощью Helm в кластер Managed Kubernetes.

1. Установите RabbitMQ командой:
   ```sh
   helm install rabbitmq oci://registry-1.docker.io/bitnamicharts/rabbitmq --set auth.username=user --set ...
   ```
2. Проверьте состояние подов RabbitMQ:
   ```sh
   kubectl get pods
   ```
3. Дождитесь, пока все поды очереди RabbitMQ перейдут в состояние «Running».

8. Установите KEDA

На этом шаге вы установите KEDA для поддержки событийного масштабирования.

1. В личном кабинете перейдите в созданный кластер Managed Kubernetes.
2. На панели слева выберите Плагины и нажмите Добавить плагин.
3. Выберите KEDA и нажмите Установить.
4. Выберите версию плагина и нажмите Установить.
5. Чтобы проверить статус подов KEDA, в терминале выполните команду:
   ```sh
   kubectl get pods -n keda
   ```
6. Дождитесь, пока все поды KEDA перейдут в состояние «Running».

9. Загрузите образы контейнеров в приватный реестр Artifact Registry

На этом этапе соберите и загрузите образы собственного приложения в приватный реестр.

1. Перейдите в папку репозитория приложения:
   ```sh
   cd $HOME/keda-p2
   ```
2. Откройте файл build.sh в удобном редакторе.
3. Укажите URI вашего приватного реестра и ключи доступа к облаку в переменных в начале скрипта:
   • <REPO> — адрес реестра Artifact Registry.
   • <LOGIN> — Key ID учетной записи.
   • <PASSWORD> — Secret Key учетной записи.
4. Сделайте скрипт исполняемым и выполните его:
   ```sh
   chmod +x $HOME/keda-p2/build-images.sh
   $HOME/keda-p2/build-images.sh
   ```
Скрипт выполнит аутентификацию с помощью ключей доступа в Artifact Registry, соберет образы контейнеров через Docker Engine и загрузит их в указанный реестр.

10. Разверните приложение в Managed Kubernetes

На этом этапе выполните развертывание event-driven приложения, используя подготовленные манифесты.

1. Примените манифесты:
   ```sh
   kubectl apply -f $HOME/keda-p2/deploy/
   ```
2. Ознакомьтесь со схемой работы приложения:

![Схема работы приложения](https://example.com/scheme.png)

• При отправке POST-запроса на http://complex-app-keda-service/send?name=<item-name>&content=<content> сервис complex-app отправляет сообщение с параметрами name и content в формате JSON в очередь RabbitMQ.
• Ресурс ScaledJob периодически опрашивает очередь RabbitMQ. Когда в очередь приходит новое сообщение, ScaledJob создает новый Kubernetes Job с именем processor-job .
• Ресурс processor-job извлекает сообщение, записывает его в MongoDB в формате JSON (name и content), после чего засыпает на 20 секунд.
• Функция sleep имитирует, что processor-job обрабатывает какой-то «тяжелый» файл. Например, конвертирует видео.
• Если вы масштабировали Deployment с помощью ресурса HPA, то реализовать описанное выше масштабирование было бы невозможно, так как нам необходимо масштабировать ресурс не на основании метрик утилизации ресурсов, а на основании событий.

3. Проверьте, что все необходимые поды созданы и работают.

11. Проверьте работу автоматического масштабирования KEDA

На завершающем этапе вы протестируете работу event-driven масштабирования через отправку сообщений и анализ работы Job.

1. Создайте тестовый под curl для взаимодействия с приложением:
   ```sh
   kubectl run -it --rm curl-pod --image=curlimages/curl -- /bin/sh
   ```
2. Внутри curl-pod отправьте несколько POST-запросов на сервис для генерации событий:
   ```sh
   curl -X POST "http://complex-app-keda-service/send?name=record1&content=content1"
   curl -X POST "http://complex-app-keda-service/send?name=record2&content=content2"
   curl -X POST "http://complex-app-keda-service/send?name=record3&content=content3"
   curl -X POST "http://complex-app-keda-service/send?name=record4&content=content4"
   curl -X POST "http://complex-app-keda-service/send?name=record5&content=content5"
   ```
3. Проверьте, что данные были добавлены в MongoDB:
   ```sh
   curl "http://complex-app-keda-service/data"
   ```
   Job-ресурсам потребуется некоторое время на запуск и выполнение, поэтому записи могут появиться в течение минуты.
4. Выйдите из curl-пода командой:
   ```sh
   exit
   ```
5. Проверьте количество созданных Job:
   ```sh
   kubectl get jobs
   ```
Убедитесь, что для каждого события KEDA запустила отдельный Job, реализуя event-driven масштабирование обработки.

Что дальше

В практической работе вы создали кластер Managed Kubernetes, установили KEDA в этом кластере и развернули в нем приложение, в котором реализовано event-driven масштабирование с помощью KEDA.