---
source_image: docs_tutorials-evolution_list_topics_managed-rag__md-files.jpg
page_number: 0
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 46.97
tokens: 7919
characters: 5438
timestamp: 2025-12-24T05:59:18.052285
finish_reason: stop
---

### Создание базы знаний из md-файлов

В руководстве описан сценарий создания базы знаний на основе markdown-файлов, чтобы продемонстрировать, как дополнительная информация из внешних источников улучшает качество ответов языковой модели.

В результате вы получите практические навыки работы с технологией Retrieval Augmented Generation (RAG), которая позволяет расширять контекст запросов к языковым моделям за счет внешних данных.

Вы будете использовать следующие сервисы:

• Managed RAG — сервис для создания и управления базами знаний, используемыми при генерации ответов языковыми моделями.
• Object Storage — объектное S3-хранилище с бесплатным хранением файлов, объемом до 15 ГБ.
• T-Lite — легковесная языковая модель, с которой вы будете взаимодействовать в чате и с помощью клиента Chatbox.

Шаги:

1. Подготовьте контент для базы знаний.
2. Создайте базу знаний.
3. Проверьте работу LLM с базой знаний.

Перед началом работы

1. Зарегистрируйтесь в личном кабинете Cloud.ru.
   Если вы уже зарегистрированы, войдите под своей учетной записью.
2. Скачайте архив cloudia_docs.zip.

Шаг 1. Подготовьте контент для базы знаний

На этом шаге вы подготовите документы с информацией об AI-ассистенте Cloud.ru и загрузите их в объектное хранилище для последующего использования в базе знаний.

1. Распакуйте архив cloudia_docs.zip на вашем компьютере.
   Внутри распакованной папки cloudia_docs находятся файлы в формате .md.
2. Создайте бакет в сервисе Object Storage со следующими параметрами:
   a. В поле Название укажите уникальное название бакета, например rag-kb-cloudia-docs.
   b. В поле Класс хранения выберите «Стандартный».
   Остальные параметры оставьте по умолчанию.
3. В бакете нажмите Создать папку и укажите ее название, например cloudia_docs .
4. Загрузите файлы в папку бакета:
   a. Откройте папку cloudia_docs в бакете.
   b. Нажмите Загрузить.
   c. Выберите все файлы из локальной папки cloudia_docs .
   d. Подтвердите загрузку.
Ожидайте завершения загрузки — процесс может занять несколько секунд в зависимости от скорости интернет-соединения.

Шаг 2. Создайте базу знаний

На этом шаге вы создадите базу знаний на основе загруженных документов и проиндексируете ее для использования с языковыми моделями.

1. В личном кабинете перейдите в AI Factory → Managed RAG.
2. Нажмите Создать базу знаний.
3. Настройте параметры базы знаний:
   a. В поле Название укажите имя базы знаний, например cloudia-kb .
   b. При необходимости введите описание в поле Описание.
   c. В поле Путь к папке в бакете укажите путь в формате s3://<bucket_name>/cloudia_docs/ , где <bucket_name> — название созданного вами бакета, например rag-kb-cloudia-docs .
   d. В поле Расширение файлов введите md и выберите его.
Остальные параметры оставьте по умолчанию.
4. Нажмите Создать.
Дождитесь завершения индексации базы знаний и ее версии — это займет несколько минут.

Шаг 3. Проверьте работу LLM с базой знаний

На этом шаге вы сравните ответы языковой модели T-Lite без использования базы знаний и с ней, чтобы оценить улучшения контекста.

1. Ознакомьтесь с ответом модели «t-tech/T-lite-it-1.0» на следующий вопрос:

Расскажи о новом AI-ассистенте Cloud.ru.

Модель генерирует ответ на основе собственных знаний, полученных при обучении, и предоставляет вымышленную информацию.

Cloud.ru недавно представил новый AI-ассистента, который получил название "CloudAI". Этот ассистент разработан для улучшения пользовательского опыта и автоматизации рутинных задач в облачной инфраструктуре.

Основные функции CloudAI:
1. Автоматизация управления: CloudAI способен автоматически настраивать и оптимизировать облачную инфраструктуру, что позволяет сократить время на администрирование и минимизировать ошибки.
2. Мониторинг и оповещения: Ассистент предоставляет детальный мониторинг состояния серверов и других компонентов облачной инфраструктуры, а также отправляет уведомления при возникновении проблем.
3. Аналитика и прогнозирование: CloudAI использует алгоритмы машинного обучения для анализа данных и прогнозирования возможных сбоев или перегрузок, что позволяет предпринимать превентивные меры.
4. Интеграция с другими сервисами: Ассистент поддерживает интеграцию с популярными облачными платформами и инструментами, такими как Kubernetes, Docker и другие.

Чтобы самостоятельно проверить этот запрос, подключите Foundation Models в стороннем клиенте Chatbox AI.
2. В личном кабинете перейдите в AI Factory → Managed RAG.
3. Выберите созданную базу знаний (например, cloudia-kb ). Она должна быть в статусе «Активная».
4. Перейдите в версию базы знаний и нажмите Чат.
5. Задайте тот же вопрос:

Расскажи о новом AI-ассистенте Cloud.ru.

Теперь модель использует информацию из базы знаний и предоставляет точный, достоверный ответ, основанный на документации об AI-ассистенте Cloud.ru и дополнительных данных.

Что дальше

С этим руководством вы создали базу знаний с помощью Managed RAG, загрузили в нее документацию об AI-ассистенте Cloud.ru и проверили, как дополнительные данные улучшают качество ответов языковой модели.

Вы убедились, что даже «легковесная» модель может давать точные и релевантные ответы при использовании технологии RAG, что открывает возможности для создания специализированных ассистентов по внутренней документации, технической поддержке и другим задачам.

Узнавайте больше о прикладных сценариях и примерах решения бизнес-задач, получайте навыки управления облаком, выполняя практические руководства.