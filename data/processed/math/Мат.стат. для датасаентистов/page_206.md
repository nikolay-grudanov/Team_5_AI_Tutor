---
source_image: page_206.png
page_number: 206
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 65.50
tokens: 12013
characters: 2645
timestamp: 2025-12-24T06:15:09.881126
finish_reason: stop
---

ем оценки максимального правдоподобия (MLE, maximum likelihood estimation). Оценка максимального правдоподобия — это процедура, пытающаяся найти модель, которая вероятнее всего породила данные, имеющиеся у нас. В уравнении логистической регрессии откликом является не 0 или 1, а оценка логарифма шансов, что отклик равняется 1. Метод MLE находит такое решение, что оценочный логарифм шансов наилучшим образом описывает наблюдаемый исход. Механизм данного алгоритма сопряжен с квазиньютоновской оптимизацией, которая итеративно выполняется на основе текущих параметров между шагом оценки результивности (оценка в баллах по Фишеру) и обновлением параметров для улучшения подгонки.

Оценка максимального правдоподобия

Рассмотрим этот метод подробнее, если вам нравятся статистические символы: начнем с набора данных \((X_1, X_2, ..., X_n)\) и вероятностной модели \(P_\theta(X_1, X_2, ..., X_n)\), которая зависит от набора параметров \(\hat{\theta}\). Цель метода MLE состоит в том, чтобы найти набор параметров \(\hat{\theta}\), который максимизирует значение \(P_\theta(X_1, X_2, ..., X_n)\), т. е. максимизирует вероятность наблюдать \((X_1, X_2, ..., X_n)\) в условиях модели \(P(...)\). В процессе подгонки модель оценивается при помощи метрического показателя, который называется погрешностью:

\[
\text{погрешность} = -2 \log(P_{\hat{\theta}}(X_1, X_2, ..., X_n)).
\]

Более низкая погрешность соответствует более удачной подгонке.

К счастью, большинству пользователей не придется заниматься деталями алгоритма подгонки, поскольку они обрабатываются программным обеспечением. Кроме того, большинству аналитиков данных нет надобности беспокоиться по поводу метода подгонки, кроме понимания того, что он представляет собой способ найти хорошую модель при наличии определенных предположений.

Обработка факторных переменных
В логистической регрессии факторные переменные должны кодироваться как в линейной регрессии (см. разд. "Факторные переменные в регрессии" главы 4). В R и других программных системах это обычно обрабатывается автоматически, и вдобавок, как правило, используется опорное кодирование. Все другие методы классификации, охваченные в этой главе, в основном используют представление в виде кодировщика с одним активным состоянием (см. разд. "Кодировщик с одним активным состоянием" главы 6).

Диагностика модели
Как и другие методы классификации, логистическая регрессия диагностируется тем, насколько точно модель классифицирует новые данные (см. разд. "Оценивание моделей классификации" далее в этой главе). Как и в случае с линейной регрессией, есть несколько дополнительных стандартных статистических инструментов, кото-