---
source_image: page_155.png
page_number: 155
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 58.37
tokens: 11875
characters: 2229
timestamp: 2025-12-24T06:12:36.857224
finish_reason: stop
---

Отбор модели и шаговая регрессия

В некоторых задачах многие переменные могут применяться в качестве предикторов в регрессии. Например, для предсказания стоимости дома могут использоваться дополнительные переменные, такие как размер подвала или год постройки. В R их легко добавить к уравнению регрессии:

house_full <- lm(AdjSalePrice ~ SqFtTotLiving + SqFtLot + Bathrooms +
    Bedrooms + BldgGrade + PropertyType + NbrLivingUnits +
    SqFtFinBasement + YrBuilt + YrRenovated +
    NewConstruction,
    data=house, na.action=na.omit)

Добывление большего количества переменных, однако, не обязательно означает, что у нас получится более хорошая модель. В статистике в качестве ориентира пользуются принципом бритвы Оккама, который позволяет выбрать модель: при прочих равных условиях предпочтение отдается использованию более простой модели над более сложной.

Включение в состав дополнительных переменных всегда уменьшает RMSE и увеличивает \( R^2 \). Следовательно, они не подходят в качестве ориентиров, которые помогают выбрать модель. В 1970-х гг. Хиротугу Акаике (Hirotugu Akaike), выдающийся японский статистик, разработал метрический показатель, названный информационным критерием Акаике — AIC (Akaike’s Information Criteria), который штрафует добавление членов в модель. В случае регрессии AIC имеет следующую форму:

\[
AIC = 2P + n \log \left( \text{RSS}/n \right),
\]

где \( p \) — это число переменных; \( n \) — число записей. Цель состоит в том, чтобы найти модель, которая минимизирует AIC; модели с \( k \) дополнительными переменными штрафуются на \( 2k \).

AIC, BIC и CP Мэллоуза
Формула AIC может показаться немного таинственной, но фактически она основывается на асимптотических результатах в теории информации. Существует несколько вариантов AIC:
• AICc — версия AIC, скорректированная для размеров небольших выборок;
• BIC, или байесовский информационный критерий, — аналогичный AIC, но с более сильным штрафом за включение в состав модели дополнительных переменных;
• CP Мэллоуза — вариант AIC, разработанный Колином Мэллоузом (Colin Mallows).

Аналитикам данных обычно не приходится беспокоиться по поводу различий среди этих внутривыборочных метрических показателей или теории, лежащей в их основе.