---
source_image: page_136.png
page_number: 136
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 79.84
tokens: 12212
characters: 3128
timestamp: 2025-12-24T06:12:03.101903
finish_reason: stop
---

♦ рука \( A \): 10 выигрышей из 50;
♦ рука \( B \): 2 выигрыша из 50;
♦ рука \( C \): 4 выигрыша из 50.

Один из предельных подходов состоит в том, чтобы сказать: "Похоже, рычаг \( A \) выигрышный — надо прекратить пробовать другие и остановиться на \( A \)". Этот шаг в полной мере пользуется информацией начального испытания. Если \( A \) действительно превосходит, то мы извлекаем из этого пользу с самого начала. С другой стороны, если \( B \) или \( C \) реально лучше, то мы теряем любую возможность это обнаружить. Другой предельный подход состоит в том, чтобы сказать: "Сдается, что все это во власти случая — попробую подергать их одинаково". Это дает максимальную возможность проявиться другим альтернативам помимо \( A \). Однако по ходу мы задействуем варианты, которые выглядят менее удачными. Сколько времени мы позволим этому продолжаться? Бандитские алгоритмы принимают гибридный подход: мы чаще начинаем дергать за рычаг \( A \), пользуясь его очевидным превосходством, но мы не отказываемся от \( B \) и \( C \). Мы просто обращаемся к ним не так часто. Если \( A \) продолжает превосходить по результативности, то мы продолжаем смешать ресурсы (нажимаем рычаги) в сторону от \( B \) и \( C \) и чаще нажимаем на \( A \). Если с другой стороны \( C \) начинает работать лучше, а \( A \) — хуже, то мы можем сместиться от \( A \) назад к \( C \). Если окажется, что один из них превосходит \( A \), и это было скрыто в начальном испытании в силу случайности, то теперь он имеет возможность проявить себя при дальнейшем тестировании.

Теперь подумаем, как это применить к веб-тестированию. Вместо нескольких пусковых рычагов автомата у вас могут быть многочисленные варианты, заголовки объявлений, цвета и другие объекты и характеристики, которые тестируются на веб-сайте. Клиенты либо нажимают ("выигрыш" для коммерсанта), либо не нажимают. Первоначально, варианты предлагаются произвольно и одинаково. Если, однако, один вариант начинает превосходить по результативности другие, то он может предлагаться ("нажиматься") чаще. Но какими должны быть параметры алгоритма, который изменяет интенсивность нажатий рычага? На какую "интенсивность нажатий рычага" мы должны перейти, и когда мы должны это сделать?

Вот один из простых алгоритмов, эпсилон-жадный (\( \varepsilon \)) алгоритм для \( A/B \)-теста:

1. Сгенерировать случайное число между 0 и 1.
2. Если число находится между 0 и \( \varepsilon \) (при этом \( \varepsilon \) — это число между 0 и 1, обычно довольно малое), подбросьте "справедливую" монету (с вероятностью 50/50), и:
   • если монета повернется орлом, предложите вариант \( A \);
   • если монета повернется решкой, предложите вариант \( B \).
3. Если число больше или равно \( \varepsilon \), предложите любой вариант, который до настоящего времени имел самую высокую интенсивность откликов.

Эпсилон (\( \varepsilon \)) — это единственный параметр, который управляет этим алгоритмом. Если \( \varepsilon = 1 \), то мы заканчиваем стандартным простым \( A/B \)-экспериментом (случайное распределение между \( A \) и \( B \) для каждого испытуемого). Если \( \varepsilon = 0 \), то мы за-