---
source_image: page_191.png
page_number: 191
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 57.32
tokens: 11842
characters: 2183
timestamp: 2025-12-24T06:14:22.700542
finish_reason: stop
---

Для понимания байесовской классификации можно начать с того, чтобы представить "не наивную" байесовскую классификацию. Для каждой записи, которая будет классифицирована:

1. Найти все остальные записи с одинаковым предикторным профилем (т. е. в которых значения предикторных переменных одинаковы).
2. Определить, к каким классам эти записи принадлежат и какой класс является преобладающим (т. е. вероятным).
3. Назначить этот класс новой записи.

Приведенный выше подход сводится к отысканию всех записей в выборке, которые выглядят в точности как новая классифицируемая запись в том смысле, что все значения предикторных переменных идентичны.

В стандартном наивном байесовском алгоритме предикторные переменные должны быть категориальными (факторными) переменными. См. разд. "Числовые предикторные переменные" далее в этой главе касательно двух обходных решений для использования непрерывных переменных.

Почему точная байесовская классификация непрактична?

Когда число предикторных переменных становится немалым, многие классифицируемые записи будут без точных совпадений. Это можно понять в контексте модели, которая предсказывает итоги голосования на основе демографических переменных. Даже внушительная выборка не будет содержать ни единого совпадения для новой записи с мужчиной латиноамериканцем с высоким доходом, из Среднего Запада США, который голосовал на последних выборах, не голосовал на предшествующих выборах, имеет трех дочерей и одного сына и разведен. И это всего восемь переменных — совсем небольшое число для большинства задач классификации. Добавление всего одной новой переменной с пятью одинаково частыми категориями уменьшает вероятность совпадения в 5 раз.

Несмотря на свое название, наивный байесовский алгоритм не считается методом байесовской статистики. Наивный байесовский алгоритм — это управляемый данными эмпирический метод, требующий относительно небольшой статистической компетенции. Название происходит от похожих на правило Байеса расчетов с целью формирования предсказаний — в частности, сначала вычисляются вероятности значений предикторных переменных при заданном исходе и далее выполняется заключительная калькуляция вероятностей исходов.