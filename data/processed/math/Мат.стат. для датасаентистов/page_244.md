---
source_image: page_244.png
page_number: 244
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 62.92
tokens: 11906
characters: 2317
timestamp: 2025-12-24T06:17:04.702119
finish_reason: stop
---

Ключевые идеи для древовидных моделей

• Деревья решений порождают набор правил классификации или предсказывают исход.
• Правила соответствуют последовательному разбиению данных на сегменты.
• Каждый сегмент, или разбиение, соотнесен с определенным значением предикторной переменной и делит данные на записи, где значение этого предиктора выше или ниже значения в точке разбиения.
• На каждом этапе древовидный алгоритм выбирает точку разбиения, которая минимизирует разнородность исхода в каждом подсегменте.
• Когда никакие дальнейшие разбиения сделать невозможно, дерево считается полностью выращенным, и каждый терминальный узел, или лист, имеет записи с единственным классом; новым случаям, которые следуют этим путем правил (разбиения), назначается этот класс.
• Полностью выращенное дерево переподогнано к данным и должно быть подрезано так, чтобы оно получало сигнал вместо шума.
• Алгоритмы множественных деревьев, такие как случайные леса и бустированные деревья, дают более хорошую предсказательную результативность, но теряют в основанной на правилах коммуникативной способности одиночных деревьев.

Дополнительные материалы для чтения

♦ "Полное учебное руководство по моделированию на основе деревьев с нуля на Python и R" (A Complete Tutorial on Tree Based Modeling from Scratch (in R & Python) // 2016. — April 12) от группы Analytics Vidya Content Team (https://www.analyticsvidhya.com/blog/2016/04/complete-tutorial-tree-based-modeling-scratch-in-python/).
♦ "Введение в рекурсивное сегментирование с использованием подпрограмм RPART" (Therneau T. M., Atkinson E. J. An Introduction to Recursive Partitioning Using the RPART Routines // Mayo Foundation. — 2015. — June 29) (https://cran.r-project.org/web/packages/rpart/vignettes/longintro.pdf).

Бэггинг и случайный лес

В 1907 г. статистик сэр Фрэнсис Гальтон (Francis Galton) посещал окружную ярмарку в Англии, на которой проводился конкурс по угадыванию убойного веса вола, демонстрируемого на выставке. Поступило 800 предположений, и, хотя отдельные предположения значительно варьировались, среднее и медиана вышли в пределах 1% от истинной массы вола. Джеймс Суровецки (James Suroweicki) исследовал этот феномен в своей книге "Мудрость толпы" (The Wisdom of Crowds. — Doubleday, 2004). Данный принцип также применяется к предсказательным моде-