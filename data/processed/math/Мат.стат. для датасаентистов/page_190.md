---
source_image: page_190.png
page_number: 190
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 62.69
tokens: 11890
characters: 2222
timestamp: 2025-12-24T06:14:27.842852
finish_reason: stop
---

Более двух категорий?

Подавляющее большинство задач сопряжено с бинарным откликом. Некоторые задачи классификации, однако, связаны с откликом из более чем двух возможных исходов. Например, по истечении срока действия клиентского договора подписки может быть три исхода: клиент покидает, или "переходит к другому поставщику" (\( Y = 2 \)), переводится на помесячный договор (\( Y = 1 \)) либо подписывает новый долгосрочный договор (\( Y = 0 \)). Цель состоит в том, чтобы предсказать \( Y = j \) для \( j = 0, 1 \) либо 2. Большинство методов классификации в данной главе могут применяться непосредственно либо со скромной адаптацией к откликам, которые имеют более двух исходов. Даже в случае более двух исходов задача часто может быть переработана в серию бинарных задач при помощи условных вероятностей. Например, чтобы предсказать исход договора, можно решить две задачи бинарного предсказания:

• предсказать, является ли \( Y = 0 \) или \( Y > 0 \);
• если дано \( Y > 0 \), предсказать, является ли \( Y = 1 \) или \( Y = 2 \).

В последнем случае имеет смысл разбить задачу на два случая: перейдет ли клиент к другому поставщику, и если он не перейдет, какой договор он выберет. С точки зрения подгонки модели часто выгодно трансформировать мультиклассовую задачу в серию бинарных задач. Это в особенности характерно, когда одна категория распространена намного больше, чем другие.

Наивный байесовский алгоритм

Наивный байесовский алгоритм использует вероятность наблюдать значения предикторных переменных при условии исхода с целью оценить вероятность наблюдать исход \( Y = i \) при условии набора значений предикторных переменных\(^{1}\).

Ключевые термины

Условная вероятность (conditional probability)

Вероятность наблюдать какое-то событие (скажем, \( X = i \)) при условии, что имеется какое-то другое событие (скажем, \( Y = i \)); записывается, как \( P(X_i | Y_i) \).

Апостериорная вероятность (posterior probability)

Вероятность исхода после того, как предикторная информация была учтена (в отличие от априорной вероятности исходов, которая ее не учитывает).

\footnotetext{1}{Этот и последующие разделы в настоящей главе используются с разрешения © 2017 Datastats, LLC, Питер Брюс и Эндрю Брюс.}