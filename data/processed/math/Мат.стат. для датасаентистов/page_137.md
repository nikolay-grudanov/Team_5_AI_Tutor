---
source_image: page_137.png
page_number: 137
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 74.08
tokens: 12038
characters: 2655
timestamp: 2025-12-24T06:12:02.735426
finish_reason: stop
---

канчиваем чисто жадным алгоритмом — он не стремится продолжать экспериментировать, просто относя испытуемых (посетителей веб-сайта) к наиболее результативному варианту.

Более сложный алгоритм использует "отбор образцов по методу Томпсона". Данная процедура "вынимает выборки" (нажимает пусковой рычаг бандита) на каждом этапе для максимизации вероятности выбора наилучшего рычага. Разумеется, вы не знаете, какой рычаг лучший — в этом-то и проблема! — но по мере того как вы наблюдаете за выплатой при каждой последующей выемке, вы получаете больше информации. В отборе образцов по методу Томпсона используется байесовский подход: первоначально принимается какое-то априорное распределение вознаграждений на основе так называемого бета-распределения (это общепринятый механизм для указания априорной информации в байесовской задаче). По мере накопления информации после каждой выемки может обновляться, давая возможность лучше оптимизировать следующую выемку с точки зрения выбора нужного рычага.

"Бандитские" алгоритмы способны эффективно обрабатывать три варианта и более и двигаться к оптимальному выбору "лучшего". Что касается традиционных статистических процедур тестирования, то сложность процесса выбора в бандитских алгоритмах относительно трех и более вариантов далеко превосходит традиционный A/B-тест, и тем самым преимущество "бандитских" алгоритмов гораздо выше.

<table>
  <tr>
    <th>Ключевые идеи для алгоритма многорукого бандита</th>
  </tr>
  <tr>
    <td>
      <ul>
        <li>Традиционные A/B-тесты предусматривают случайный процесс отбора, который может привести к чрезмерному показу худшего по качеству варианта.</li>
        <li>Многорукие бандиты, напротив, изменяют процесс отбора для включения информации, извлеченной во время эксперимента, и уменьшают частоту показа менее качественного варианта.</li>
        <li>Они также упрощают эффективную обработку более двух вариантов.</li>
        <li>Существуют разные алгоритмы, которые смещают вероятность отбора от менее качественного варианта к (предполагаемому) более качественному.</li>
      </ul>
    </td>
  </tr>
</table>

Дополнительные материалы для чтения

♦ Книга "Бандитские алгоритмы для веб-оптимизации" (White J. M. Bandit algorithms for website optimization: developing, deploying, and debugging.— O’Reilly, 2012) предлагает превосходное краткое изложение алгоритмов многоруких бандитов. Автор приводит примеры на Python, а также результаты имитационного моделирования для анализа результативности бандитов.

♦ По поводу дополнительных сведений об отборе образцов по методу Томпсона, см. работу "Анализ отбора образцов по методу Томпсона для задачи многоруко-