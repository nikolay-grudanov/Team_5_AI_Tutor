---
source_image: page_154.png
page_number: 154
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 59.10
tokens: 11885
characters: 2407
timestamp: 2025-12-24T06:12:36.951296
finish_reason: stop
---

щимися около 0) говорят о том, что предиктор должен быть сохранен в модели, в то время как очень низкие t-статистики указывают на то, что предиктор может быть отброшен. См. разд. "p-Значение" главы 3 для получения более подробной информации.

Перекрестная проверка

Классические статистические метрические показатели регрессии (R^2, F-статистики и p-значения) являются "внутривыборочными" показателями — они применяются к тем же данным, которые использовались для подгонки модели. На интуитивном уровне вы видите, что имеет большой смысл отложить немного исходных данных, не используя их для подгонки модели, и далее применить модель к зарезервированным (отложенным в сторону) данным, чтобы увидеть, как хорошо она справляется со своей работой. Обычно значительную часть данных вы будете использовать, чтобы выполнить подгонку модели, а оставшуюся часть — чтобы ее проверить.

Такая идея "вневыборочной" проверки не является новой, но она не утвердилась до тех пор, пока большие наборы данных не получили широкое распространение; имея в распоряжении небольшой набор данных, аналитики, как правило, хотят использовать все имеющиеся данные и на их основе выполнять подгонку лучшей модели.

Использование контрольной выборки с отложенными данными, тем не менее, ставит вас в зависимость от некоторой неопределенности, которая возникает просто из-за вариабельности в малой контрольной выборке. Насколько будут отличаться результаты диагностики модели, если взять другую контрольную выборку с отложенными данными?

Перекрестная проверка расширяет идею контрольной выборки с отложенными данными до множественных последовательных контрольных выборок. Алгоритм базовой k-блочной перекрестной проверки выглядит следующим образом:

1. Отложить 1/k данных в качестве контрольной выборки.
2. Натренировать модель на оставшихся данных.
3. Применить модель к контрольной выборке 1/k (оценить результаты) и записать необходимые метрические показатели диагностики модели.
4. Восстановить первые 1/k данных и отложить следующее 1/k (исключая любые записи, которые были выбраны в первый раз).
5. Повторить шаги 2 и 3.
6. Повторять, пока каждая запись не будет использована в процентной доле, предназначенной для контрольной выборки.
7. Усреднить или же скомбинировать метрические показатели диагностики модели.

Подразделение данных на тренировочную выборку и контрольную выборку также называется разделением на блоки (fold).