---
source_image: page_256.png
page_number: 256
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 63.82
tokens: 11952
characters: 2380
timestamp: 2025-12-24T06:17:49.692725
finish_reason: stop
---

Результат показан на рис. 6.9. В качественном плане он аналогичен предсказаниям из случайного леса (см. рис. 6.7). Предсказания несколько шумные в том, что некоторые заемщики с очень высокой балльной оценкой заемщика по-прежнему получают предсказание невозврата ссуды.

Регуляризация: предотвращение переподгонки

Слепое применение xgboost может привести к нестабильным моделям в результате переподгонки к тренировочным данным. Проблема с переподгонкой имеет две составляющие:

♦ точность модели на новых данных не из тренировочного набора ухудшится;
♦ получаемые из модели предсказания весьма вариабельны, что приводит к нестабильным результатам.

Любой прием моделирования потенциально подвержен переподгонке. Например, если слишком много переменных включены в уравнение регрессии, то в конечном итоге модель может прийти к нимым предсказаниям. Однако в отношении большинства статистических приемов переподгонку можно предотвратить разумным выбором предикторных переменных. Даже случайный лес обычно порождает разумную модель без настройки параметров. Это, однако, не относится к xgboost. Выполним подгонку xgboost к данным о ссудах для тренировочного набора со всеми включенными в модель переменными:

> predictors <- data.matrix(loan_data[,which(names(loan_data) %in% 'outcome')])
> label <- as.numeric(loan_data$outcome)-1
> test_idx <- sample(nrow(loan_data), 10000)
> xgb_default <- xgboost(data=predictors[-test_idx,],
    label=label[-test_idx],
    objective = "binary:logistic", nrounds=250)
> pred_default <- predict(xgb_default, predictors[test_idx,])
> error_default <- abs(label[test_idx] - pred_default) > 0.5
> xgb_default$evaluation_log[250,]
iter train_error
1: 250 0.145622
> mean(error_default)
[1] 0.3715

Проверочный набор состоит из 10 000 в произвольном порядке отобранных записей из полных данных, а тренировочный набор — из оставшихся записей. Бустинг приводит к коэффициенту ошибок, равному всего 14,6% для тренировочного набора. Проверочный набор, однако, имеет намного более высокий коэффициент ошибок — 36,2%. Это является результатом переподгонки: в то время как бустинг способен очень хорошо объяснить вариабельность в тренировочном наборе, правила предсказания не применимы к новым данным.

Бустинг предоставляет несколько параметров для предотвращения переподгонки, в том числе параметры eta и subsample (см. разд. "XGBoost" ранее в этой главе).