---
source_image: page_196.png
page_number: 196
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 81.69
tokens: 12075
characters: 2573
timestamp: 2025-12-24T06:15:03.121991
finish_reason: stop
---

Ковариационная матрица

Для понимания дискриминантного анализа сначала необходимо ввести понятие ковариации между двумя или несколькими переменными. Ковариация измеряет связь между двумя переменными x и z. Обозначим среднее каждой переменной как \( \overline{x} \) и \( \overline{z} \) (см. разд. "Среднее" главы 1). Ковариация \( s_{x,z} \) между x и z задается следующей формулой:

\[
s_{x,z} = \frac{\sum_{i=1}^{n} (x_i - \overline{x})(z_i - \overline{z})}{n-1},
\]

где n — это число записей (отметим, что мы делим на \( n-1 \) вместо \( n \): см. врезку "Степени свободы и n или n – 1?" главы 1).

Как и с коэффициентом корреляции (см. разд. "Корреляция" главы 1), положительные значения говорят о положительной связи, а отрицательные значения — об обратной. Корреляция, однако, ограничена значениями между –1 и 1, тогда как ковариация находится на той же шкале измерения, что и переменные x и z. Ковариационная матрица \( \Sigma \) для x и z состоит из дисперсий индивидуальных переменных \( s_x^2 \) и \( s_z^2 \) на диагонали (где строка и столбец — это одинаковая переменная) и ковариаций между парами переменных, стоящих вне диагоналей.

\[
\hat{\Sigma} = \begin{bmatrix}
s_x^2 & s_{x,z} \\
s_{x,z} & s_z^2
\end{bmatrix}.
\]

Вспомним, что стандартное отклонение применяется для нормализации переменной в стандартизированную оценку (z-меру); ковариационная матрица используется в многомерном расширении этого процесса стандартизации. Такое расширение известно как расстояние Махаланобиса (см. примечание "Другие метрические показатели расстояния" главы 6) и связано с функцией LDA.

Линейный дискримinant Фишера

Для простоты сосредоточимся на задаче классификации, в которой мы хотим предсказать бинарный результат y при помощи всего двух непрерывных числовых переменных (x, z). В техническом плане дискриминантный анализ предполагает, что предикторные переменные представляют собой нормально распределенные непрерывные величины, но на практике метод работает хорошо даже на непредельных отклонениях от нормальности, а также для бинарных предикторов. Линейный дискримinant Фишера различает, с одной стороны, вариацию между группами и, с другой, вариацию внутри групп. В частности, стремясь разделить записи на две группы, LDA фокусируется на максимизации "между" суммой квадратов \( SS_{\text{между}} \) (измеряя вариацию между этими двумя группами) относительно "внутригрупповой" суммы квадратов \( SS_{\text{внутри}} \) (измеряющей внутригрупповую вариацию). В этом случае эти две группы соответствуют записям \( (x_0, z_0) \), для которых \( y = 0 \), и запи-