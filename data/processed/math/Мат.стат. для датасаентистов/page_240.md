---
source_image: page_240.png
page_number: 240
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 81.20
tokens: 12077
characters: 2449
timestamp: 2025-12-24T06:17:12.939278
finish_reason: stop
---

В дополнение к бинарному предсказанию в формате 0/1, древовидные модели могут производить оценку вероятности, основанную на количестве нулей и единиц в сегменте. Оценкой является простая сумма нулей или единиц в сегменте, деленная на число наблюдений в сегменте.

\[
\operatorname{Prob}(Y = 1) = \frac{\text{Число единиц в сегменте}}{\text{Размер сегмента}}
\]

Затем оценочная вероятность \( \operatorname{Prob}(Y = 1) \) может быть конвертирована в бинарное решение; например, оценка устанавливается в 1, если \( \operatorname{Prob}(Y = 1) > 0,5 \).

Измерение однородности или разнородности

Древовидные модели рекурсивно создают сегменты (наборы записей) \( A \), которые предсказывают исход \( Y = 0 \) или \( Y = 1 \). Из предыдущего алгоритма видно, что нам нужен способ измерить однородность, так называемую чистоту класса, в сегменте. Или, что то же самое, нам нужно измерить разнородность сегмента. Точность предсказаний — это доля \( p \) неправильно классифицированных записей внутри этого сегмента, которая колеблется от 0 (идеально) до 0,5 (чисто случайное угадывание).

Оказывается, что точность не является хорошей мерой разнородности. Вместо нее общеприняты две другие меры разнородности — коэффициент разнородности Джини и энтропия, или информация. В то время как эти (и другие) меры разнородности применяются к задачам классификации с более чем двумя классами, мы сосредоточимся на бинарном случае. Коэффициент разнородности Джини для набора записей \( A \) имеет вид:

\[
I(A) = p(1 - p).
\]

Энтропийная мера задается следующей формулой:

\[
I(A) = -p \log_2(p) - (1 - p) \log_2(1 - p).
\]

На рис. 6.5 показано, что мера разнородности Джини (перешкалированная) и мера энтропии схожи, при этом энтропия дает более высокие оценки разнородности для умеренных и высоких уровней точности.

Коэффициент Джини
Разнородность Джини не следует путать с коэффициентом Джини. Эти два показателя представляют схожие понятия, но разнородность Джини ограничена задачей бинарной классификации и связана с метрическим показателем AUC (см. разд. "Метрический показатель AUC" главы 5).

Метрический показатель разнородности используется в описанном ранее алгоритме сегментирования. По каждому предлагаемому разбиению данных разнородность вычисляется для каждого сегмента, который получается в результате разбиения. Затем вычисляется взвешенное среднее, и (на каждом этапе) выбирается любой сегмент, который выдает самое низкое взвешенное среднее.