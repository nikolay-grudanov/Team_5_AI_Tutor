---
source_image: page_242.png
page_number: 242
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 72.79
tokens: 11993
characters: 2640
timestamp: 2025-12-24T06:17:05.151201
finish_reason: stop
---

Нам нужен какой-нибудь способ определения, когда следует прекратить выращивание дерева на этапе, который будет обобщать выводы на новые данные. Существует два общепринятых способа прекратить разбиение данных.

♦ Не допускать разбиение сегмента, если результирующий подсегмент либо терминальный лист слишком мал. В rpart эти ограничения контролируются отдельно соответственно параметрами minsplit и minbucket со значениями по умолчанию 20 и 7.

♦ Не разбивать сегмент, если только новый сегмент "значительно" не уменьшает разнородность. В rpart это контролируется параметром сложности ср, т. е. мерой того, насколько сложным дерево является — чем сложнее, тем больше значение ср. На практике ср используется для ограничения роста дерева путем наложения штрафа на дополнительную сложность (дополнительные разбиения) в дереве.

Первый метод предполагает произвольные правила и может быть полезным для работы на этапе разведочного анализа, но мы не можем с легкостью определить оптимальные значения (т. е. значения, которые максимизируют предсказательную точность с новыми данными). При помощи параметра сложности ср мы можем оценить, какой размер дерева будет давать наилучшую результативность с новыми данными.

Если параметр сложности ср окажется слишком малым, то дерево будет переподогнано к данным, приспосабливаясь к шуму, а не к сигналу. С другой стороны, если ср будет слишком большим, то дерево окажется слишком малым и будет иметь малую предсказательную силу. В rpart значение по умолчанию равно 0,01, хотя в случае больших наборов данных вы, вероятно, обнаружите, что оно слишком большое. В предыдущем примере ср был установлен в 0,005, поскольку значение по умолчанию привело к дереву с единственным разбиением. В разведочном анализе достаточно просто испытать несколько значений.

Определение оптимального параметра ср является примером компромисса между смещением и дисперсией (см. примечание "Компромисс между смещением и дисперсией" в разд. "Выбор K" ранее в этой главе). Самый общепринятый способ вычислить приближенную оценку подходящего значения параметра ср лежит через перекрестную проверку (см. разд. "Перекрестная проверка" главы 4):

1. Разделить данные на тренировочный и проверочный (контрольная выборка с отложенными данными) наборы.
2. Вырастить дерево с тренировочными данными.
3. Подрезать его последовательно, шаг за шагом, на каждом шаге записывая ср (используя тренировочные данные).
4. Отметить ср, который соответствует минимальной ошибке (потере) на проверочных данных.
5. Повторно разделить данные на тренировочный и проверочный наборы и повторить процесс выращивания дерева, подрезания ветвей и записи ср.