---
source_image: page_192.png
page_number: 192
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 77.79
tokens: 12032
characters: 2344
timestamp: 2025-12-24T06:14:43.614781
finish_reason: stop
---

Наивное решение

В наивном байесовском решении мы больше не ограничиваем вычисление вероятности теми записями, которые совпадают с классифицируемой записью. Вместо этого мы используем весь набор данных. Наивная байесовская модификация имеет следующий вид:

1. Относительно бинарного отклика \( Y = i \) (\( i = 0 \) либо 1) оценить индивидуальные условные вероятности для каждого предиктора \( P(X_j | Y = i) \); речь идет о вероятностях, что значение предиктора находится в записи, когда мы наблюдаем \( Y = i \). Данная вероятность оценивается долей значений \( X_j \) среди записей \( Y = i \) в тренировочном наборе.

2. Перемножить эти вероятности друг с другом, а затем на долю записей, которые принадлежат \( Y = i \).

3. Повторить шаги 1 и 2 для всех классов.

4. Оценить вероятность для исхода \( i \), взяв значение, вычисленное на шаге 2 для класса \( i \), и поделив его на сумму таких значений для всех классов.

5. Отнести запись к классу с самой высокой вероятностью для этого набора значений предикторов.

Данный наивный байесовский алгоритм можно также записать в виде уравнения вероятности наблюдать исход \( Y = i \) при условии, что имеется набор значений предикторов \( X_1, ..., X_p \):

\[
P\left(X_1, X_2, ..., X_p\right).
\]

Значение \( P\left(X_1, X_2, ..., X_p\right) \) — это поправочный коэффициент, который гарантирует, что вероятность находится между 0 и 1 и не зависит от \( Y \):

\[
\begin{align*}
P\left(X_1, X_2, ..., X_p\right) &= \\
&= P(Y = 0)\left(P(X_1 | Y = 0)P(X_2 | Y = 0) \cdots P(X_p | Y = 0)\right) + \\
&+ P(Y = 1)\left(P(X_1 | Y = 1)P(X_2 | Y = 1) \cdots P(X_p | Y = 1)\right).
\end{align*}
\]

Почему эта формула называется "наивной"? Дело в том, что мы приняли упрощающее допущение, что точная условная вероятность вектора значений предикторов в условиях наблюдаемого исхода достаточно хорошо оценивается произведением индивидуальных условных вероятностей \( P\left(X_j | Y = i\right) \). Другими словами, в оценке \( P\left(X_j | Y = i\right) \) вместо \( P\left(X_1, X_2, ..., X_p | Y = i\right) \) мы принимаем, что \( X_j \) независима от всех остальных предикторных переменных \( X_k \) для \( k \neq j \).

В R для оценки наивной байесовской модели могут использоваться несколько программных пакетов. Представленный далее фрагмент кода выполняет подгонку модели при помощи пакета klaR: