---
source_image: page_037.png
page_number: 37
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 85.46
tokens: 12314
characters: 5166
timestamp: 2025-12-24T05:46:53.892820
finish_reason: stop
---

**b_{k1}, b_{k2}, ..., b_{kn}**. Таким образом, определители (1.40) равны в силу следствия 5 из п. 3.

В заключение заметим, что непосредственно из формулы (1.37) вытекает, что определитель прямой суммы \( |A \oplus B| = \begin{vmatrix} A & O \\ O & B \end{vmatrix} \) двух матриц \( A \) и \( B \) равен произведению определителей этих матриц.

7. Понятие обратной матрицы. Пусть \( A \) — квадратная матрица \( n \)-го порядка, а \( E \) — единичная квадратная матрица того же порядка (см. п. 2 § 1).

Матрица \( B \) называется правой обратной по отношению к матрице \( A \), если \( AB = E \).

Матрица \( C \) называется левой обратной по отношению к матрице \( A \), если \( CA = E \).

Так как обе матрицы \( A \) и \( E \) являются квадратными матрицами порядка \( n \), то матрицы \( B \) и \( C \) (при условии, что они существуют) также являются квадратными матрицами порядка \( n \).

Убедимся в том, что если обе матрицы \( B \) и \( C \) существуют, то они совпадают между собой. В самом деле, на основании равенств (1.7) (см. п. 2 § 1), соотношений \( AB = E, CA = E \) и сочетательного свойства произведения матриц, получим

\[
C = CE = C(AB) = (CA)B = EB = B.
\]

Естественно возникает вопрос об условиях на матрицу \( A \), при выполнении которых для этой матрицы существуют как левая, так и правая обратные матрицы *).

Теорема 1.4. Для того чтобы для матрицы \( A \) существовали левая и правая обратные матрицы, необходимо и достаточно, чтобы определитель \( \det A \) матрицы \( A \) был отличен от нуля.

Доказательство. 1) Необходимость. Если для матрицы \( A \) существует хотя бы одна из обратных матриц, например \( B \), то из соотношения \( A \cdot B = E \) мы получим, что \( \det A \cdot \det B = \det E = 1 ** \), откуда вытекает, что \( \det A \neq 0 \).

2) Достаточность. Пусть определитель \( \Delta = \det A \) отличен от нуля. Обозначим, как и выше, символом \( A_{ij} \) алгебраические дополнения элементов \( a_{ij} \) матрицы \( A \) и составим матрицу \( B \), в \( i \)-й строке которой стоят алгебраические дополнения \( i \)-го столбца матрицы \( A \), поделенные на величину определителя \( \Delta \):

\[
B = \begin{vmatrix}
\frac{A_{11}}{\Delta} & \frac{A_{21}}{\Delta} & \ldots & \frac{A_{n1}}{\Delta} \\
\frac{A_{12}}{\Delta} & \frac{A_{22}}{\Delta} & \ldots & \frac{A_{n2}}{\Delta} \\
\ldots & \ldots & \ldots & \ldots \\
\frac{A_{1n}}{\Delta} & \frac{A_{2n}}{\Delta} & \ldots & \frac{A_{nn}}{\Delta}
\end{vmatrix}.
\] (1.41)

*) И, стало быть, эти матрицы совпадают.
**) \( \det E = 1 \) в силу примера 2 из п. 5 этого параграфа.

§ 3] ТЕОРЕМА О БАЗИСНОМ МИНОРЕ МАТРИЦЫ

Убедимся в том, что эта матрица \( B \) является как правой, так и левой обратной по отношению к матрице \( A \).

Достаточно доказать, что оба произведения \( AB \) и \( BA \) являются единичной матрицей. Для этого достаточно заметить, что у обоих произведений любой элемент, не лежащий на главной диагонали, равен нулю, ибо после выноса множителя \( 1/\Delta \) этот элемент равен сумме произведений элементов одной строки (или одного столбца) на соответствующие алгебраические дополнения другой строки (или другого столбца). Что же касается элементов, лежащих на главной диагонали, то у обоих произведений \( AB \) и \( BA \) все такие элементы равны единице в силу того, что сумма произведений элементов и соответствующих алгебраических дополнений одной строки (одного столбца) равна определителю. Теорема доказана.

Замечание 1. Квадратную матрицу \( A \), определитель \( \det A \) которой отличен от нуля, принято называть невырожденной.

Замечание 2. Впредь мы можем опускать термины «левая» и «правая» и говорить просто о матрице \( B \), обратной по отношению к невырожденной матрице \( A \) и определяемой соотношениями \( AB = BA = E \). Очевидно также, что свойство быть обратной матрицей взаимно в том смысле, что если \( B \) является обратной для \( A \), то \( A \) является обратной для \( B \). Матрицу, обратную к матрице \( A \), впредь мы будем обозначать символом \( A^{-1} \).

§ 3. Теорема о базисном миноре матрицы

1. Понятие линейной зависимости строк. Выше мы уже договорились называть строку *) \( A = (a_1, a_2, ..., a_n) \) линейной комбинацией строк \( B = (b_1, b_2, ..., b_n), ..., C = (c_1, c_2, ..., c_n) \), если для некоторых вещественных чисел \( \lambda, ..., \mu \) справедливы равенства

\[
a_j = \lambda b_j + ... + \mu c_j \quad (j = 1, 2, ..., n).
\] (1.42)

Указанные \( n \) равенств (1.42) удобно записать в виде одного равенства

\[
A = \lambda B + ... + \mu C.
\] (1.43)

Всякий раз, когда будет встречаться равенство (1.43), мы будем понимать его в смысле \( n \) равенств (1.42).

Введем теперь понятие линейной зависимости строк.

Определение. Строки \( A = (a_1, a_2, ..., a_n), B = (b_1, b_2, ..., b_n), ..., C = (c_1, c_2, ..., c_n) \) назовем линейно зависимыми, если найдутся такие числа \( \alpha, \beta, ..., \gamma \), не все равные нулю, что справедливы равенства

\[
\alpha a_j + \beta b_j + ... + \gamma c_j = 0 \quad (j = 1, 2, ..., n).
\] (1.44)

*) Каждую строку можно рассматривать как матрицу. Поэтому естественно использовать для обозначения строк большие латинские буквы.