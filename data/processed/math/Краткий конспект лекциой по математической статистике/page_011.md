---
source_image: page_011.png
page_number: 11
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 110.35
tokens: 12715
characters: 3929
timestamp: 2025-12-24T07:03:28.098439
finish_reason: stop
---

2 ТОЧЕЧНОЕ ОЦЕНИВАНИЕ

2.1 Параметрические семейства распределений

Рассматривается следующая задача. Имеется выборка объема \( n \), элементы которой \( X_1, \ldots, X_n \) независимы, одинаково распределены и имеют «известное» распределение \( \mathcal{F}_\theta \) с некоторым неизвестным скалярным или векторным параметром \( \theta \). Пусть параметр \( \theta \) принимает значения из некоторого множества \( \Theta \subseteq \mathbb{R}^k \). Мы будем считать, что в классе распределений \( \{ \mathcal{F}_\theta, \theta \in \Theta \} \) каждое распределение целиком определяется значением параметра \( \theta \). То есть равенство \( \theta_1 = \theta_2 \) влечет равенство \( \mathcal{F}_{\theta_1} = \mathcal{F}_{\theta_2} \).

Например, рассматривается задача следующего вида: для всех \( i = 1, \ldots, n \)

• знаем: \( X_i \in \Pi_\lambda \), где \( \lambda > 0 \); не знаем: \( \lambda \);
  здесь \( \mathcal{F}_\theta = \Pi_\lambda, \theta = \lambda, \Theta = (0, \infty) \);

• знаем: \( X_i \in \Pi_\lambda \), где \( \lambda \in (3, 5) \); не знаем: \( \lambda \);
  здесь \( \mathcal{F}_\theta = \Pi_\lambda, \theta = \lambda, \Theta = (3, 5) \);

• знаем: \( X_i \in \mathrm{B}_p \), где \( p \in (0, 1) \); не знаем: \( p \);
  здесь \( \mathcal{F}_\theta = \mathrm{B}_p, \theta = p, \Theta = (0, 1) \);

• знаем: \( X_i \in \mathrm{U}_{a,b} \), где \( a < b \); не знаем: \( a, b \);
  здесь \( \mathcal{F}_\theta = \mathrm{U}_{a,b}, \theta = \{a, b\}, \Theta = \{ \{a, b\} : a < b \} \);
  или одно знаем, другое — нет, например:

• знаем: \( X_i \in \mathrm{U}_{0,\theta} \), где \( \theta > 0 \); не знаем: \( \theta \)
  здесь \( \mathcal{F}_\theta = \mathrm{U}_{0,\theta}, \Theta = (0, \infty) \);

• знаем: \( X_i \in \mathrm{N}_{a,\sigma^2} \), где \( a \in \mathbb{R}, \sigma > 0 \); не знаем: \( a, \sigma^2 \)
  здесь \( \mathcal{F}_\theta = \mathrm{N}_{a,\sigma^2}, \theta = \{a, \sigma^2\}, \Theta = \mathbb{R} \times (0, \infty) \);
  (или одно знаем, другое — нет).

Такая постановка имеет смысл, поскольку редко о проводимом эксперименте совсем ничего нельзя сказать. Обычно тип распределения ясен заранее, и требуется лишь указать значения параметров этого распределения.

Так, в широких предположениях рост юношей одного возраста имеет нормальное распределение (с неизвестными средним и дисперсией), а число покупателей в магазине в течение часа (не часа пик) — распределение Пуассона, и опять-таки с неизвестной «интенсивностью» \( \lambda \).

2.2 Точечные оценки. Несмешенность, состоятельность оценок

Итак, пусть \( X_1, \ldots, X_n \) — выборка объема \( n \) из параметрического семейства распределений \( \mathcal{F}_\theta, \theta \in \Theta \).
Заметим, что все характеристики случайных величин \( X_1, \ldots, X_n \) зависят от параметра \( \theta \). Так, например, для \( X_i \in \Pi_\lambda \):

\[
\mathbf{E}X_1 = \lambda, \quad \mathbf{P}(X_1 = 2) = \frac{\lambda^2}{2} e^{-\lambda}, \quad \mathbf{D}X_1 = \lambda \quad \text{и т.д.}
\]

Чтобы отразить эту зависимость, будем писать \( \mathbf{E}_\theta X_1 \) вместо \( \mathbf{E}X_1 \) и т.д. Так, \( \mathbf{D}_{\theta_1} X_1 \) означает дисперсию, вычисленную в предположении \( \theta = \theta_1 \).

Упражнение. Пусть \( X_1 \in \mathrm{B}_p, p_1 = 0,5, p_2 = 0,1 \). Вычислить \( \mathbf{E}_{p_1} X_1, \mathbf{E}_{p_2} X_1 \).

Определение 2. Статистикой называется любая (измеримая!) функция \( \theta^* = \theta^*(X_1, \ldots, X_n) \).

Замечание 6. Статистика есть функция от эмпирических данных, т.е. от выборки \( X_1, \ldots, X_n \), но никак не от параметра \( \theta \). Статистика, как правило, предназначена именно для оценивания неизвестного параметра \( \theta \) (в этом случае ее называют «оценкой»), и уже поэтому от него зависеть не должна.
Вообще говоря, статистика есть не «любая», а «измеримая» функция от выборки, но поскольку на практике иного не бывает :), мы на это обращать внимание не будем.