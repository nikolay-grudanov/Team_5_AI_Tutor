---
source_image: page_024.png
page_number: 24
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 80.66
tokens: 12559
characters: 3289
timestamp: 2025-12-24T07:04:02.318371
finish_reason: stop
---

По теореме 9, оценка \( \theta_k^* \) — АНО для \( \theta \) с коэффициентом

\[
\sigma_k^2(\theta) = (H'(a))^2 D_{\theta} g(X_1) = \frac{1}{k^2} \theta^{2-2k} \cdot \frac{k^2}{2k+1} \theta^{2k} = \frac{\theta^2}{2k+1}.
\]

В том числе для \( \theta_1^* = 2 \overline{X} \) имеем коэффициент \( \sigma_1^2(\theta) = \frac{\theta^2}{3} \) (см. пример 11).

Осталось понять, при чем тут сравнение оценок и что показывает коэффициент асимптотической нормальности.

**3.8 Асимптотический подход к сравнению оценок**

Возьмем две случайные величины: \( \xi \in N_{0,1} \) и \( 10 \xi \in N_{0,100} \). Если для \( \xi \), например, \( 0,997 = P(|\xi| < 3) \), то для \( 10 \xi \) уже \( 0,997 = P(|\xi| < 30) \). Разброс значений величины \( 10 \xi \) гораздо больший, и дисперсия (показатель рассеяния) соответственно больше.

Что показывает коэффициент асимптотической нормальности? Возьмем две АНО с коэффициентами 1 и 100:

\[
\sqrt{n}(\theta_1^* - \theta^*) \Rightarrow N_{0,1} \quad \text{и} \quad \sqrt{n}(\theta_2^* - \theta^*) \Rightarrow N_{0,100}.
\]

При больших \( n \) разброс значений величины \( \sqrt{n}(\theta_2^* - \theta^*) \) около нуля гораздо больше, чем у величины \( \sqrt{n}(\theta_1^* - \theta^*) \), поскольку больше предельная дисперсия (она же коэффициент асимптотической нормальности).

Но чем меньше отклонение оценки от параметра, тем лучше. Отсюда — естественный способ сравнения асимптотически нормальных оценок:

**Определение 12.** Пусть \( \theta_1^* \) — АНО с коэффициентом \( \sigma_1^2(\theta) \), \( \theta_2^* \) — АНО с коэффициентом \( \sigma_2^2(\theta) \). Говорят, что \( \theta_1^* \) *лучше*, чем \( \theta_2^* \) в смысле асимптотического подхода, если для любого \( \theta \in \Theta \)

\[
\sigma_1^2(\theta) \leq \sigma_2^2(\theta),
\]

и хотя бы при одном \( \theta \) это неравенство строгое.

Пример 12 (продолжение). Сравним между собой оценки в последовательности \( \theta_1^*, \theta_2^*, \ldots \). Для \( \theta_k^* \) коэффициент асимптотической нормальности имеет вид

\[
\sigma_k^2(\theta) = \frac{\theta^2}{2k+1} \to 0 \quad \text{при} \ k \to \infty.
\]

Коэффициент тем меньше, чем больше \( k \), то есть каждая следующая оценка в этой последовательности лучше предыдущей.

Оценка \( \theta_\infty^* \), являющаяся «последней», могла бы быть лучше всех оценок в этой последовательности в смысле асимптотического подхода, если бы являлась асимптотически нормальной. Увы:

**Упражнение.** (См. задачу 8 к главе 1). Доказать, что \( \theta_k^* \to X_{(n)} \) (поточечно), то есть для любого элементарного исхода \( \omega \) при \( k \to \infty \)

\[
\sqrt[k]{(k+1) \frac{\sum_1^n X_i^k(\omega)}{n}} \to \max\{X_1(\omega), \ldots, X_n(\omega)\}.
\]

**Упражнение.*** Можно ли придать некий смысл фразе: «оценка \( \hat{\theta} = X_{(n)} \) асимптотически нормальна с коэффициентом 0»? Какой? И зачем?

**3.9 Вопросы и упражнения**

1. Задачник [1], задачи 7.5, 4.4 — 4.7, 4.9.

2. Пусть \( X_1, \ldots, X_n \) — выборка объема \( n \) из равномерного распределения \( U_{\theta, \theta+5} \), где \( \theta \in \mathbb{R} \). Сравнить оценки \( \hat{\theta}_0 = X_{(n)} - 5, \hat{\theta}_1 = X_{(1)} \) (см. пример 9) в среднеквадратичном. Сравнить с этими оценками оценку метода моментов \( \theta^* = \overline{X} - 2,5 \).