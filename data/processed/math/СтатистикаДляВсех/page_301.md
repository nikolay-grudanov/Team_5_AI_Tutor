---
source_image: page_301.png
page_number: 301
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 32.21
tokens: 6678
characters: 3009
timestamp: 2025-12-24T07:59:35.951325
finish_reason: stop
---

поскольку такая ситуация может привести к очень большим стандартным ошибкам оценок и, соответственно, широким доверительным интервалам. Чтобы увидеть, как может выглядеть полное разделение, посмотрите на гипотетические данные, представленные в табл. 11.3.

Таблица 11.3. Гипотетические данные с полным разделением

<table>
  <tr>
    <th rowspan="2">Страховка</th>
    <th colspan="2">Пол</th>
  </tr>
  <tr>
    <th>Женщины</th>
    <th>Мужчины</th>
  </tr>
  <tr>
    <td>Отсутствует</td>
    <td>62</td>
    <td>0</td>
  </tr>
  <tr>
    <td>Имеется</td>
    <td>234</td>
    <td>167</td>
  </tr>
</table>

В данном примере все те, у кого нет страховки, женского пола. Таким образом, если мы знаем, что у кого-то нет страховки, мы сразу же знаем, что это женщина; вот что подразумевается под полным разделением. На практике полное разделение чаще встречается с категориальными независимыми переменными (предположите, что мы также включили в модель такие переменные, как работа, семейное положение и образованность), если некоторые из них неравномерно распределены по отдельным категориям. Модель логистической регрессии не сработает в случае, если имеется полное разделение, так что лучше всего попробовать перекодировать переменную. Если у семейного положения есть шесть категорий (женат/замужем, вдовец/вдова, в разводе, холост/не замужем, проживание с партнером того же пола, проживание с партнером противоположного пола), возможно, вам удастся так их объединить, чтобы получилось 2–3 категории, в каждую из которых попадает достаточно испытуемых, чтобы избежать проблемы разделения. Разумеется, вы должны уметь защитить свой выбор объединяемых категорий. К примеру, если в вашем случае важно только то, женат/замужем испытуемый(ая) или нет, вы вольны перекодировать данную переменную для отражения этого факта. Даже если у вас в данных нет полного разделения, правильно избегать переменных с очень малым числом испытуемых в определенных категориях, поскольку, как говорилось ранее, в таких ситуациях доверительные интервалы оценок будут чрезвычайно широкими.

Проверив выполнение всех условий, мы продолжаем наш анализ. В логистической регрессии качество модели в целом определяется несколькими способами. Во-первых, существует критерий для коэффициентов модели, проверяющий, лучше ли наша модель в целом, чем нулевая модель без коэффициентов (omnibus test); модель проходит этот тест со статистикой хи-квадрат (2 степени свободы), равной 16,686 (\( p < 0,001 \)). Кроме того, мы рассчитываем три других показателя качества модели: –2 логарифма правдоподобия, \( R^2 \) Кокса и Снелла (the Cox&Snell \( R^2 \)) и \( R^2 \) Нагелкерке (the Nagelkerke \( R^2 \)). Показатель –2 логарифма правдоподобия в чем-то аналогичен сумме квадратов остатков в линейной регрессии. Сложно интерпретировать его значение само по себе, но он полезен при сравнении двух и более вложенных моделей (моделей, в которых большая из них включает все независимые переменные из меньшей), поскольку чем меньше значение –2 логариф-