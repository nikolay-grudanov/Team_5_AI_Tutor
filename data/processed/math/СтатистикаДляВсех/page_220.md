---
source_image: page_220.png
page_number: 220
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 36.86
tokens: 6626
characters: 2844
timestamp: 2025-12-24T07:57:39.747240
finish_reason: stop
---

В данном случае коэффициент корреляции (r) и коэффициент детерминации (r^2) между ростом и массой тела равны соответственно 0,47 и 0,22. Это значит, что около 22% дисперсии массы тела может быть связано с ростом, совсем не идеальное предсказание или объяснение, но значительно более хорошее, чем 0. Уравнение регрессии для этих данных таково:

\[
y = 91x - 74.
\]

Коэффициент наклона равен 91, константа — 74. Для нахождения предсказываемого значения массы тела человека подставьте вместо x его рост в метрах, и останется только произвести вычисления. Это уравнение предсказывает, что человек с ростом 1,8 метра будет иметь массу тела 89,8 кг, потому что:

\[
y = 91(1,8) - 74 = 89,8.
\]

Разумеется, если бы мы по-настоящему хотели предсказывать массу тела, мы бы разработали более сложную модель, включающую такие факторы, как пол и возраст, но этот пример служит хорошей иллюстрацией основных принципов простой регрессии. Вы могли заметить, что хотя корреляция не требует указывать, какая переменная является независимой, а какая от нее зависит, вам приходится делать такой выбор при работе с регрессией. Я назначила массу тела зависимой переменной, а рост — независимой, что осмысленно, потому что рост у взрослого человека постоянен и может рассматриваться как причинный фактор для массы тела. (При прочих равных, включая телосложение, высокие люди в целом весят больше, чем низкие.) Не думаю, что я могла бы как-то защитить позицию о первичности массы тела по отношению к росту.

Можно посчитать линию регрессии вручную (я делала это в аспирантуре, а до тех пор, пока компьютеры не получили широкого распространения, все делали это таким образом), но гораздо чаще для этих расчетов используют статистические программы. Регрессия — это очень часто встречающаяся процедура, и практически любой статистический пакет, который вы можете использовать, вероятно, будет включать в себя возможности по расчету регрессии. Для тех же, кто захочет рассчитать параметры регрессии вручную, в конце данной главы приведен решённый пример.

Даже если вы не планируете проводить регрессию вручную, стоит ближе познакомиться с логикой этого процесса. Когда статистический пакет выдает линию регрессии для набора данных, он подбирает уравнение, соответствующее линии, максимально близкой ко всем точкам одновременно. Это часто описывают как минимизацию квадратов отклонений, где квадраты отклонений — это суммы квадратов отклонений между каждой точкой данных и линией регрессии5. Это легко проиллюстрировать на примере простой регрессии, потому что тут участвуют только два измерения (независимая и зависимая переменные); тот же принцип применим и к более сложным моделям (с большим число переменных), но в этом случае его сложнее проиллюстрировать из-за большего числа измерений.

5 По-русски обычно это называют «методом наименьших квадратов» — Прим. пер.