---
source_image: page_302.png
page_number: 302
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 42.10
tokens: 7032
characters: 3400
timestamp: 2025-12-24T07:59:47.843450
finish_reason: stop
---

Логистическая регрессия

мов правдоподобия, тем лучше модель. Мы не можем рассчитать R Пирсона или \( R^2 \) для логистической регрессии, но существуют две статистики вместо этой величины: \( R^2 \) Кокса и Снелла и \( R^2 \) Нагелкерке. Обе основаны на сравнении логарифма правдоподобия нашей модели и нулевой модели; поскольку максимум \( R^2 \) Кокса и Снелла никогда не достигает теоретического максимального значения, равного 1,0, \( R^2 \) Нагелкерке использует поправку, приводящую к тому, что оно всегда больше первого. Обе из них интерпретируют так же, как и коэффициент детерминации в линейной регрессии, то есть они описывают долю дисперсии зависимой переменной, объясняемую моделью. Из-за поправки \( R^2 \) Нагелкерке в целом принимает более высокие значения, чем \( R^2 \) Кокса и Снелла для одной и той же модели. В нашем случае —2 логарифма правдоподобия равны 301,230, \( R^2 \) Кокса и Снелла равно 0,038, а \( R^2 \) Нагелкерке равно 0,073. Коэффициенты для этой модели представлены в табл. 11.4.

Таблица 11.4. Коэффициенты для логистической регрессии, предсказывающей наличие медицинской страховки по полу и возрасту

<table>
  <tr>
    <th rowspan="2"> </th>
    <th colspan="7">95% ДИ для Exp(B)</th>
  </tr>
  <tr>
    <th>В</th>
    <th>Станд. ошибка</th>
    <th>Вальд</th>
    <th>df</th>
    <th>Знач.</th>
    <th>Exp(B)</th>
    <th>Нижняя граница</th>
    <th>Верхняя граница</th>
  </tr>
  <tr>
    <td>Мужской пол</td>
    <td>0.030</td>
    <td>0.310</td>
    <td>0.010</td>
    <td>1</td>
    <td>0.922</td>
    <td>1.031</td>
    <td>0.561</td>
    <td>1.893</td>
  </tr>
  <tr>
    <td>Возраст</td>
    <td>0.035</td>
    <td>0.009</td>
    <td>16.006</td>
    <td>1</td>
    <td>&lt; 0.001</td>
    <td>1.036</td>
    <td>1.018</td>
    <td>1.054</td>
  </tr>
  <tr>
    <td>Константа</td>
    <td>0.118</td>
    <td>0.475</td>
    <td>0.062</td>
    <td>1</td>
    <td>0.804</td>
    <td>1.125</td>
    <td></td>
    <td></td>
  </tr>
</table>

Мы перекодировали пол в новую переменную, Мужской пол, со значениями 0 для женщин и 1 для мужчин; это проще интерпретировать, поскольку нам не надо запоминать, как какая категория была закодирована. Как и с линейной регрессией, критерии для константы нам обычно не интересны. Независимые переменные оцениваются с помощью хи-квадрата Вальда (the Wald chi-square); значения достоверностей интерпретируют так же, как p-значения в любых других статистиках. В данном случае мы видим, что возраст достоверно предсказывает наличие страховки (хи-квадрат Вальда (1 df) равен 16,006, \( p < 0,001 \)), тогда как мужской пол — нет (хи-квадрат Вальда (1 df) \( p = 0,922 \)). Вспомнив, что мы закодировали страховку так, что 0 — это ее отсутствие, а 1 — наличие, легко видеть, что, поскольку, коэффициент для возраста положительный, с увеличением возраста вероятность наличия страховки у человека тоже растет.

Столбец Exp(B) дает нам отношение вероятностей для каждой независимой и зависимой переменной с поправкой на все остальные переменные в модели; последние две колонки показывают 95%-ный доверительный интервал для отношения вероятностей с поправкой. Если вы незнакомы с отношениями вероятностей, вам лучше прочитать раздел главы 15 о них, прежде чем двигаться дальше, потому что тут приведено лишь очень краткое объяснение. Как видно из названия, отношение вероятностей — это частное вероятностей двух возможных событий.