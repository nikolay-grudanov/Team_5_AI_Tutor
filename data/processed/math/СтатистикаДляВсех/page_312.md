---
source_image: page_312.png
page_number: 312
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 46.36
tokens: 7142
characters: 3573
timestamp: 2025-12-24T08:00:11.617773
finish_reason: stop
---

Переподгонка

Сводка результатов построения нескольких моделей (с диастолическим давлением как независимой переменной, а числом сигарет в день как независимой) представлена в табл. 11.12. Как вы можете видеть из нее, кроме линейной, возможно еще много видов связи между двумя переменными. Еще более удивительно, что модель, включающая линейный и кубический члены, объясняет 97% дисперсии диастолического давления. Никто до того не отмечал кубическую связь между этими переменными, так что вы думаете, что нашли очень убедительный аргумент.

Таблица 11.12. Связь между диастолическим кровяным давлением и числом выкуренных за день сигарет

<table>
  <tr>
    <th rowspan="2">Зависимость</th>
    <th colspan="4">Информация о модели</th>
    <th colspan="5">Оценки параметров</th>
  </tr>
  <tr>
    <th>R<sup>2</sup></th>
    <th>F</th>
    <th>df1</th>
    <th>df2</th>
    <th>Знач.</th>
    <th>Константа</th>
    <th>b<sub>1</sub></th>
    <th>b<sub>2</sub></th>
    <th>b<sub>3</sub></th>
  </tr>
  <tr>
    <td>Линейная</td>
    <td>0.781</td>
    <td>28.518</td>
    <td>1</td>
    <td>8</td>
    <td>0.001</td>
    <td>78.423</td>
    <td>1.246</td>
    <td></td>
    <td></td>
  </tr>
  <tr>
    <td>Квадратичная</td>
    <td>0.869</td>
    <td>23.118</td>
    <td>2</td>
    <td>7</td>
    <td>0.001</td>
    <td>80.984</td>
    <td>-0.386</td>
    <td>0.053</td>
    <td></td>
  </tr>
  <tr>
    <td>Кубическая</td>
    <td>0.970</td>
    <td>64.155</td>
    <td>3</td>
    <td>6</td>
    <td>0.000</td>
    <td>79.069</td>
    <td>3.975</td>
    <td>-0.299</td>
    <td>0.007</td>
  </tr>
  <tr>
    <td>Составная</td>
    <td>0.813</td>
    <td>34.853</td>
    <td>1</td>
    <td>8</td>
    <td>0.000</td>
    <td>79.007</td>
    <td>1.013</td>
    <td></td>
    <td></td>
  </tr>
  <tr>
    <td>Рост</td>
    <td>0.813</td>
    <td>34.853</td>
    <td>1</td>
    <td>8</td>
    <td>0.000</td>
    <td>4.370</td>
    <td>0.012</td>
    <td></td>
    <td></td>
  </tr>
  <tr>
    <td>Экспоненциальная</td>
    <td>0.813</td>
    <td>34.853</td>
    <td>1</td>
    <td>8</td>
    <td>0.000</td>
    <td>79.007</td>
    <td>.0120</td>
    <td></td>
    <td></td>
  </tr>
</table>

Имеют ли R<sup>2</sup>, рассчитанные при таком подходе, какое-то реальное значение? И да, и нет; один из рисков при таком «выуживании результатов» — это переподгонка (или переобучение — overfitting). Это означает, что ваша модель слишком хорошо аппроксимирует данные и объясняет не только достоверные зависимости, но и случайные отклонения. Поскольку задачей статистического анализа являются обобщение результатов и перенос их на другие выборки из той же генеральной совокупности, переподгонка мешает достижению этой цели. Вы можете получить модель, которая замечательно описывает ваши данные, но она совсем не обязательно подойдет для каких-то других данных, так что она не привносит новых полезных знаний в вашу область.

Лучшая защита от переподгонки — построение моделей на основании теории. Если вы решите строить свою модель с помощью механистичных подходов, следует проверять ее на многих выборках, чтобы быть уверенным, что вы моделируете важные взаимосвязи в данных, а не случайный шум. Если доступно только ограниченное число выборок, например в случае, когда получение данных сопровождается уничтожением образца, можно применять методы создания повторных выборок (resampling), или создания искусственных выборок на основе имеющихся данных, таких как бутстреп (bootstrapping) или «складной нож» (jackknife); они обсуждаются в книге Ефрон (Efron), упомянутой в приложении C.