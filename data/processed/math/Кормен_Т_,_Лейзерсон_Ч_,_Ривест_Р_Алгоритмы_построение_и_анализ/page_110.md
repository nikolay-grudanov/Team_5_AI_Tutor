---
source_image: page_110.png
page_number: 110
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 47.64
tokens: 11454
characters: 1547
timestamp: 2025-12-24T06:25:12.172978
finish_reason: stop
---

каждую выпавшую решку. Выигрыш \( X \) будет случайной величиной, и её математическое ожидание будет равно

\[
M[X] = 6 \cdot P\{2 \text{ орла}\} + 1 \cdot P\{1 \text{ орёл и 1 решка}\} - 4 \cdot P\{2 \text{ решки}\}
= 6(1/4) + 1(1/2) - 4(1/4)
= 1.
\]

Математическое ожидание суммы случайных величин равно сумме их ожиданий:

\[
M[X + Y] = M[X] + M[Y],
\]

если \( M[X] \) и \( M[Y] \) определены. Это правило можно распространить на любые конечные и абсолютно сходящиеся бесконечные суммы.

Пусть \( X \) — случайная величина, а \( g(x) \) — произвольная функция. Тогда можно рассмотреть случайную величину \( g(X) \) (на том же вероятностном пространстве). Её математическое ожидание (если оно определено) можно найти по формуле

\[
M[g(X)] = \sum_x g(x)P\{X = x\}.
\]

Для функции \( g(x) = ax \), где \( a \) — некоторая константа, имеем

\[
M[aX] = aM[X].
\]

Два последних свойства можно скомбинировать в одной формуле (свойство линейности): для любых двух случайных величин \( X \) и \( Y \) и любой константы \( a \)

\[
M[aX + Y] = aM[X] + M[Y].
\]

Если две случайные величины \( X \) и \( Y \) независимы и их математические ожидания определены, то

\[
\begin{align*}
M[XY] &= \sum_x \sum_y xyP\{X = x, Y = y\} \\
&= \sum_x \sum_y xyP\{X = x\}P\{Y = y\} \\
&= (\sum_x xP\{X = x\})(\sum_y yP\{Y = y\}) \\
&= M[X]M[Y].
\end{align*}
\]

Более общо, если имеется \( n \) независимых в совокупности случайных величин \( X_1, X_2, \ldots, X_n \), имеющих математические ожидания, то

\[
M[X_1 X_2 \cdots X_n] = M[X_1]M[X_2] \cdots M[X_n].
\]