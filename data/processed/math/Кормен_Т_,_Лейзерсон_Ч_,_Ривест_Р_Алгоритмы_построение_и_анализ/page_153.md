---
source_image: page_153.png
page_number: 153
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 49.17
tokens: 11313
characters: 1609
timestamp: 2025-12-24T06:27:08.317008
finish_reason: stop
---

Рисунок 8.4 Дерево рекурсии для случая, когда разбиение каждый раз производится в отношении 9 : 1. Время работы равно \( \Theta(n \lg n) \).

В данном случае эта глубина равна \( \log_{10/9} n = \Theta(\lg n) \), так что время работы по-прежнему составляет \( \Theta(n \lg n) \), хотя константа и больше. Ясно, что для любого фиксированного отношения размеров частей (сколь бы велико оно ни было) глубина дерева рекурсии по-прежнему будет логарифмической, а время работы будет равно \( \Theta(n \lg n) \).

Среднее время: интуитивные соображения

Чтобы вопрос о среднем времени работы имел смысл, нужно уточнить, с какой частотой появляются различные входные значения. Как правило, предполагается, что все перестановки входных значений равновероятны. (Мы вернёмся к этому в следующем разделе.)

Для наугад взятого массива разбиения вряд ли будут всё время происходить в одном и том же отношении — скорее всего, часть разбиений будет хорошо сбалансирована, а часть нет. Как показывает упр. 8.2-5, примерно 80 процентов разбиений производятся в отношении не более 9 : 1.

Будем предполагать для простоты, что на каждом втором уровне все разбиения наихудшие, а на оставшейся половине уровней наилучшие (пример показан на рис. 8.5(а)). Поскольку после каждого "хорошего" разбиения размер частей уменьшается вдвое, число "хороших" уровней равно \( \Theta(\lg n) \), а поскольку каждый второй уровень "хороший", общее число уровней равно \( \Theta(\lg n) \), а время работы — \( \Theta(n \lg n) \). Таким образом, плохие уровни не испортили асимптотику времени работы (а лишь увеличили константу, скрытую в асимпто-