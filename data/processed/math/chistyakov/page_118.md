---
source_image: page_118.png
page_number: 118
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 34.56
tokens: 8472
characters: 1482
timestamp: 2025-12-24T07:28:56.799930
finish_reason: stop
---

Отсюда и из (3.1) следует, что

\[
D\xi = M\xi^2 - (M\xi)^2.
\] (3.2)

Если случайная величина \( \xi \) абсолютно непрерывна, то, полагая в формуле (1.7) \( n = 1 \) и \( g(x_1) = (x_1 - M\xi)^2 \), получим

\[
D\xi = \int_{-\infty}^{\infty} (x - M\xi)^2 p_\xi(x) dx.
\] (3.3)

Для дискретной величины \( \xi \) из (1.6) найдем

\[
D\xi = \sum_{k=1}^{\infty} (x_k - M\xi)^2 P(\xi = x_k),
\] (3.4)

где \( \sum_{k=1}^{\infty} P(\xi = x_k) = 1 \).

Приведем свойства дисперсии.

Теорема 3.1.
1°. Для любой случайной величины \( \xi \) имеем \( D\xi \geq 0 \).
2°. Если с постоянная, то \( Dc = 0 \).
3°. Если с постоянная, то \( D(c\xi) = c^2 D\xi \).
4°. Если случайные величины \( \xi_1 \) и \( \xi_2 \) независимы, то

\[
D(\xi_1 + \xi_2) = D\xi_1 + D\xi_2.
\] (3.5)

Доказательство. Свойства 1°, 2°, 3° следуют непосредственно из определения и свойств математического ожидания. Докажем свойство 4°. По определению (3.1)

\[
\begin{align*}
D(\xi_1 + \xi_2) &= M[(\xi_1 + \xi_2) - M(\xi_1 + \xi_2)]^2 = \\
&= M[(\xi_1 - M\xi_1) + (\xi_2 - M\xi_2)]^2 = \\
&= M[(\xi_1 - M\xi_1)^2 + (\xi_2 - M\xi_2)^2 + 2(\xi_1 - M\xi_1)(\xi_2 - M\xi_2)].
\end{align*}
\] (3.6)

Отсюда, так как случайные величины \( \xi_1 - M\xi_1, \xi_2 - M\xi_2 \) независимы и

\[
M(\xi_1 - M\xi_1)(\xi_2 - M\xi_2) = M(\xi_1 - M\xi_1) \cdot M(\xi_2 - M\xi_2) =
\]
\[
= (M\xi_1 - M\xi_1)(M\xi_2 - M\xi_2) = 0,
\]

следует, что

\[
D(\xi_1 + \xi_2) = M(\xi_1 - M\xi_1)^2 + M(\xi_2 - M\xi_2)^2 = D\xi_1 + D\xi_2.
\]