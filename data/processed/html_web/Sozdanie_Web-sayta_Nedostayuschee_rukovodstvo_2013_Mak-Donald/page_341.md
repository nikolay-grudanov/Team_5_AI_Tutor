---
source_image: page_341.png
page_number: 341
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 80.56
tokens: 12163
characters: 3249
timestamp: 2025-12-24T09:42:03.825163
finish_reason: stop
---

Как показывает данный пример, в файл robots.txt можно вставить одно за другим столько правил Disallow, сколько захотите.

Но помните, что файл robots.txt — это только набор инструкций для роботов поисковых машин, а не способ управления доступом. Другими словами, он подобен надписи "Никакой рекламы" на вашем почтовом ящике: она будет действовать, только если рекламные агенты обращают на нее внимание.

СОВЕТ
Вы можете узнать больше о программах-роботах, включая способы общения с ними при посещении вашего сайта и задание ограничений для роботов определенных поисковых машин, на Web-сайте www.robotstxt.org.

НА ПРОФЕССИОНАЛЬНОМ УРОВНЕ
Web-долговечность
Вы наверняка слышали разговоры о постоянно меняющейся природе Web. Возможно, вы боитесь, что ссылки, созданные вами сегодня, завтра уже будут указывать на заброшенные сайты или исчезнувшие страницы. Но на самом деле сейчас назревает совершенно иная проблема — копии старых сайтов, которые просто так не исчезают.

После того как вы поместили свою работу в Web, вы навсегда теряете над ней контроль. Эта простая мысль приводит к следующему совету: всегда убеждайтесь в том, что на вашем сайте нет ничего противозаконного, нарушающего авторские права, ставящего кого-либо в неловкое положение или способного сделать вас изгоем. Материал, единожды выпущенный вами в Web-пространство, может остаться там навсегда.

Представьте себе, что вы случайно открыли торговый секрет вашей компании, касающийся жевательной резинки со вкусом и ароматом моркови. Через несколько недель любознательный покупатель попадает по ссылке на ваш сайт. Вы осознали свою ошибку и удалили страницы с Web-сервера. Но действительно ли вы устранили проблему?

Допустим, что робот Google недавно посетил ваш сайт (что более чем вероятно), теперь у Google есть копия вашего старого сайта. Хуже того, пользователи могут получить эту кэшированную (сохраненную) копию от Google, если им знакомо ключевое слово кэш. Например, если URL создавшей проблему страницы — www.GumLover.com/newProduct.htm, ушлый пользователь Google может получить старую копию вашей страницы с помощью строки поиска "cache:www.GumLover.com/newProduct.htm". (Менее осведомленные посетители также могут наткнуться на кэшированную страницу, щелкнув мышью ссылку Cached (Сохраненная копия), которая появляется в списке результатов поиска Google после каждой выведенной страницы.) Хотите верьте, хотите нет, но именно этот прием использовался раньше для получения случайно просочившейся информации, начиная со сплетен и заканчивая лицензионными ключами программного обеспечения.

Вы можете попытаться как можно быстрее удалить вашу страницу из кэша Google, используя средство удаления URL на странице www.google.com/webmasters/tools/removals. Но даже если оно сработает, у вас останется вопрос: как узнать, сколько поисковых машин успели сделать копию вашей работы? Любопытные пользователи, заметившие, что вы удалили информацию с вашего сайта, посетят эти поисковые машины и скопируют подробности на свои собственные сайты, сделав практически невозможным удаление многочисленных следов вашей ошибки. Существуют даже каталоги, предназначенные для сохранения старых сайтов для потомков (см. подборку Wayback Machine (Машина в прошлое) на сайте www.archive.org).