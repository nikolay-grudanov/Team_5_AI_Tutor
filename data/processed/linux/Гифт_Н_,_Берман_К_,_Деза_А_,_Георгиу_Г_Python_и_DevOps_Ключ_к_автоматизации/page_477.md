---
source_image: page_477.png
page_number: 477
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 33.42
tokens: 7608
characters: 2464
timestamp: 2025-12-24T03:13:26.849777
finish_reason: stop
---

pp.pprint(result)
{
    'Namespaces': 'A way to divide cluster resources between users.',
    'Pod': 'Basic building block of Kubernetes.',
    'Service': 'An abstraction for dealing with Pods.',
    'Volume': 'A directory accessible to containers in a Pod.'}

Большие данные

Размеры данных растут быстрее, чем вычислительные мощности компьютеров. Еще более интересной делает ситуацию то, что закон Мура, согласно которому скорость и возможности компьютеров должны удваиваться каждые два года, фактически больше не работает начиная с примерно 2015 года согласно доктору Дэвиду Паттерсону из Калифорнийского университета в Беркли. Тактовая частота CPU растет сейчас лишь на 3 % в год.

Необходимы новые методы работы с большими данными, в том числе такие ASIC, как GPU, тензорные процессоры (TPU), а также ИИ и платформы данных поставщиков облачных сервисов. На уровне микросхем это значит, что лучше всего ориентироваться на использование в сложных IT-процессах GPU вместо CPU. Зачастую такой GPU сочетается с системой, обеспечивающей распределенный механизм хранения, что делает возможными как распределенные вычисления, так и распределенные операции дискового ввода/вывода. Прекрасные примеры — Apache Spark, Amazon SageMaker и платформа ИИ Google. Все они могут применять ASIC (GPU, TPU и др.), а также распределенное хранилище вместе с системой управления. Еще один, более низкоуровневый пример — AMI спотовых инстансов Amazon с точками монтирования файловой системы Amazon Elastic File System (EFS).

Для специалиста по DevOps отсюда вытекают несколько вещей. Во-первых, поставка программного обеспечения в эти системы должна производиться с дополнительной осторожностью. Например, стоит ответить на следующие вопросы: правильные ли драйверы GPU на целевой платформе? Производится ли контейнерное развертывание? Будет ли данная система использовать распределенную GPU-обработку? Данные преимущественно пакетные или потоковые? Заблаговременное обдумывание этих вопросов имеет большое значение для разработки правильной архитектуры.

Одна из проблем с модными словечками вроде ИИ, «большие данные», «облачные вычисления» и «исследователи данных» — для разных людей их смысл может различаться. Рассмотрим, например, термин «исследователь данных» (data scientist). В одной компании это специалист, занимающийся созданием информационных панелей бизнес-аналитики для отдела продаж, а в другой — разработчик программного обеспечения для самоуправляемых автомобилей.