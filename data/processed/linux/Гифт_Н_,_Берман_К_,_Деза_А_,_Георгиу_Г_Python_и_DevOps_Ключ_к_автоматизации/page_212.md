---
source_image: page_212.png
page_number: 212
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 41.10
tokens: 7706
characters: 2585
timestamp: 2025-12-24T03:06:38.674046
finish_reason: stop
---

CentOS, Debian и Ubuntu). Основным требованием к системе сборки было ее быстродействие.

И хотя одной из главных среди поставленных задач была скорость работы, при проектировании системы, включающем несколько этапов и различные компоненты, имеет смысл заранее учесть известные проблемные места и попытаться предотвратить появление новых. В больших системах всегда возникают новые проблемы, поэтому жизненно важны правильные стратегии журналирования (и агрегирования журналов), мониторинга и восстановления.

Вернемся к системе сборки. Одна из проблем заключалась в сложности организации машин для создания репозиториев: HTTP API получал пакеты для конкретной версии конкретного проекта, а репозитории генерировались автоматически. В этом процессе участвовали база данных, сервис RabbitMQ для асинхронной обработки заданий и большой объем пространства в хранилище под управлением Nginx для хранения репозиториев. Наконец, информация о состоянии отправлялась на центральную инструментальную панель, чтобы в процессе сборки разработчики могли отследить свою ветвь проекта. Совершенно необходимо было проектировать все с учетом вероятности отказа этого сервиса.

На доску приклеили большую записку: «ОШИБКА: отказ сервиса репозитория вследствие переполнения диска». Задача заключалась вовсе не в предотвращении переполнения диска, а в создании системы, которая могла бы продолжать работать и при заполненном диске, так что после решения проблемы с диском не представляло бы труда снова подключить его к системе. Ошибка переполненного диска — выдуманная, ее место могла занимать любая другая, например не запущенный сервис RabbitMQ или проблема с DNS, но она прекрасно отражает суть поставленной задачи.

Не так уж просто осознать важность паттернов мониторинга, журналирования и грамотной архитектуры до тех пор, пока часть этого пазла не перестанет работать и не окажется невозможно понять, почему и как. Важно знать, почему произошел сбой, чтобы реализовать шаги по его предотвращению (оповещения, мониторинг и самовосстановление), гарантируя, что это проблема не возникнет в будущем.

Чтобы система могла продолжить работать в случае отказа, мы разобьем нагрузку на пять одинаковых машин, выполняющих одну работу — создание и размещение репозиториев. Узлы, создающие бинарные файлы, запрашивают у API исправную машину репозитория, которая, в свою очередь, отправляет HTTP-запрос к конечной точке /health/ следующего сервера сборки в списке. Если сервер отвечает, что исправен, туда отправляются исполняемые файлы, в противном случае API выбирает следующий сервер в списке. Если проверка