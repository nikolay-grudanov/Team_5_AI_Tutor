---
source_image: page_473.png
page_number: 473
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 32.39
tokens: 7621
characters: 2342
timestamp: 2025-12-24T03:13:17.787513
finish_reason: stop
---

данием API для доступа к ним, а также планирование выполнения этих заданий. Эта задача однозначна: конвейер либо работает, либо нет.

Аналогично проектировщик систем машинного обучения занимается созданием моделей машинного обучения и развертыванием их так, чтобы упростить сопровождение. Это также вполне однозначная задача. Впрочем, конкретный специалист может заниматься инженерией данных или машинным обучением и все равно вести себя в соответствии с практиками науки о данных и DevOps. Сегодня самое время заняться работой с данными, поскольку существует немало прекрасных возможностей создать сложные устойчивые к ошибкам конвейеры для снабжения данными других сложных и обладающих широкими возможностями прогнозных систем. Есть высказывание: «Нельзя быть слишком богатым или слишком стройным». Точно так же и с данными: навыков DevOps или работы с данными никогда не бывает слишком много. Обсудим подробнее приправленные DevOps идеи инженерии данных.

Малые данные

Наборы инструментов — замечательная концепция. Если вызвать на дом сантехника, обычно он приезжает с инструментами, позволяющими ему справиться с проблемой гораздо эффективнее, чем могли бы вы. Нанятый вами для каких-либо работ плотник также приходит со своим набором специальных инструментов, благодаря которому может выполнить работу намного быстрее, чем вы. Инструменты жизненно важны для профессионалов, и специалисты по DevOps не исключение.

В этом разделе мы рассмотрим утилиты для инженерии данных. Они включают инструменты для небольших задач по работе с данными, например для чтения и записи файлов, использования библиотеки pickle, формата JSON, а также записи и чтения файлов YAML. Свободная работа с этими форматами — необходимый навык для специалиста по автоматизации, который хочет уметь превратить любую задачу в сценарий. Далее в этой главе мы обсудим утилиты для работы с большими данными, которые принципиально отличаются от утилит для работы с малыми данными.

Что же такое большие данные, а что — малые? Самый простой способ различить их — так называемый ноутбучный тест. Можно ли с ними работать на ноутбуке? Если нет — это большие данные. Хороший пример — Pandas. Эта библиотека требует в 5–10 раз больше оперативной памяти, чем размер набора данных. Скорее всего, для обработки в Pandas файла размером 2 Гбайт вашего ноутбука будет недостаточно.