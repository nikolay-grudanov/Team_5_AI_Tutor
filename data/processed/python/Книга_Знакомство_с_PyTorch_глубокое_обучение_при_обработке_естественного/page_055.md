---
source_image: page_055.png
page_number: 55
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 26.09
tokens: 7431
characters: 1585
timestamp: 2025-12-24T02:22:34.334803
finish_reason: stop
---

значения в сети просто становятся равны 0 и никогда более не восстанавливаются. Эта проблема носит название «умирающего ReLU». Для уменьшения этого эффекта были предложены функции активации под названием ReLU «с утечкой» (leaky ReLU) и параметрический ReLU (parametric ReLU, PReLU), где коэффициент утечки \( a \) — параметр, значение которого определяется в процессе обучения. Результат показан в примере 3.5.

\[
f(x) = \max(x, ax).
\]

Пример 3.5. PReLU-активация

import torch
import matplotlib.pyplot as plt

prelu = torch.nn.PReLU(num_parameters=1)
x = torch.range(-5., 5., 0.1)
y = prelu(x)

plt.plot(x.numpy(), y.numpy())
plt.show()

Многомерная логистическая функция

Еще один вариант функции активации — многомерная логистическая функция (softmax). Подобно сигма-функции, многомерная логистическая функция сжимает результат каждого из блоков в диапазон от 0 до 1, как показано в примере 3.6. Впрочем, она также делит каждый из результатов на сумму всех результатов, в итоге получается дискретное распределение вероятности¹ по \( k \) возможным классам:

\[
softmax(x_i) = \frac{e^{x_i}}{\sum_{j=1}^k e^{x_j}}.
\]

Сумма вероятностей в полученном распределении равна 1. Это очень удобно для интерпретации результатов при классификации, так что данное преобразование обычно сочетается с целевой функцией вероятностного обучения, например

¹ Слова «распределение» и «вероятность» здесь следует воспринимать с толикой здорового скепсиса. Под «вероятностью» мы понимаем ограниченность значений на выходе отрезком [0, 1], а под «распределением» — то, что сумма результатов равна 1.