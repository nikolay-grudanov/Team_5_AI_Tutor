---
source_image: page_052.png
page_number: 52
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 30.28
tokens: 7529
characters: 1947
timestamp: 2025-12-24T02:22:33.409379
finish_reason: stop
---

self.fc1 = nn.Linear(input_dim, 1)

def forward(self, x_in):
    """ Прямой проход перцептрона

    Аргументы:
        x_in (torch.Tensor): тензор входных данных
            x_in.shape должен быть равен (batch, num_features)
    Возвращает:
        Итоговый тензор. tensor.shape должен быть равен (batch,).
    """
    return torch.sigmoid(self.fc1(x_in)).squeeze()

В модуле torch.nn фреймворка PyTorch есть удобный класс Linear, берущий на себя всю «бухгалтерию» весов и смещений, а также выполнение нужного аффинного преобразования¹. В подразделе «Углубляемся в обучение с учителем» на с. 68, вы прочитаете, как узнать значения весов \( w \) и смещения \( b \) путем обучения на данных. В предыдущем примере в качестве функции активации использовалась сигма-функция (sigmoid function). В следующем разделе мы обсудим некоторые распространенные функции активации, включая и эту.

Функции активации

Функции активации — нелинейности, вводимые в нейронную сеть для того, чтобы уловить сложные взаимосвязи данных. В подразделе «Углубляемся в обучение с учителем» на с. 68 и в разделе «Многослойный перцептрон» на с. 101 вы узнаете, зачем в машинном обучении нужны нелинейности, но сначала рассмотрим несколько часто используемых функций активации².

Сигма-функция

Сигма-функция — одна из первых функций активации в истории нейронных сетей. Она «размазывает» полученное вещественное значение по диапазону от 0 до 1. Математически сигма-функция описывается следующим образом:

\[
f(x) = \frac{1}{1 + e^{-x}}.
\]

¹ Значения весов и смещений обрабатываются внутри класса nn.Linear. Если по какой-то маловероятной причине вам понадобится модель без смещения, можно явным образом указать bias=False в конструкторе nn.Linear.

² Существует множество видов функций активации — в одном только фреймворке PyTorch насчитывается более 20 готовых. Разобравшись с этой главой, вы сможете обратиться к документации (http://bit.ly/2SuIQLm) и узнать о них больше.