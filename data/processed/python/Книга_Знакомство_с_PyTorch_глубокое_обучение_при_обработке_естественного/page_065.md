---
source_image: page_065.png
page_number: 65
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 32.78
tokens: 7626
characters: 2493
timestamp: 2025-12-24T02:22:57.149477
finish_reason: stop
---

обновления параметров моделей с учетом градиента. Однако для процесса машинного обучения важны несколько вспомогательных понятий, часть из которых мы рассмотрим в этом разделе.

Точная оценка качества модели: метрики оценки

Помимо основного цикла обучения с учителем, важнейшим компонентом является объективная оценка качества модели с помощью данных, на которых эта модель не обучалась. Оценка моделей производится с помощью одной или нескольких метрик оценки (evaluation metrics). При обработке написанных на естественных языках текстов используется несколько подобных метрик. Самая распространенная, которой мы и воспользуемся в этой главе, — точность (accuracy). Точность представляет собой просто долю правильных предсказаний для не участвовавшего в обучении набора данных.

Точная оценка качества модели: разбиение набора данных

Важно не забывать, что конечная цель — обобщить модель на истинное распределение данных. Что это значит? Если бы нашему алгоритму для просмотра было доступно бесконечное количество данных, он бы обнаружил глобальное распределение данных («истинное/ненаблюдаемое распределение»). Конечно, это невозможно. Нам приходится довольствоваться конечной выборкой — обучающей последовательностью. В этой конечной выборке мы наблюдаем распределение данных, приближенно (неполно) соответствующее истинному. Одна модель считается лучше обобщающейся, чем другая, если она снижает погрешность не только в присутствовавших в обучающей последовательности выборках, но и в выборках из распределения, которое она не наблюдала. Поскольку модель стремится снизить потери на обучающей последовательности, то может «переобучиться» и адаптироваться к особенностям, не имеющим отношения к истинному распределению данных.

Для хорошего обобщения принято либо разбивать набор данных на три выбранные случайным образом части (обучающий (training), проверочный (validation) и контрольный (test) наборы данных) или выполнять k-блочную перекрестную проверку (k-fold cross-validation). Разбиение на три части — самый простой из этих методов, поскольку требует одного прохода. Следует, впрочем, позаботиться о том, чтобы распределение классов в этих наборах данных было одинаковым. Другими словами, рекомендуется агрегировать набор данных по меткам классов, после чего разбивать каждый из наборов со своей меткой класса на обучающий, проверочный и контрольный. Обычно при разбиении 70 % данных отводится на обучающий набор, 15 % на проверочный и 15 % на контрольный. Но это не обязательно.