---
source_image: page_183.png
page_number: 183
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 36.70
tokens: 7670
characters: 2639
timestamp: 2025-12-24T02:26:11.795554
finish_reason: stop
---

Несмотря на новизну темы, сейчас можно найти много литературы, посвященной вниманию, что указывает на важность этой тематики. Подробный обзор всех подходов выходит за рамки книги, так что в качестве отправного пункта мы рекомендуем вам обратиться к статьям Луона, Фама и Мэннинга (Luong, Pham, Manning, 2015) и Васвани и др. (Vaswani et al., 2017).

Оценка эффективности моделей генерации последовательностей

Такие метрики классификации, как точность, чувствительность¹ и F1, ничего не дают моделям при наличии нескольких возможных ответов, как мы видели в задачах генерации, — у одного французского предложения может быть несколько переводов на английский. Модели последовательностей оцениваются путем сравнения с ожидаемыми выходными данными — эталонными выходными данными (reference output). При сравнении различных моделей применяются показатели согласия (goodness) — близости выходных данных модели к эталонным. Например, в таких задачах, как машинный перевод, не стоит штрафовать отклонившуюся на одно слово модель так же сильно, как модель, выходной текст которой совершенно невозможно понять. Для одной входной выборки может существовать несколько эталонных выходных данных, например несколько (чуть отличающихся) допустимых переводов на английский конкретного французского предложения. Предусмотрено два вида оценки эффективности для моделей генерации последовательностей: оценка человеком и автоматическая оценка.

При оценке человеком эффективности машинного перевода несколько человек либо оценивают (положительно или отрицательно) результаты работы модели, либо исправляют перевод. В результате получается простой показатель частоты появления ошибок, очень хорошо отражающий нашу конечную цель: оценить близость результатов работы системы к результатам перевода человеком. Оценка человеком важна, но редко используется из-за дороговизны и медленной работы экспертов. Мнения людей также часто различаются, поэтому в качестве золотого стандарта при человеческой оценке применяется показатель частоты взаимного согласия оценщиков (inter-annotator agreement rate).

Измерение частоты взаимного согласия оценщиков также требует немалых затрат ресурсов. Одна из часто применяемых метрик оценки человеком — человекоориентированная частота ошибок перевода (human-targeted translation error rate, HTER) — взвешенное редакторское расстояние. Оно определяется путем подсчета количества вставок, удалений и перестановок, которые нужно выполнить человеку, чтобы «исправить» результат работы машинного перевода и получить текст с приемлемым смыслом и достаточно «гладкий» перевод (рис. 8.10).

¹ Иногда называется «полнота». — Примеч. пер.