---
source_image: page_185.png
page_number: 185
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 36.02
tokens: 7640
characters: 2385
timestamp: 2025-12-24T02:26:11.406641
finish_reason: stop
---

для вычисления оценок мы будем использовать пакеты NLTK¹ или SacreBLEU². Определение самой метрики BLEU при наличии эталонных данных происходит достаточно быстро и просто.

Перплексия — еще одна основанная на теории информации метрика автоматической оценки. Применима в любой ситуации, где можно определить вероятность выходной последовательности. Для последовательности x, вероятность которой составляет P(x), перплексия определяется как:

\[
\text{перплексия}(x) = 2^{-P(x)\log P(x)}.
\]

Благодаря этому можно легко сравнивать различные модели генерации последовательностей, просто определяя перплексию модели для выделенного набора данных. Хотя вычислить перплексию несложно, с ее использованием для оценки эффективности генерации последовательностей связано много проблем. Во-первых, это «раздувающая» метрика. Обратите внимание, что в выражении для перплексии есть возведение в степень. В результате мелкие различия эффективности моделей (правдоподобия) приводят к большим различиям в перплексии, создавая иллюзию значительного прогресса. Во-вторых, изменения перплексии не обязательно отражаются в соответствующие изменения частоты ошибок моделей с точки зрения других метрик. Наконец, как и в случае BLEU и других метрик на основе n-грамм, улучшение перплексии не всегда приводит к ощутимым улучшениям перевода с точки зрения человека.

В следующем разделе мы приведем пример машинного перевода и соединим все описанные понятия воедино в реализации с помощью фреймворка PyTorch.

Пример: нейронный машинный перевод

В этом разделе мы рассмотрим реализацию наиболее распространенного применения S2S-моделей — машинного перевода. По мере роста популярности глубокого обучения в начале 2010-х стало очевидно, что вложения слов и RNN — исключительно мощные инструменты для перевода с одного языка на другой — при условии достаточного количества данных. Модели машинного перевода еще больше усовершенствовались с появлением механизма внимания,писанного в разделе «Оценка эффективности моделей генерации последовательностей» на с. 213. В этом разделе мы опишем реализацию, в основе которой лежит упрощенный подход к вниманию в S2S-моделях (Luong, Pham, Manning, 2015).

¹ Пример можно найти по адресу https://github.com/nltk/nltk/blob/develop/nltk/translate/bleu_score.py.
² Пакет SacreBLEU (https://github.com/mjpost/sacreBLEU) — общепринятый ориентир при оценке машинного перевода.