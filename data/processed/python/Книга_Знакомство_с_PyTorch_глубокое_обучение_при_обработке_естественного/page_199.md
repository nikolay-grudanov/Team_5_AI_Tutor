---
source_image: page_199.png
page_number: 199
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 38.44
tokens: 7788
characters: 2773
timestamp: 2025-12-24T02:26:41.592232
finish_reason: stop
---

довательностей» на с. 213 описано несколько метрик оценки генерации последовательностей, но такие метрики, как BLEU, оценивающие пересечение n-грамм между предсказанными и эталонными предложениями, стали стандартом в сфере машинного перевода. Код оценки с агрегированием результатов мы здесь приводить не станем, но вы можете найти его в репозитории GitHub по адресу https://nlproc.info/PyTorchNLPBook/repo/. В этом коде выходные данные модели агрегируются с исходным предложением, эталонным целевым предложением и матрицей вероятностей внимания для данного примера. Наконец, для каждой пары исходного и сгенерированного предложений вычисляется BLEU-4.

Для качественной, а не количественной оценки работы модели мы визуализируем матрицу вероятностей внимания в виде выравниваний между исходным и сгенерированным текстом. Впрочем, важно отметить: недавние исследования показали, что выравнивания на основе внимания отнюдь не то же самое, что в классическом машинном переводе. Показатели выравнивания на основе внимания не говорят о синонимии переводов, как выравнивания между словами и фразами, но могут указывать на полезную для декодировщика информацию, например обращать внимание на подлежащее при генерации выходного сказуемого (см. статью Кёна, Ноулза [Koehn, Knowles, 2017]).

Две версии нашей модели отличаются по типу своего взаимодействия с целевым предложением. Первая использует имеющиеся целевые предложения в качестве входных данных на каждом из временных шагов в декодировщике. Вторая версия с помощью плановой выборки предоставляет модели возможность наблюдать ее собственные предсказания в качестве входных данных декодировщика. Преимущество этой версии — в возможности оптимизировать модель на основе ее собственной погрешности.

В табл. 8.1 приведены показатели BLEU. Важно не забывать, что для упрощения обучения мы выбрали облегченную версию стандартной задачи NMT, поэтому показатели кажутся выше, чем обычно встречаются в научной литературе. Хотя у второй модели, с плановой выборкой, показатель BLEU выше, их показатели довольно близки. Но что эти показатели значат на самом деле? Для выяснения этого необходимо выполнить качественную оценку модели.

Таблица 8.1. Показатели BLEU для двух показанных выше моделей; BLEU вычисляется как простое среднее значение пересечений 1-, 2-, 3- и 4-грамм

<table>
  <tr>
    <th>Название модели</th>
    <th>Показатель BLEU</th>
  </tr>
  <tr>
    <td>Модель без плановой выборки</td>
    <td>46,8</td>
  </tr>
  <tr>
    <td>Модель с плановой выборкой</td>
    <td>48,1</td>
  </tr>
</table>

Для углубленной оценки построим график показателей внимания, чтобы увидеть, дают ли они какую-либо информацию о выравнивании между исходными и целевыми предложениями. При этом оказывается, что между двумя моделями есть