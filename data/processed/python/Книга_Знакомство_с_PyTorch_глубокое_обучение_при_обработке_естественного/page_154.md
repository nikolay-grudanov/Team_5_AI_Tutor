---
source_image: page_154.png
page_number: 154
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 24.58
tokens: 7445
characters: 1769
timestamp: 2025-12-24T02:25:10.969023
finish_reason: stop
---

7 Продолжаем моделирование последовательностей для обработки текстов на естественных языках

Наша цель в этой главе — научиться предсказанию последовательностей. Задача предсказания последовательности требует маркирования всех ее элементов. Подобные задачи часто встречаются при обработке текстов на естественных языках. В числе их примеров моделирование языка (рис. 7.1), при котором на каждом шаге по заданной последовательности слов предсказывается следующее слово; частеречная разметка (part-of-speech tagging), когда предсказывается грамматическая часть речи для каждого слова; распознавание поименованных сущностей (named entity recognition), при котором предсказывается, является ли каждое из слов частью поименованной сущности, и т. д. Иногда в литературе, посвященной NLP, задачи предсказания последовательностей также называются маркированием последовательностей (sequence labeling).

Хотя теоретически для задач предсказания последовательностей можно воспользоваться рекуррентными нейронными сетями Элмана, с которыми мы познакомились в главе 6, но эти RNN не способны уловить «далекие» зависимости и на практике работают плохо. В этой главе мы немного поговорим о том, почему так происходит, и расскажем о новом типе архитектуры RNN — шлюзовых сетях¹ (gated networks).

Мы также расскажем вам, как применять предсказание последовательностей для решения задачи генерации естественного языка (natural language generation), и изучим контекстно обусловленную генерацию, при которой выходная последовательность каким-либо образом ограничена.

¹ В русскоязычной литературе отсутствует устоявшийся термин для подобных нейронных сетей, их называют также «управляемыми» и «вентильными», но вариант «шлюзовые» в наибольшей степени отражает их сущность. — Примеч. пер.