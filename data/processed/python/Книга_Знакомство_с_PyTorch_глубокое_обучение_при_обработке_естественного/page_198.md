---
source_image: page_198.png
page_number: 198
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 31.74
tokens: 7618
characters: 2390
timestamp: 2025-12-24T02:26:31.083691
finish_reason: stop
---

p_y_t_index = F.softmax(score_for_y_t_index *
    self._sampling_temperature, dim=1)
# метод 1: выбираем наиболее вероятное слово
# _, y_t_index = torch.max(p_y_t_index, 1)
# метод 2: выборка из распределения
y_t_index = torch.multinomial(p_y_t_index, 1).squeeze()

# вспомогательный код: получаем показатели эффективности
# предсказания
output_vectors.append(score_for_y_t_index)

output_vectors = torch.stack(output_vectors).permute(1, 0, 2)

return output_vectors

Процедура обучения и результаты

Процедура обучения для этого примера практически идентична процедурам обучения, которые вы видели в предыдущих главах¹. Мы проходим в цикле по набору данных по порциям-мини-пакетам в течение определенного числа эпох. Впрочем, здесь каждый мини-пакет состоит из четырех тензоров: матрицы целых чисел для исходной последовательности, двух матриц целых чисел для целевой последовательности и вектора целых чисел для длин исходной последовательности. Две матрицы целевой последовательности представляют собой смещение целевой последовательности на один токен и дополнены либо токенами BEGIN-OF-SEQUENCE в качестве наблюдений целевой последовательности, либо токенами END-OF-SEQUENCE в качестве меток предсказаний целевой последовательности. В виде входных данных модель принимает исходную последовательность и наблюдения целевой последовательности и генерирует предсказания целевой последовательности. Метки предсказаний целевой последовательности используются в функции потерь для вычисления потерь на основе перекрестной энтропии, которые затем распространяются обратно по всем параметрам модели, для выяснения градиентов. После этого вызывается оптимизатор и обновляет все параметры модели пропорционально градиентам.

Помимо прохода в цикле по обучающему фрагменту набора данных, выполняется и проход по проверочному фрагменту. Полученные при проверке сведения об эффективности служат более объективным показателем улучшения работы модели. Процедура идентична процедуре обучения, но модель работает в режиме оценки и не обновляется в соответствии с проверочными данными.

После обучения модели возникает важная и непростая задача оценки эффективности ее работы. В разделе «Оценка эффективности моделей генерации после-

¹ В основном благодаря тому, что градиентный спуск и автоматическое дифференцирование — изящные абстракции, располагающиеся между определениями модели и их оптимизацией.