---
source_image: page_122.png
page_number: 122
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 33.02
tokens: 7658
characters: 2326
timestamp: 2025-12-24T02:24:27.456136
finish_reason: stop
---

Практическое применение предобученных вложений слов

Основная часть этой главы, а также остальная часть книги касается использования предобученных вложений слов. Предобученные с помощью одного из множества описанных выше методов на большом корпусе — например, на полном корпусе Google News, «Википедии» или Common Crawl¹ — вложения слов можно свободно скачать и использовать. Далее в главе мы покажем, как грамотно находить и загружать эти вложения, изучим некоторые свойства вложений слов и приведем примеры применения предобученных вложений слов в задачах NLP.

Загрузка вложений

Вложения слов стали настолько популярными и распространенными, что для скачивания доступно множество различных их вариантов, начиная с первоначального Word2Vec² до стэнфордского GloVe (https://stanford.io/2PSIvPZ), в том числе FastText³ компании Facebook (https://fasttext.cc/) и многие другие. Обычно вложения поставляются в следующем формате: каждая строка начинается со слова/типа, за которым идет последовательность чисел (то есть векторное представление). Длина этой последовательности равна размерности представления (размерности вложения). Размерность вложений обычно порядка сотен. Количество типов токенов чаще всего равно размеру словаря и составляет порядка миллиона. Например, вот первые семь измерений векторов dog и cat из GloVe.

<table>
  <tr>
    <th>dog</th>
    <td>-1.242 -0.360 0.573 0.367 0.600 -0.189 1.273 ...</td>
  </tr>
  <tr>
    <th>cat</th>
    <td>-0.964 -0.610 0.674 0.351 0.413 -0.212 1.380 ...</td>
  </tr>
</table>

Для эффективной загрузки и обработки вложений мы опишем вспомогательный класс PreTrainedEmbeddings (пример 5.1). В нем создается хранимый в оперативной памяти индекс всех векторов слов для упрощения быстрого поиска и запросов ближайших соседей с помощью пакета приближенного вычисления ближайших соседей, annoy.

¹ Common Crawl — лицензированный по лицензии Creative Commons корпус сосканированных сайтов, доступный по адресу commoncrawl.org.
² Word2Vec — набор методов вложения. В этой главе мы рассмотрим вложение типа «непрерывное мультимножество слов» из статьи Word2Vec. Чтобы скачать Word2Vec, перейдите по адресу https://goo.gl/ZER2d5.
³ На момент написания данной книги FastText — единственный из известных нам пакетов, предлагающий вложения на различных языках. И не только вложения.