---
source_image: page_044.png
page_number: 44
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 34.20
tokens: 7637
characters: 2228
timestamp: 2025-12-24T02:22:24.738089
finish_reason: stop
---

случаях можно переиспользовать тот же код, но уже рассматривая каждый из символов как токен¹.

Леммы и основы слов

Леммы (lemmas) — корневые формы слов. Рассмотрим слово fly. Склоняя его, можно получить множество различных слов — flow, flew, flies, flown, flowing и т. д., — и для всех этих, казалось бы, различных слов fly является леммой. Иногда бывает полезно свернуть токены до соответствующих лемм ради понижения размерности векторного представления. Такая свертка называется лемматизацией (lemmatization), посмотреть на нее в действии вы можете в примере 2.3.

Пример 2.3. Лемматизация: свертка слов до корневых форм²

<table>
  <tr>
    <th>Input[0]</th>
    <td>
      import spacy<br>
      nlp = spacy.load('en')<br>
      doc = nlp(u"he was running late")<br>
      for token in doc:<br>
        print('{} --> {}'.format(token, token.lemma_))
    </td>
  </tr>
  <tr>
    <th>Output[0]</th>
    <td>
      he --> he<br>
      was --> be<br>
      running --> run<br>
      late --> late
    </td>
  </tr>
</table>

В spaCy, например, для извлечения лемм применяется встроенный словарь под названием WordNet, но лемматизацию можно рассматривать как задачу машинного обучения, для решения которой требуется понимание морфологии языка.

Стемминг, или выделение основы (stemming) слова, — лемматизация «для бедных»³. Она включает получение общих форм (основ) слов путем использования самодельных правил для обрезания окончаний. В пакетах с открытым исходным кодом часто реализуются популярные стеммеры, включая стеммер Портера и SnowBall. Поиск нужных API spaCy/NLTK для стемминга оставим в качестве упражнения читателю.

¹ В главах 4 и 6 мы рассмотрим модели глубокого обучения, неявно схватывающие, причем достаточно эффективно, такую подструктуру.
² Не удивляйтесь, если первая строка полученных вами результатов будет отличаться от приведенной здесь и выглядеть так: he --> -PRON-.
С недавних пор spaCy свертывает все местоимения в специальный токен -PRON-(от англ. pronoun — «местоимение»). См. https://spacy.io/api/annotation/#lemmatization. — Примеч. пер.
³ Рассмотрим разницу между выделением основы и лемматизацией на примере слова «гуси». В результате лемматизации получается «гусь», а после стемминга — «гус».