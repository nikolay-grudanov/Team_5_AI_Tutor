---
source_image: page_160.png
page_number: 160
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 36.33
tokens: 7700
characters: 2738
timestamp: 2025-12-24T02:25:35.301816
finish_reason: stop
---

результатов SurnameVectorizer в мини-пакеты. Поскольку в этом примере реализация объекта DataLoader и его использование не отличаются от предыдущих, мы опустим подробности¹.

Класс SurnameVectorizer и токен END-OF-SEQUENCE

Процедура обучения для задачи предсказания последовательностей ожидает на входе две последовательности целочисленных значений, представляющие токены-наблюдения и целевые токены на каждом из временных шагов. Обычно необходимо предсказать ту же самую последовательность, на которой производится обучение, в нашем случае — фамилии. Это значит, что работать приходится только с одной последовательностью токенов и с одним предложением для формирования наблюдений и целей.

Чтобы сделать из этого задачу предсказания последовательностей, всем токенам с помощью SequenceVocabulary ставятся в соответствие индексы. Далее в начало последовательности добавляется индекс токена BEGIN-OF-SEQUENCE, begin_seq_index, а в ее конец — индекс токена END-OF-SEQUENCE, end_seq_index. На этом этапе каждая точка данных представляет собой последовательность индексов, причем первые и последние индексы одинаковы. Для создания необходимых для процедуры обучения входной и выходной последовательностей мы просто воспользуемся двумя срезами последовательности индексов: первый будет включать все индексы токенов, за исключением последнего, а второй — все индексы токенов, за исключением первого. После выравнивания и попарного сочетания эти последовательности станут подходящими индексами для входа-выхода.

Для большей ясности приведем код для метода SurnameVectorizer.vectorize() в примере 7.2. Первый этап — отображение строки символов surname в список indices соответствующих им целочисленных значений. Далее к indices добавляются индексы начала и конца последовательности: а именно, в начало indices добавляется begin_seq_index, а в конец — end_seq_index. Потом проверяем значение vector_length, которое обычно передается во время выполнения (хотя код написан так, что допускает любую длину вектора). Во время обучения наличие vector_length важно, поскольку мини-пакеты формируются на основе многоярусных векторных представлений. А если длины векторов различны, то уложить их в одну матрицу не получится. После проверки vector_length создаются два вектора: from_vector и to_vector. Срез индексов, не содержащий последнего индекса, помещается в from_vector, а срез индексов, не содержащий первого, — в to_vector. Оставшиеся позиции векторов заполняются mask_index. Важно, чтобы после-

¹ См. более подробную информацию о SequenceVocabulary в подразделе «Классы Vocabulary, Vectorizer и DataLoader» на с. 132 и вводное описание структур данных Vocabulary и Vectorizer в подразделе «Классы Vocabulary, Vectorizer и DataLoader» на с. 82.