---
source_image: page_028.png
page_number: 28
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 39.74
tokens: 7698
characters: 2760
timestamp: 2025-12-24T02:22:04.875256
finish_reason: stop
---

В глубоком обучении редко встречается кодирование входных данных с помощью эвристических представлений вроде TF-IDF, поскольку цель состоит именно в получении представления. Зачастую начинают с унитарного представления с целочисленными индексами и специального слоя «поиска вложений» (embedding lookup), чтобы сформировать входные данные для нейронной сети. В следующих главах мы рассмотрим несколько примеров этого.

Кодирование целевых переменных

Как отмечалось в разделе «Парадигма обучения с учителем» этой главы, конкретный характер целевой переменной зависит от решаемой задачи NLP. Например, в случаях машинного перевода, автоматического реферирования и формирования ответов на вопросы целевая переменная также представляет собой текст и кодируется с помощью подходов, аналогичных вышеописанному унитарному представлению.

Во множестве задач NLP используются дискретные метки в том случае, когда модель должна предсказывать одно значение из фиксированного набора. Они часто кодируются путем присвоения каждой метке уникального индекса, но такое простое представление становится проблематичным при наличии слишком большого количества выходных меток. В качестве примера можно привести задачу языкового моделирования (language modeling), цель которой — предсказать следующее слово по ранее наблюдавшимся словам. Пространство меток представляет собой весь словарный запас языка, который с легкостью может составлять несколько сотен тысяч слов, считая специальные символы, названия и т. д. Мы вернемся к этой задаче в следующих главах и посмотрим, как ее можно решить.

Некоторые задачи NLP требуют предсказания числового значения на основе заданного текста. Например, оценить удобочитаемость эссе на английском языке. По отрывку из отзыва о ресторане предсказать его числовой рейтинг с точностью до первого знака после запятой. По твитам какого-либо пользователя предсказать его возрастную группу. Существует несколько способов кодирования числовых целевых переменных, в том числе вполне приемлемый подход, при котором целевые переменные распределяются по дискретным корзинам — например, 0–18, 19–25, 25–30 и т. д., — как в простой задаче классификации¹. Распределение по таким корзинам может быть однородным или неоднородным, определяемым данными. Хотя подробное обсуждение этого вопроса выходит за рамки книги, мы обращаем на него ваше внимание, поскольку кодирование целевых переменных в подобных случаях разительно влияет на производительность. Рекомендуем вам почитать книгу Догерти и др. (1995), а также изучить приведенные там источники литературы.

¹ «Порядковая» классификация представляет собой задачу многоклассовой классификации с частичной упорядоченностью меток. В нашем примере с возрастом категория 0–18 предшествует категории 19–25 и т. д.