---
source_image: page_095.png
page_number: 95
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 30.32
tokens: 7597
characters: 2365
timestamp: 2025-12-24T02:23:41.749410
finish_reason: stop
---

наследуют класс Dataset фреймворка PyTorch, поэтому нам нужно реализовать два метода: __getitem__() , возвращающий точку данных по индексу, и __len__() , возвращающий длину набора данных. Различие этого примера и примера из главы 3 — в методе __getitem__() (пример 4.5). Он возвращает не векторизованный обзор, как в разделе «Пример: классификация тональностей обзоров ресторанов» на с. 76, а векторизованную фамилию и индекс соответствующей национальности.

Пример 4.5. Реализация метода SurnameDataset.__getitem__()

class SurnameDataset(Dataset):
    # Реализация практически идентична примеру 3.14

    def __getitem__(self, index):
        row = self._target_df.iloc[index]
        surname_vector = \
            self._vectorizer.vectorize(row.surname)
        nationality_index = \
            self._vectorizer.nationality_vocab.lookup_token(row.nationality)

        return {'x_surname': surname_vector,
                'y_nationality': nationality_index}

Классы Vocabulary, Vectorizer и DataLoader

Для классификации фамилий по символам мы воспользуемся классами Vocabulary, Vectorizer и DataLoader, чтобы преобразовать фамилии в виде строковых значений в векторизованные мини-пакеты. Мы используем те же структуры данных, что и в разделе «Пример: классификация тональностей обзоров ресторанов» на с. 76, демонстрируя тем самым полиморфизм, позволяющий обрабатывать символьные токены фамилий аналогично токенам-словам из обзоров Yelp. Вместо векторизации путем отображения токенов-слов в целочисленные значения данные векторизуются с помощью отображения символов в целочисленные значения.

Класс Vocabulary

Используемый в этом примере класс Vocabulary в точности аналогичен тому, который использовался в примере 3.16 для отображения слов обзоров Yelp в соответствующие целочисленные значения. Отметим, что Vocabulary представляет собой сочетание двух словарей Python, формирующих взаимно однозначное соответствие между токенами (в данном случае символьными) и целочисленными значениями; а именно, первый словарь задает соответствие символов целочисленным индексам, а второй задает соответствие целочисленных индексов символам. Метод add_token() служит для добавления новых токенов в Vocabulary, метод lookup_token() — для извлечения индекса, а lookup_index() — для извлечения токена по заданному индексу (что удобно в фазе вывода). В отличие от Vocabulary