---
source_image: page_011.png
page_number: 11
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 43.73
tokens: 7475
characters: 3389
timestamp: 2025-12-24T02:21:33.020581
finish_reason: stop
---

Глава 7. Продолжаем моделирование последовательностей для обработки текстов на естественных языках .................................................................................................................. 184
    Проблемы «наивных» RNN (RNN Элмана)..................................................................................... 185
    Пример: символьная RNN для генерации фамилий ................................................................. 188
        Класс SurnameDataset ............................................................................................................. 188
        Структуры данных для векторизации .................................................................................... 189
        От RNN Элмана к GRU ........................................................................................................ 192
    Модель 1. Контекстно не обусловленная модель SurnameGenerationModel ............................................. 192
    Модель 2. Контекстно обусловленная модель SurnameGenerationModel ............................................. 194
        Процедура обучения и результаты ......................................................................................... 195
    Полезные советы по обучению моделей последовательностей .................................................. 200
    Библиография .................................................................................................................................. 202

Глава 8. Продвинутое моделирование последовательностей для обработки текстов на естественных языках .................................................................................................................. 203
    Модели преобразования последовательностей в последовательности, модели типа «кодировщик-декодировщик» и контекстно обусловленная генерация ............................................................................................................................................. 203
    Захватываем больше информации из последовательности: двунаправленные рекуррентные модели ................................................................................................................................. 207
    Захватываем больше информации из последовательности: внимание ......................... 209
    Оценка эффективности моделей генерации последовательностей ................................. 213
    Пример: нейронный машинный перевод .................................................................................. 215
        Набор данных для машинного перевода ............................................................................. 216
        Конвейер векторизации для NMT ....................................................................................... 217
        Кодирование и декодирование в NMT-модели ................................................................. 221
        Процедура обучения и результаты ..................................................................................... 232
    Резюме ........................................................................................................................................... 234
    Библиография .................................................................................................................................. 235