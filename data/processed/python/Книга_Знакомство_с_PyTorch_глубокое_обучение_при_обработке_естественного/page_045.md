---
source_image: page_045.png
page_number: 45
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 23.11
tokens: 7406
characters: 1624
timestamp: 2025-12-24T02:22:14.955162
finish_reason: stop
---

Категоризация предложений и документов

Категоризация или классификации документов — одно из самых первых приложений NLP. Описанные в главе 1 представления TF и TF-IDF можно непосредственно применять для классификации и категоризации длинных фрагментов текста, таких как документы или предложения. Задачи вроде присвоения меток тем, предсказания тональностей обзоров, фильтрации спама в электронной почте, идентификации языков и сортировки электронной почты можно рассматривать как задачи классификации документов с учителем (очень удобны варианты с частичным обучением, когда используется лишь небольшой маркированный набор данных, но эта тема выходит за рамки данной книги).

Категоризация слов: маркирование частей речи

Концепцию маркирования можно распространить с документов на отдельные слова или токены. Распространенный пример категоризации слов — маркирование частей речи (part-of-speech, POS), показанное в примере 2.4.

Пример 2.4. Маркирование частей речи

Input[0]
import spacy
nlp = spacy.load('en')
doc = nlp(u"Mary slapped the green witch.")
for token in doc:
    print('{} - {}'.format(token, token.pos_))

Output[0]
Mary - PROPN
slapped - VERB
the - DET
green - ADJ
witch - NOUN
. - PUNCT

Категоризация отрезков текста: разбивка на порции и распознавание поименованных сущностей

Довольно часто бывает нужно маркировать отрезок текста, то есть непрерывную границу мультитокена (multitoken boundary). Например, рассмотрим предложение Mary slapped the green witch. Пусть необходимо выделить в нем именные (noun phrases, NP) и глагольные группы (verb phrases, VP):

[NP Mary] [VP slapped] [the green witch].