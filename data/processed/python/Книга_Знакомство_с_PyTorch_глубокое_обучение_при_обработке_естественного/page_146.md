---
source_image: page_146.png
page_number: 146
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 32.87
tokens: 7583
characters: 2222
timestamp: 2025-12-24T02:25:07.817305
finish_reason: stop
---

initial_hidden = initial_hidden.to(x_in.device)

hidden_t = initial_hidden

for t in range(seq_size):
    hidden_t = self.rnn_cell(x_in[t], hidden_t)
    hiddens.append(hidden_t)

hiddens = torch.stack(hiddens)

if self.batch_first:
    hiddens = hiddens.permute(1, 0, 2)

return hiddens

В RNN, помимо гиперпараметров, управляющих размером входных и скрытых векторов, есть булев аргумент, позволяющий указать, должно ли данное измерение находиться на месте нулевого. Этот флаг есть во всех реализациях RNN фреймворка PyTorch. Если он равен True, RNN меняет местами нулевое и первое измерения входного тензора.

Метод forward() в классе ElmanRNN проходит в цикле по входному тензору, вычисляя вектор скрытого состояния для каждого из временных шагов. Обратите внимание, что в нем есть аргумент для задания начального скрытого состояния, но если его не задать, то будет использоваться вектор скрытого состояния, состоящий из одних 0. При проходе в цикле по входному вектору класс ElmanRNN вычисляет новое скрытое состояние. Эти скрытые состояния агрегируются и в конце концов располагаются ярусами¹.

Перед их возвратом снова проверяется значение флага batch_first. Если оно равно True, выходные скрытые векторы переставляются так, что данные пакета снова будут находиться в нулевом измерении.

Выходные данные класса представляют собой трехмерный тензор — по вектору скрытого состояния для каждой точки данных в пакетном измерении и каждого шага по времени. Эти скрытые векторы можно использовать различными способами, в зависимости от имеющейся задачи. Один из этих способов: классификация с их помощью каждого из временных шагов по какому-либо дискретному набору вариантов. Данный метод означает, что веса RNN адаптируются к отслеживанию информации, связанной с предсказаниями на каждом из шагов. Кроме того, итоговый вектор можно использовать для классификации предложения в целом. Это значит, что веса RNN можно приспособить для отслеживания важной для итоговой классификации информации. В данной главе мы рассмотрим только классификацию, но в следующих двух главах изучим подробнее пошаговые предсказания.

¹ Обсуждение операции расположения ярусами PyTorch можно найти в подразделе «Операции над тензорами» на с. 35.