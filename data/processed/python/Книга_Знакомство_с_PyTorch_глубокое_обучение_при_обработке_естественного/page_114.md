---
source_image: page_114.png
page_number: 114
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 30.38
tokens: 7547
characters: 1825
timestamp: 2025-12-24T02:24:11.641379
finish_reason: stop
---

попакетно так, что их отклонения в отдельных пакетах ни на что сильно не влияют. Благодаря BatchNorm модели оказываются менее чувствительными к начальным параметрам, а подстройка скорости обучения упрощается (см. статью Иоффе и Шегеди [Ioffe, Szegedy, 2015]). Во фреймворке PyTorch BatchNorm описан в модуле nn. Пример 4.22 демонстрирует создание экземпляра и использование BatchNorm со сверткой и линейными слоями.

Пример 4.22. Использование слоя Conv1D с пакетной нормализацией

# ...
self.conv1 = nn.Conv1d(in_channels=1, out_channels=10,
    kernel_size=5,
    stride=1)
self.conv1_bn = nn.BatchNorm1d(num_features=10)
# ...

def forward(self, x):
    # ...
    x = F.relu(self.conv1(x))
    x = self.conv1_bn(x)
    # ...

Связи типа «сеть в сети» (свертки \(1 \times 1\))

Связи типа «сеть в сети» (network-in-network, NiN) — это сверточные ядра с kernel_size=1 и несколькими интересными свойствами. В частности, свертка \(1 \times 1\) ведет себя по отношению к каналам так же, как и полносвязный линейный слой\(^1\). Это удобно при отображении карт признаков с большим количеством каналов в менее «глубокие» карты признаков. На рис. 4.14 мы покажем применение отдельной связи типа NiN к входной матрице. Как вы можете видеть, два канала

![Пример операции свертки 1 × 1 в действии](../images/chapter_4/fig_4_14.png)

Входной тензор с двумя каналами и сверточное ядро типа «сеть в сети»

Ядро применяется к входному тензору

Выходная матрица

Рис. 4.14. Пример операции свертки \(1 \times 1\) в действии. Обратите внимание, как операция свертки \(1 \times 1\) уменьшает число каналов с двух до одного

\(^1\) Если вы вспомните предыдущие схемы, для каждого входящего канала есть по параметру, так что сверточное ядро с kernel_size=1 представляет собой вектор, размер которого соответствует количеству входящих каналов.