---
source_image: page_051.png
page_number: 51
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 20.34
tokens: 7309
characters: 1290
timestamp: 2025-12-24T02:22:20.014367
finish_reason: stop
---

Рис. 3.1. Граф вычислений для перцептрона с входом (x) и выходом (y). Параметры модели составляют веса (w) и смещение (b)

Обычно у перцептрона несколько входных значений. Для представления такого общего случая можно воспользоваться векторами. То есть x и w — векторы, а произведение x и w в вышеприведенной формуле заменяется их скалярным произведением:

\[
y = f(wx + b).
\]

Функция активации, обозначенная здесь f, обычно нелинейная. График линейной функции представляет собой прямую. В этом примере wx + b — линейная функция. Так что, по существу, перцептрон — композиция линейной и нелинейной функций. Линейное выражение wx + b называют также аффинным преобразованием (affine transform).

В примере 3.1 представлена реализация перцептрона с помощью фреймворка PyTorch, которая принимает произвольное число входных данных, выполняет аффинное преобразование, применяет функцию активации и генерирует одно выходное значение.

Пример 3.1. Реализация перцептрона с помощью PyTorch

import torch
import torch.nn as nn
class Perceptron(nn.Module):
    """ Перцептрон представляет собой один линейный слой """
    def __init__(self, input_dim):
        """
        Аргументы:
            input_dim (int): размер вектора входных признаков
        """
        super(Perceptron, self).__init__()