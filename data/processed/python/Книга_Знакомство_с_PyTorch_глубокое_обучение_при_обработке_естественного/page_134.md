---
source_image: page_134.png
page_number: 134
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 32.03
tokens: 7583
characters: 2320
timestamp: 2025-12-24T02:24:46.346450
finish_reason: stop
---

Оценка модели и получение предсказаний

Оценка в этом примере основывается на предсказании целевого слова по заданному контексту для каждого из целевых слов и пар контекстов в контрольном наборе¹. Правильно предсказанное слово означает, что модель обучилась предсказанию слов по контексту. В данном примере точность классификации целевых слов на контрольном наборе данных достигает 15 %. Этот результат не слишком высок по нескольким причинам. Во-первых, архитектура CBOW в примере должна была иллюстрировать конструирование универсальных вложений. Многие свойства исходной реализации были опущены, поскольку только вносили ненужные для изучения метода сложности (но при этом были необходимы для максимальной эффективности). Во-вторых, используемый набор данных очень мал — всего одна книга на примерно 70 000 слов, что совершенно недостаточно для выявления многих закономерностей при обучении с нуля. А созданные по последнему слову науки и техники вложения обычно обучаются на наборах данных, состоящих из терабайт текста².

В этом примере мы показали, как с помощью слоя nn.Embedding фреймворка PyTorch с нуля обучать вложения путем подготовки искусственной задачи обучения с учителем — классификации CBOW. В следующем примере мы выясним, как приспособить уже обученное на одном корпусе вложение к другой задаче. В МО использование модели, обученной на одной задаче, для решения другой называется переносом обучения (transfer learning).

Пример: перенос обучения для классификации документов с применением предобученных вложений

В предыдущем примере слой вложений использовался для простой классификации. Текущий пример расширяет его тремя способами: сначала загружает предобученные вложения слов, затем подгоняет их путем классификации целых статей из новостей и, наконец, с помощью сверточной нейронной сети улавливает пространственные связи между словами.

В этом примере мы воспользуемся набором данных AG News. Для моделирования последовательностей слов из AG News создадим вариант SequenceVocabulary класса Vocabulary, включающий нескольких специальных токенов, жизненно важных для моделирования предложений. Класс Vectorizer демонстрирует использование этого словаря.

¹ Состав набора данных описан в подразделе «Набор данных “Франкенштейн”» ранее.
² Набор данных Common Crawl содержит более 100 Тбайт данных.