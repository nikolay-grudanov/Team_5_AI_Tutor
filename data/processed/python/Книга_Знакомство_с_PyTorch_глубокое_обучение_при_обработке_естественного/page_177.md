---
source_image: page_177.png
page_number: 177
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 31.04
tokens: 7578
characters: 2221
timestamp: 2025-12-24T02:25:57.239925
finish_reason: stop
---

Захватываем больше информации из последовательности: двунаправленные рекуррентные модели

Рекуррентную модель для простоты можно рассматривать как черный ящик, кодирующий последовательность в вектор. При моделировании последовательности полезно наблюдать не только предыдущие слова, но и те слова, которые появятся в будущем¹. Рассмотрим следующее предложение²:

The man who hunts ducks out on the weekends.

Если модель читает это предложение строго слева направо, то ее представление слова ducks³ будет не таким, как у модели, читающей слова так же и еще справа налево. Люди постоянно подсознательно корректируют смысл подобным ретроспективным образом.

Информации из прошлого и будущего вместе достаточно для полноценного представления смысла слова в предложении. В этом и состоит цель двунаправленных рекуррентных моделей. В двунаправленной форме могут применяться любые модели из рекуррентного семейства — RNN Элмана, LSTM или GRU. Двунаправленные модели, как и их однонаправленные аналоги, рассмотренные в главах 6 и 7, можно использовать как для классификации, так и для маркировки последовательностей, при которой необходимо предсказать по одной метке для каждого слова из входных данных.

Рисунки 8.5 и 8.6 подробно иллюстрируют вышеописанное.

Обратите внимание на рис. 8.5, как модель «читает» предложение в двух направлениях и генерирует представление предложения φ, являющееся композицией прямого и обратного представлений. На этом рисунке не показан завершающий слой классификации, состоящий из линейного слоя и многомерной логистической функции.

φ_{love} на рис. 8.6 — представление (кодировка) скрытого состояния сети на временнóм шаге, когда входные данные представляют собой слово love. Эта информация

¹ В потоковых приложениях это невозможно, но NLP в любом случае часто применяется в пакетном (не потоковом) контексте.
² Предложения, подобные приведенному в этом примере, называются предложениями «с подвохом» (garden-path sentence) (https://en.wikipedia.org/wiki/Garden_path_sentence) и встречаются чаще, чем можно подумать; например, в заголовках газет подобные конструкции — обычное дело.
³ У английского слова duck есть как минимум два значения: «утка» (существительное) и «уклоняться» (глагол).