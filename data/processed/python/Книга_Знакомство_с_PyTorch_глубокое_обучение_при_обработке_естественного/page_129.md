---
source_image: page_129.png
page_number: 129
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 38.44
tokens: 7724
characters: 2664
timestamp: 2025-12-24T02:24:46.512665
finish_reason: stop
---

конвейер векторизации: от токенов до векторизованных мини-пакетов. После этого вкратце опишем модель классификации CBOW и применение слоя вложений. Далее мы рассмотрим процедуру обучения (хотя, если вы читали главы по порядку, она уже хорошо вам знакома). Наконец, попробуем оценить эффективность модели, обсудим ее вывод и способы ее проверки.

Набор данных «Франкенштейн»

Для этого примера мы сформируем текстовый набор данных на основе оцифрованной версии романа Мэри Шелли «Франкенштейн», доступной на сайте проекта «Гутенберг» (http://bit.ly/2T5iU8J). В подразделе мы обсудим предварительную обработку, создание класса Dataset фреймворка PyTorch для этого набора данных и, наконец, разбиение набора данных на обучающий, проверочный и контрольный наборы.

Начнем с неформатированного текстового файла и выполним минимальную предварительную обработку: воспользуемся лексическим анализатором Punkt из набора инструментов NLTK (http://bit.ly/2GvRO9j) для разбиения текста на отдельные предложения, после чего преобразуем все предложения в нижний регистр и удалим знаки пунктуации. Такая предварительная обработка позволит нам в дальнейшем разбить строковые значения по пробелам и получить список токенов (или лексем). Для нее мы снова воспользуемся функцией из раздела «Пример: классификация тональностей обзоров ресторанов» на с. 76.

Следующий этап: пронумеровать набор данных как последовательность окон для оптимизации модели CBOW. Для этого мы пройдем в цикле по списку токенов каждого из предложений и сгруппируем их в окна заданного размера¹, как наглядно показано на рис. 5.2.

Последний этап формирования набора данных: разбиение данных на обучающий, проверочный и контрольный наборы. Напомним, что обучающий и проверочный наборы используются при обучении модели: обучающий — для обновления параметров, а проверочный — для оценки эффективности модели². Контрольный

1 Точный размер окна представляет собой критически важный для CBOW гиперпараметр. При слишком большом размере окон модель перестанет улавливать закономерности, при слишком маленьким — может упустить из виду интересные зависимости.
2 Повторим, что не следует ни при каких обстоятельствах интерпретировать оценки эффективности, полученные на данных, на которых модель обучалась, как окончательные оценки эффективности модели. На проверочном наборе модель не обучается, так что эффективность ее работы на нем гораздо лучше отражает окончательную эффективность. Впрочем, ваши решения, как решения экспериментатора, могут оказаться необъективными при использовании данных об эффективности на проверочном наборе, а показатели эффективности модели — более высокими, чем были бы на новых данных.