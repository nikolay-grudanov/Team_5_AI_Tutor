---
source_image: page_091.png
page_number: 91
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 28.75
tokens: 7570
characters: 1932
timestamp: 2025-12-24T02:23:30.058273
finish_reason: stop
---

Пример 4.3. Тестирование MLP на случайных входных данных

Input[0]
def describe(x):
    print("Type: {}".format(x.type()))
    print("Shape/size: {}".format(x.shape))
    print("Values: \n{}".format(x))

x_input = torch.rand(batch_size, input_dim)
describe(x_input)

Output[0]
Type: torch.FloatTensor
Shape/size: torch.Size([2, 3])
Values:
tensor([[ 0.8329,  0.4277,  0.4363],
        [ 0.9686,  0.6316,  0.8494]])

Input[1]
y_output = mlp(x_input, apply_softmax=False)
describe(y_output)

Output[1]
Type: torch.FloatTensor
Shape/size: torch.Size([2, 4])
Values:
tensor([[-0.2456,  0.0723,  0.1589, -0.3294],
        [-0.3497,  0.0828,  0.3391, -0.4271]])

Важно разобраться, как читать входные и выходные данные моделей PyTorch. В предыдущем примере выходные данные модели MLP представляли собой тензор из двух строк и четырех столбцов. Строки тензора соответствуют измерению пакета — числу точек данных в мини-пакете. Столбцы — итоговые векторы признаков для каждой из точек данных¹. В некоторых случаях, например при классификации, вектор признаков является вектором предсказаний (prediction vector). Название «вектор предсказаний» означает, что он соответствует распределению вероятности. Судьба вектора предсказаний зависит от того, выполняем мы обучение или вывод. Во время обучения выходные данные используются «как есть», вместе с функцией потерь и представлением целевых меток классов². Мы обсудим это подробнее в разделе «Пример: классификация фамилий с помощью MLP» на с. 109.

¹ Иногда называемые «векторами представления».
² Выходные данные модели и функции потерь во фреймворке PyTorch должны быть согласованы между собой. Подробнее это описано в документации (http://bit.ly/2RFOIjM); например, там указано, какие функции потерь требуют предшествующего многомерной логистической функции вектора предсказаний, а какие — нет. Причины этого основываются на математических упрощениях и соображениях численной устойчивости.