---
source_image: page_158.png
page_number: 158
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 27.52
tokens: 7689
characters: 2354
timestamp: 2025-12-24T01:11:48.416390
finish_reason: stop
---

платформе или вы не можете полагаться на стандартную кодировку по причинам, связанным с переносимостью данных.

К счастью, все проще, чем могло показаться. Чтобы получить доступ к файлам, содержащим отличающийся от ASCII текст Unicode представленного ранее вида, мы просто передаем имя кодировки, если она не совпадает со стандартной кодировкой для имеющейся платформы. В таком режиме текстовые файлы Python автоматически кодируют при записи и декодируют при чтении согласно схеме кодировки, имя которой было предоставлено. В Python 3.x:

```python
>>> S = 'sp\xc4m'        # Текст Unicode, отличающийся от ASCII
>>> S
'spAm'
>>> S[2]                # Последовательность символов
'A'

>>> file = open('unidata.txt', 'w', encoding='utf-8')  # Записать/
    # закодировать текст UTF-8
>>> file.write(S)        # Записано 4 символа
4
>>> file.close()

>>> text = open('unidata.txt', encoding='utf-8').read()  # Прочитать/
    # декодировать текст UTF-8
>>> text
'spAm'
>>> len(text)            # 4 символа (кодовые точки)
4

Такое автоматическое кодирование и декодирование является тем, что обычно требуется. Поскольку файлы делают это при передаче, вы можете обрабатывать текст в памяти как простую строку символов, не заботясь о его источниках в кодировке Unicode. Однако при необходимости вы можете посмотреть, что действительно хранится в файле, перейдя в двоичный режим:

>>> raw = open('unidata.txt', 'rb').read()   # Читать закодированные байты
>>> raw
b'sp\xc3\x84m'
>>> len(raw)                              # 5 байтов в кодировке UTF-8
5

В случае, когда данные Unicode получаются не из файла (скажем, из сообщения электронной почты или через сетевое подключение), вы также можете их кодировать и декодировать вручную:

>>> text.encode('utf-8')                  # Вручную кодировать в байты
b'sp\xc3\x84m'
>>> raw.decode('utf-8')                   # Вручную декодировать в строку
'spAm'

Прием удобен, если нужно посмотреть, как текстовые файлы автоматически кодировали бы ту же самую строку для разных имен кодировок, и он представляет собой способ перевода данных в другие кодировки. В случае указания надлежащего имени кодировки отличающиеся байты в файлах декодируются в ту же самую строку в памяти:

>>> text.encode('latin-1')                # Байты отличаются от других
b'sp\xc4m'
>>> text.encode('utf-16')
b'\xff\xfe\x00p\x00\x04\x00m\x00'