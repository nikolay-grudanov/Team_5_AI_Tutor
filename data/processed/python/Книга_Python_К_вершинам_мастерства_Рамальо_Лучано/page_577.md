---
source_image: page_577.png
page_number: 577
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 76.07
tokens: 12212
characters: 2881
timestamp: 2025-12-24T02:02:10.648759
finish_reason: stop
---

Объезд блокирующих вызовов

<table>
  <tr>
    <th>Устройство</th>
    <th>Тактов ЦП</th>
    <th>Пропорциональная «человеческая» шкала</th>
  </tr>
  <tr>
    <td>Кэш L2</td>
    <td>14</td>
    <td>14 секунд</td>
  </tr>
  <tr>
    <td>ОЗУ</td>
    <td>250</td>
    <td>250 секунд</td>
  </tr>
  <tr>
    <td>диск</td>
    <td>41 000 000</td>
    <td>1,3 года</td>
  </tr>
  <tr>
    <td>сеть</td>
    <td>240 000 000</td>
    <td>7,6 лет</td>
  </tr>
</table>

Чтобы правильно понять табл. 18.1, имейте в виду, что для современных процессоров с гигагерцевой частотой количество тактов измеряется миллиардами в секунду. Допустим, что частота процессора в точности равна миллиарду тактов в секунду. Такой процессор в секунду выполнит 333 333 333 операций чтения из кэша L1 или только 4 (четыре!) операции чтения из сети. В третьей колонке эти числа приведены к более привычной шкале путем умножения на постоянный коэффициент. То есть в альтернативной вселенной, где одно чтение из кэша L1 занимает 3 секунды, для чтения из сети понадобилось бы 7,6 лет!

Есть два способа не дать блокирующим вызовам остановить работу всего приложения:

• запускать каждую блокирующую операцию в отдельном потоке;
• преобразовать каждую блокирующую операцию в неблокирующий асинхронный вызов.

Потоки — вещь хорошая, но накладные расходы на каждый поток ОС (а именно они используются в Python) измеряются мегабайтами, в зависимости от ОС. Мы не можем позволить себе заводить по одному потоку на каждое соединение, если таких соединений тысячи.

Обратные вызовы — традиционный способ реализации асинхронности с низким потреблением памяти. Это низкоуровневая концепция, которую можно сравнить со старейшим и самым примитивным механизмом конкурентности: аппаратными прерываниями. Вместо того чтобы терпеливо ждать ответа, мы регистрируем функцию, которая должна быть вызвана, когда произойдет что-то интересное. При таком подходе все вызовы оказываются неблокирующими. Райан Дал рачивает обратные вызовы за их простоту и низкие накладные расходы.

Разумеется, чтобы обратные вызовы работали, необходим цикл обработки событий, опирающийся на ту или иную инфраструктуру: прерывания, потоки, опрос, фоновые процессы и т. д. Только так можно гарантировать, что обработка всех параллельных запросов будет происходить и в конечном счете завершится5. Получив ответ, цикл обработки событий вызывает наш код. Но единственный главный поток, в котором работает и цикл обработки, и код приложения, никогда не блокируется — если, конечно, мы сами не сделаем ошибку.

5 Node.js не поддерживает потоки пользовательского уровня, написанные на JavaScript, но за кулисами для реализации файлового API на базе обратных вызовов в нем используется пул потоков на основе написанной на С библиотеки. Это связано с тем, что в 2014 году в большинстве ОС не было стабильного и переносимого API для асинхронной работы с файлами.