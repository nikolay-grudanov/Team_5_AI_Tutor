---
source_image: page_601.png
page_number: 601
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 55.30
tokens: 12047
characters: 2914
timestamp: 2025-12-24T02:02:53.150227
finish_reason: stop
---

Резюме

Большая часть кода, необходимого для отправки результатов порциями, будет находиться на стороне браузера. Именно поэтому Google и вообще все крупные сайты в Интернете содержат так много клиентского кода: интеллектуальные асинхронные клиенты более эффективно используют ресурсы сервера.

Хотя интеллектуальные клиенты могут улучшить даже Django-приложения, написанные по старинке, для полноценного использования всех их возможностей необходима поддержка асинхронного программирования на всех стадиях: от обработки HTTP-запросов и ответов до доступа к базе данных. Особенно это относится к реализации служб реального времени, например игр или потокового мультимедиа, с помощью технологии WebSockets10.

Реализацию поддержки прогрессивной загрузки в скрипте http_charfinder.py я оставляю в качестве упражнения для читателя. Бонусные очки тому, кто сумеет сделать «бесконечную прокрутку», как в Твиттере. Этим вызовом я и завершу рассмотрение конкурентного программирования с применением пакета asyncio.

Резюме

В этой главе мы познакомились с совершенно новой технологией конкурентного программирования в Python, в которой используются выражения yield from, сопрограммы, будущие объекты и цикл обработки событий asyncio. На первых простых примерах анимированного индикатора мы провели сравнение подходов на основе пакетов threading и asyncio.

Затем мы обсудили специфику класса asyncio.Future, обратив особое внимание на поддержку yield from и связи с сопрограммами и классом asyncio.Task. Далее мы проанализировали скрипт загрузки флагов на основе пакета asyncio.

После этого мы поразмышляли над приведенными Райаном Далом данными о задержке ввода-вывода и последствиях блокирующих вызовов. Чтобы написать программу, которая будет продолжать обслуживание запросов, несмотря на неизбежное присутствие блокирующих функций, у нас есть два подхода: потоки и асинхронные вызовы, причем последний вариант можно реализовать с помощью обратных вызовов или сопрограмм.

На практике асинхронные библиотеки опираются на низкоуровневые — вплоть до уровня ядра — потоки, но пользователь такой библиотеки никаких потоков не создает и даже не обязан знать об их использовании в инфраструктуре. На уровне приложения мы лишь должны следить за тем, чтобы наш собственный код не блокировал выполнение, а о параллелизме позаботится цикл обработки событий. Исключение накладных расходов, сопряженных с потоками пользовательского уровня, и есть основная причина того, что асинхронные системы способны обрабатывать больше одновременных подключений, чем многопоточные

Для того чтобы добавить в скрипт загрузки флагов индикатор хода выполнения и обработку ошибок, его пришлось существенно переработать и, прежде всего, перейти от метода asyncio.wait к методу asyncio.as_completed. Это заставило нас перенести значительную часть функциональности из функции download_many в

10 Я еще вернусь к этой теме на врезке «Поговорим» ниже.