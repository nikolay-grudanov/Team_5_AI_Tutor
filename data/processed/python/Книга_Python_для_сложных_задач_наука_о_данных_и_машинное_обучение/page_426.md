---
source_image: page_426.png
page_number: 426
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 25.87
tokens: 7371
characters: 1530
timestamp: 2025-12-24T01:02:14.195458
finish_reason: stop
---

y_test = model.fit(X, y).predict(X_test)
plt.plot(X_test.ravel(), y_test, hold=True);
plt.axis(lim);

![Оптимальная модель, определенная посредством автоматического поиска по сетке](../images/5_34.png)

Рис. 5.34. Оптимальная модель, определенная посредством автоматического поиска по сетке

У поиска по сетке имеется множество опций, включая возможности задания пользовательской функции оценки эффективности, распараллеливания вычислений, выполнения случайного поиска и др. Для получения дополнительной информации см. примеры в разделах «Заглянем глубже: ядерная оценка плотности распределения» и «Прикладная задача: конвейер распознавания лиц» данной главы или обратитесь к документации библиотеки Scikit-Learn, посвященной поиску по сетке (http://scikit-learn.org/stable/modules/grid_search.html).

Резюме

В этом разделе мы приступили к изучению понятий проверки модели и оптимизации гиперпараметров, фокусируя внимание на наглядных аспектах компромисса между систематической ошибкой и дисперсией и его работы при подгонке моделей к данным. В частности, мы обнаружили, что крайне важно использовать проверочный набор или перекрестную проверку при настройке параметров, чтобы избежать переобучения более сложных/гибких моделей.

В следующих разделах мы детально рассмотрим некоторые особенно удобные модели, попутно обсуждая имеющиеся возможности их настройки и влияние этих свободных параметров на сложность модели. Не забывайте уроки этого раздела при дальнейшем чтении книги и изучении упомянутых методов машинного обучения!