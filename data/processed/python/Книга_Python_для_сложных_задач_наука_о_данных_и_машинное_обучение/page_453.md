---
source_image: page_453.png
page_number: 453
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 27.63
tokens: 7429
characters: 1476
timestamp: 2025-12-24T01:02:58.018708
finish_reason: stop
---

Хотя концептуально эта регрессия очень близка к гребневой, результаты их могут очень сильно различаться. Например, по геометрическим причинам лассо-регрессия любит разреженные модели, то есть она по возможности делает коэффициенты модели равными нулю.

Посмотреть на поведение этой регрессии мы можем, воспроизведя показанный на рис. 5.49 график, но с использованием коэффициентов, нормализованных с помощью нормы L₁ (рис. 5.50):

In[13]: from sklearn.linear_model import Lasso
    model = make_pipeline(GaussianFeatures(30), Lasso(alpha=0.001))
    basis_plot(model, title='Lasso Regression') # Лассо-регуляризация

![Применение лассо-регуляризации к слишком сложной модели](https://i.imgur.com/3Q5z5QG.png)

Рис. 5.50. Применение лассо-регуляризации к слишком сложной модели (ср. с рис. 5.48)

При использовании штрафа лассо-регрессии большинство коэффициентов в точности равны нулю, а функциональное поведение моделируется небольшим подмножеством из имеющихся базисных функций. Как и в случае гребневой регуляризации, параметр управляет уровнем штрафа и его следует определять путем перекрестной проверки (см. раздел «Гиперпараметры и проверка модели» данной главы).

Пример: предсказание велосипедного трафика

В качестве примера посмотрим, сможем ли мы предсказать количество пересекающих Фримонтский мост в Сиэтле велосипедов, основываясь на данных о погоде, времени года и других факторах. Мы уже работали с этими данными в разделе «Работа с временными рядами» главы 3.