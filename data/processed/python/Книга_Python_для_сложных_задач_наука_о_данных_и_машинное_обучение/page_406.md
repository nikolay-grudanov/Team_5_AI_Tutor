---
source_image: page_406.png
page_number: 406
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 33.69
tokens: 7506
characters: 1988
timestamp: 2025-12-24T01:01:48.260382
finish_reason: stop
---

(отображаемые фиолетовым) практически не пересекаются в параметрическом пространстве. На интуитивном уровне это представляется вполне логичным: нули содержат пустое место в середине изображения, а у единиц там, наоборот, чернила. С другой стороны, единицы и четверки на графике располагаются сплошным спектром, что понятно, ведь некоторые люди рисуют единицы со «шляпками», из-за чего они становятся похожи на четверки.

В целом различные группы достаточно хорошо разнесены в параметрическом пространстве. Это значит, что даже довольно простой алгоритм классификации с учителем должен работать на них достаточно хорошо.

Классификация цифр

Применим алгоритм классификации к нашим цифрам. Как и в случае с набором данных Iris, разобьем данные на обучающую и контрольную последовательности, после чего обучим на первой из них Гауссову наивную байесовскую модель таким образом:

In[28]: Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, random_state=0)

In[29]: from sklearn.naive_bayes import GaussianNB
    model = GaussianNB()
    model.fit(Xtrain, ytrain)
    y_model = model.predict(Xtest)

Теперь, осуществив предсказания по нашей модели, мы можем оценить ее точность, сравнив настоящие значения из контрольной последовательности с предсказанными:

In[30]: from sklearn.metrics import accuracy_score
    accuracy_score(ytest, y_model)

Out[30]: 0.8333333333333337

Даже при такой исключительно простой модели мы получили более чем 80%-ную точность классификации цифр! Однако из одного числа сложно понять, где наша модель ошиблась. Для этой цели удобна так называемая матрица различий (confusion matrix), вычислить которую можно с помощью библиотеки Scikit-Learn, а нарисовать посредством Seaborn (рис. 5.20):

In[31]: from sklearn.metrics import confusion_matrix
    mat = confusion_matrix(ytest, y_model)
    sns.heatmap(mat, square=True, annot=True, cbar=False)
    plt.xlabel('predicted value') # Прогнозируемое значение
    plt.ylabel('true value');      # Настоящее значение