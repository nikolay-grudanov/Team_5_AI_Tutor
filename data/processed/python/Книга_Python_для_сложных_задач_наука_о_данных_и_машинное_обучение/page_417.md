---
source_image: page_417.png
page_number: 417
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 33.13
tokens: 7507
characters: 1995
timestamp: 2025-12-24T01:02:09.039206
finish_reason: stop
---

Кривая проверки достигает максимума в какой-то промежуточной точке. Этот уровень сложности означает приемлемый компромисс между систематической ошибкой и дисперсией.

Средства регулирования сложности модели различаются в зависимости от модели. Как осуществлять подобную регулировку для каждой из моделей, мы увидим в следующих разделах, когда будем обсуждать конкретные модели подробнее.

Кривые проверки в библиотеке Scikit-Learn

Рассмотрим пример перекрестной проверки для расчета кривой проверки для класса моделей. Мы будем использовать модель полиномиальной регрессии (polynomial regression model): это обобщенная линейная модель с параметризованной степенью многочлена. Например, многочлен 1-й степени аппроксимирует наши данные прямой линией; при параметрах модели \(a\) и \(b\):

\[
y = ax + b.
\]

Многочлен 3-й степени аппроксимирует наши данные кубической кривой; при параметрах модели \(a, b, c, d\):

\[
y = ax^3 + bx^2 + cx + d.
\]

Это можно обобщить на любое количество полиномиальных признаков. В библиотеке Scikit-Learn реализовать это можно с помощью простой линейной регрессии в сочетании с полиномиальным препроцессором. Мы воспользуемся конвейером (pipeline) для соединения этих операций в единую цепочку (мы обсудим полиномиальные признаки и конвейеры подробнее в разделе «Проектирование признаков» данной главы):

In[10]: from sklearn.preprocessing import PolynomialFeatures
        from sklearn.linear_model import LinearRegression
        from sklearn.pipeline import make_pipeline

        def PolynomialRegression(degree=2, **kwargs):
            return make_pipeline(PolynomialFeatures(degree),
                                 LinearRegression(**kwargs))

Теперь создадим данные, на которых будем обучать нашу модель:

In[11]: import numpy as np

    def make_data(N, err=1.0, rseed=1):
        # Создаем случайные выборки данных
        rng = np.random.RandomState(rseed)
        X = rng.rand(N, 1) ** 2
        y = 10 - 1. / (X.ravel() + 0.1)
        if err > 0: