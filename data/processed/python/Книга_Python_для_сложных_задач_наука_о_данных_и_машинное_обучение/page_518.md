---
source_image: page_518.png
page_number: 518
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 38.65
tokens: 7615
characters: 2205
timestamp: 2025-12-24T01:04:51.339977
finish_reason: stop
---

Заглянем глубже: кластеризация методом k-средних

В нескольких предыдущих разделах мы рассматривали только одну разновидность машинного обучения без учителя — понижение размерности. В этом разделе мы перейдем к другому классу моделей машинного обучения без учителя — алгоритмам кластеризации. Алгоритмы кластеризации нацелены на то, чтобы найти, исходя из свойств данных, оптимальное разбиение или дискретную маркировку групп точек.

В библиотеке Scikit-Learn и других местах имеется множество алгоритмов кластеризации, но, вероятно, наиболее простой для понимания — алгоритм кластеризации методом k-средних (k-means clustering), реализованный в классе sklearn.cluster.KMeans. Начнем с обычных импортов:

In[1]: %matplotlib inline
    import matplotlib.pyplot as plt
    import seaborn as sns; sns.set()  # для стилизации графиков
    import numpy as np

Знакомство с методом k-средних

Алгоритм k-средних выполняет поиск заранее заданного количества кластеров в немаркированном многомерном наборе данных. Достигается это с помощью простого представления о том, что такое оптимальная кластеризация.

□ «Центр кластера» — арифметическое среднее всех точек, относящихся к этому кластеру.
□ Каждая точка ближе к центру своего кластера, чем к центрам других кластеров.

Эти два допущения составляют основу модели метода k-средних. Далее мы рассмотрим детальнее, каким именно образом алгоритм находит это решение, а пока возьмем простой набор данных и посмотрим на результаты работы метода k-средних для него.

Во-первых, сгенерируем двумерный набор данных, содержащий четыре отдельных « пятна ». Чтобы подчеркнуть отсутствие учителя в этом алгоритме, мы не будем включать метки в визуализацию (рис. 5.110):

In[2]: from sklearn.datasets.samples_generator import make_blobs
    X, y_true = make_blobs(n_samples=300, centers=4,
        cluster_std=0.60, random_state=0)
    plt.scatter(X[:, 0], X[:, 1], s=50);

Визуально выделить здесь четыре кластера не представляет труда. Алгоритм k-средних делает это автоматически, используя в библиотеке Scikit-Learn API статистических оценок:

In[3]: from sklearn.cluster import KMeans
    kmeans = KMeans(n_clusters=4)
    kmeans.fit(X)
    y_kmeans = kmeans.predict(X)