---
source_image: page_490.png
page_number: 490
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 21.31
tokens: 7281
characters: 1268
timestamp: 2025-12-24T01:03:51.623846
finish_reason: stop
---

Нарисовав эти главные компоненты рядом с исходными данными, получаем графики, показанные на рис. 5.82.

![Преобразованные главные оси данных](https://i.imgur.com/3Q5z5QG.png)

Рис. 5.82. Преобразованные главные оси данных

Это преобразование от осей координат данных к главным осям представляет собой аффинное преобразование (affine transformation). По существу, это значит, что оно состоит из сдвига (translation), вращения (rotation) и пропорционального масштабирования (uniform scaling).

Хотя этот алгоритм поиска главных компонент может показаться всего лишь математической диковиной, оказывается, что у него есть весьма перспективные приложения в сфере машинного обучения и исследования данных.

PCA как метод понижения размерности

Использование метода PCA для понижения размерности включает обнуление одной или нескольких из наименьших главных компонент, в результате чего данные проецируются на пространство меньшей размерности с сохранением максимальной дисперсии данных.

Вот пример использования PCA в качестве понижающего размерность преобразования:

In[7]: pca = PCA(n_components=1)
pca.fit(X)
X_pca = pca.transform(X)
print("original shape:    ", X.shape)
print("transformed shape:", X_pca.shape)

original shape:    (200, 2)
transformed shape: (200, 1)