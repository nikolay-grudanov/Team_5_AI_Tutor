---
source_image: page_452.png
page_number: 452
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 24.85
tokens: 7376
characters: 1310
timestamp: 2025-12-24T01:02:55.079940
finish_reason: stop
---

\[
P = \alpha \sum_{n=1}^{N} \theta_n^2,
\]
где \( \alpha \) — свободный параметр, служащий для управления уровнем штрафа. Этот тип модели со штрафом встроен в библиотеку Scikit-Learn в виде оценивателя Ridge (рис. 5.49):

In[12]: from sklearn.linear_model import Ridge
    model = make_pipeline(GaussianFeatures(30), Ridge(alpha=0.1))
    basis_plot(model, title='Ridge Regression') # Гребневая регрессия

![Гребневая регрессия](https://i.imgur.com/3Q5z5QG.png)

Рис. 5.49. Применение гребневой (\( L_2 \)) регуляризации к слишком сложной модели (ср. с рис. 5.48)

Параметр \( \alpha \) служит для управления сложностью получаемой в итоге модели. В предельном случае \( \alpha \to 0 \) мы получаем результат, соответствующий стандартной линейной регрессии; в предельном случае \( \alpha \to \infty \) будет происходить подавление любого отклика модели. Достоинства гребневой регрессии включают, помимо прочего, возможность ее эффективного расчета — вычислительные затраты практически не превышают затрат на расчет исходной линейной регрессионной модели.

Лассо-регуляризация (\( L_1 \))

Еще один распространенный тип регуляризации — так называемая лассо-регуляризация, включающая штрафование на сумму абсолютных значений (\( L_1 \)-норма) коэффициентов регрессии:

\[
P = \alpha \sum_{n=1}^{N} |\theta_n|.
\]