---
source_image: page_484.png
page_number: 484
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 23.28
tokens: 7365
characters: 1397
timestamp: 2025-12-24T01:03:41.961735
finish_reason: stop
---

На этом рисунке настоящая модель показана гладкой, а модель на основе случайного леса — «рваной» кривой. Как вы можете видеть, непараметрическая модель на основе случайного леса достаточно гибка для аппроксимации мультипериодических данных, без необходимости использования мультипериодической модели!

![Аппроксимация данных моделью на основе случайного леса](../images/5_77.png)

Рис. 5.77. Аппроксимация данных моделью на основе случайного леса

Пример: использование случайного леса для классификации цифр

Ранее мы уже видели данные по рукописным цифрам (см. раздел «Знакомство с библиотекой Scikit-Learn» этой главы). Воспользуемся ими снова, чтобы посмотреть на применение классификатора на основе случайных лесов в данном контексте.

In[12]: from sklearn.datasets import load_digits
    digits = load_digits()
    digits.keys()

Out[12]: dict_keys(['target', 'data', 'target_names', 'DESCR', 'images'])

В качестве напоминания, с чем мы имеем дело, визуализируем несколько первых точек данных (рис. 5.78):

In[13]:
# Настройки рисунка
fig = plt.figure(figsize=(6, 6))  # размер рисунка в дюймах
fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)

# Рисуем цифры: размер каждого изображения 8 x 8 пикселов
for i in range(64):
    ax = fig.add_subplot(8, 8, i + 1, xticks=[], yticks=[])
    ax.imshow(digits.images[i], cmap=plt.cm.binary, interpolation='nearest')