---
source_image: page_477.png
page_number: 477
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 21.39
tokens: 7307
characters: 1310
timestamp: 2025-12-24T01:03:30.268914
finish_reason: stop
---

Рис. 5.68. Данные для классификатора на основе дерева принятия решений

Простое дерево принятия решений для этих данных будет многократно разделять данные по одной или нескольким осям, в соответствии с определенным количественным критерием, и на каждом уровне маркировать новую область согласно большинству лежащих в ней точек. На рис. 5.69 приведена визуализация первых четырех уровней классификатора для этих данных, созданного на основе дерева принятия решений.

depth = 1        depth = 2        depth = 3        depth = 4

![Визуализация разбиения данных деревом принятия решений](https://i.imgur.com/1234567.png)

Рис. 5.69. Визуализация разбиения данных деревом принятия решений

Обратите внимание, что после первого разбиения все точки в верхней ветке остаются неизменными, поэтому необходимости в дальнейшем ее разбиении нет. За исключением узлов, в которых присутствует только один цвет, на каждом из уровней все области снова разбиваются по одному из двух признаков.

Процесс обучения дерева принятия решений на наших данных можно выполнить в Scikit-Learn с помощью оценивателя DecisionTreeClassifier:

In[3]: from sklearn.tree import DecisionTreeClassifier
    tree = DecisionTreeClassifier().fit(X, y)

Напишем небольшую вспомогательную функцию, чтобы облегчить визуализацию вывода классификатора: