---
source_image: page_480.png
page_number: 480
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 18.54
tokens: 7256
characters: 1084
timestamp: 2025-12-24T01:03:30.374605
finish_reason: stop
---

Рис. 5.72. Пример двух случайных деревьев принятия решений

Очевидно, что в некоторых местах результаты этих двух деревьев не противоречат друг другу (например, в четырех углах), а в других местах их классификации очень сильно различаются (например, в областях между любыми двумя кластерами). Важнейший вывод из этого рисунка: расхождения имеют тенденцию появляться в тех местах, где степень достоверности классификации ниже, а значит, мы можем добиться лучшего результата, используя информацию из обоих деревьев!

При применении интерактивного блокнота можно воспользоваться следующей функцией для интерактивного отображения деревьев, обученных на случайных подмножествах набора данных (рис. 5.73):

In[7]: # Модуль helpers_05_08 можно найти в онлайн-приложении к книге
    # (https://github.com/jakevdp/PythonDataScienceHandbook)
    import helpers_05_08
    helpers_05_08.randomized_tree_interactive(X, y)

Рис. 5.73. Первый кадр интерактивного виджета случайного дерева принятия решений. Полную версию см. в онлайн-приложении (https://github.com/jakevdp/PythonDataScienceHandbook)