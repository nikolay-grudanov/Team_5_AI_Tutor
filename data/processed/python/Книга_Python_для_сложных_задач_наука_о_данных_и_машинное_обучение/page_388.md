---
source_image: page_388.png
page_number: 388
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 25.27
tokens: 7409
characters: 1611
timestamp: 2025-12-24T01:01:14.515521
finish_reason: stop
---

Среди других важных алгоритмов кластеризации — смесь Гауссовых распределений (см. раздел «Заглянем глубже: смеси Гауссовых распределений» этой главы) и спектральная кластеризация (см. документацию по кластеризации библиотеки Scikit-Learn, http://scikit-learn.org/stable/modules/clustering.html).

Данные, маркированные с помощью модели кластеризации

![Данные, маркированные с помощью модели кластеризации методом k-средних](../images/chapter5/fig_5_9.png)

Рис. 5.9. Данные, маркированные с помощью модели кластеризации методом \( k \)-средних

Понижение размерности

Понижение размерности — еще один пример алгоритма обучения без учителя, в котором метки или другая информация определяются исходя из структуры самого набора данных. Алгоритм понижения размерности несколько труднее для понимания, чем рассмотренные нами ранее примеры, но он заключается в попытке получения представления низкой размерности, которое бы в какой-то мере сохраняло существенные качества полного набора данных. Различные алгоритмы понижения размерности оценивают существенность этих качеств по-разному, как мы увидим далее в разделе «Заглянем глубже: обучение на базе многообразий» этой главы.

В качестве примера рассмотрим данные, показанные на рис. 5.10. Зрительно очевидно, что у таких данных есть внутренняя структура: они получены из одномерной прямой, расположенной в двумерном пространстве в виде спирали. В некотором смысле можно сказать, что эти данные по своей внутренней сути одномерны, но вложены в пространство большей размерности. Подходящая модель понижения размерности в таком случае должна учитывать эту нелинейную