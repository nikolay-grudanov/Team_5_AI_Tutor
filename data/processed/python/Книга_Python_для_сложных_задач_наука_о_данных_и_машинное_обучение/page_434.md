---
source_image: page_434.png
page_number: 434
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 28.64
tokens: 7501
characters: 1747
timestamp: 2025-12-24T01:02:30.337894
finish_reason: stop
---

In[16]: model = LinearRegression().fit(X2, y)
    model.predict(X2)

Out[16]:
array([ 13.14869292,   14.3784627 ,  -1.15539732,  10.96606197,  -5.33782027])

Конвейеры признаков

Во всех предыдущих примерах может быстро надоест выполнять преобразования вручную, особенно если нужно связать цепочкой несколько шагов. Например, нам может понадобиться следующий конвейер обработки.

1. Внести вместо отсутствующих данных средние значения.
2. Преобразовать признаки в квадратичные.
3. Обучить модель линейной регрессии.

Для организации потоковой обработки подобного конвейера библиотека Scikit-Learn предоставляет объект конвейера, который можно использовать следующим образом:

In[17]: from sklearn.pipeline import make_pipeline

    model = make_pipeline(Imputer(strategy='mean'),
        PolynomialFeatures(degree=2),
        LinearRegression())

Этот конвейер выглядит и функционирует аналогично обычному объекту библиотеки Scikit-Learn, и выполняет все заданные шаги для любых входных данных.

In[18]: model.fit(X, y)  # Вышеприведенный массив X с пропущенными значениями
    print(y)
    print(model.predict(X))

[1416 -1  8 -5]
[ 14.  16.  -1.   8.  -5.]

Все шаги этой модели выполняются автоматически. Обратите внимание, что для простоты демонстрации мы применили модель к тем данным, на которых она была обучена, именно поэтому она сумела столь хорошо предсказать результат (более подробное обсуждение этого вопроса можно найти в разделе «Гиперпараметры и проверка модели» данной главы).

Некоторые примеры работы конвейеров библиотеки Scikit-Learn вы увидите в следующем разделе, посвященном наивной байесовской классификации, а также в разделах «Заглянем глубже: линейная регрессия» и «Заглянем глубже: метод опорных векторов» этой главы.