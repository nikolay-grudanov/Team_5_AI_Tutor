---
source_image: page_525.png
page_number: 525
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 21.20
tokens: 7323
characters: 1365
timestamp: 2025-12-24T01:04:41.745500
finish_reason: stop
---

Рис. 5.117. Нелинейные границы, обнаруженные с помощью SpectralClustering

Метод k-средних работает довольно медленно в случае большого количества выборок. Алгоритм может работать довольно медленно при росте числа выборок, ведь при каждой итерации методу k-средних необходимо обращаться к каждой точке в наборе данных. Интересно, можно ли смягчить это требование относительно использования всех данных при каждой итерации? Например, можно применить лишь подмножество данных для корректировки центров кластеров на каждом шаге. Эта идея лежит в основе пакетных алгоритмов k-средних, один из которых реализован в классе sklearn.cluster.MiniBatchKMeans. Их интерфейс не отличается от обычного KMeans. В дальнейшем мы рассмотрим пример их использования.

Примеры

При соблюдении некоторой осторожности в плане вышеупомянутых ограничений можно успешно использовать метод k-средних во множестве ситуаций. Рассмотрим несколько примеров.

Пример 1: применение метода k-средних для рукописных цифр

Для начала рассмотрим применение метода k-средних к тем же простым данным по цифрам, которые мы уже видели в разделах «Заглянем глубже: деревья принятия решений и случайные леса» и «Заглянем глубже: метод главных компонент» данной главы. Мы попробуем воспользоваться методом k-средних для распознания схожих цифр без использования информации об исходных метках. Это напоминает