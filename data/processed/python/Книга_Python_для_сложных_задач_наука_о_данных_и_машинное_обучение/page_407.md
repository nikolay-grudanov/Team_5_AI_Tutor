---
source_image: page_407.png
page_number: 407
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 24.61
tokens: 7346
characters: 1357
timestamp: 2025-12-24T01:01:39.240270
finish_reason: stop
---

Рис. 5.20. Матрица различий, демонстрирующая частоты ошибочных классификаций нашего классификатора

Этот рисунок демонстрирует нам места, в которых наш классификатор склонен ошибаться, например, значительное количество двоек ошибочно классифицированы как единицы или восьмерки. Другой способ получения информации о характеристиках модели — построить график входных данных еще раз вместе с предсказанными метками. Мы будем использовать зеленый цвет для правильных меток, и красный — для ошибочных (рис. 5.21):

In[32]: fig, axes = plt.subplots(10, 10, figsize=(8, 8),
    subplot_kw={'xticks':[], 'yticks':[]},
    gridspec_kw=dict(hspace=0.1, wspace=0.1))

for i, ax in enumerate(axes.flat):
    ax.imshow(digits.images[i], cmap='binary',
        interpolation='nearest')
    ax.text(0.05, 0.05, str(y_model[i]),
        transform=ax.transAxes,
        color='green' if (ytest[i] == y_model[i]) else 'red')

Из этого подмножества данных можно почерпнуть полезную информацию относительно мест, в которых алгоритм работает неоптимально. Чтобы поднять нашу точность выше 80 %, можно воспользоваться более сложным алгоритмом, таким как метод опорных векторов (см. раздел «Заглянем глубже: метод опорных векторов» этой главы), случайные леса (см. раздел «Заглянем глубже: деревья принятия решений и случайные леса» данной главы) или другим методом классификации.