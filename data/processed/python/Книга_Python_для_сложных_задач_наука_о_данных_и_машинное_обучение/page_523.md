---
source_image: page_523.png
page_number: 523
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 24.76
tokens: 7416
characters: 1585
timestamp: 2025-12-24T01:04:45.172366
finish_reason: stop
---

In[7]: labels = KMeans(6, random_state=0).fit_predict(X)
    plt.scatter(X[:, 0], X[:, 1], c=labels,
                s=50, cmap='viridis');
![Пример неудачного выбора количества кластеров](../images/fig_5_115.png)

Рис. 5.115. Пример неудачного выбора количества кластеров

Омысленный ли результат получен — сказать трудно. Один из полезных в этом случае и интуитивно довольно понятных подходов, который мы не станем обсуждать подробно, — силуэтный анализ (http://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html).

В качестве альтернативы можно воспользоваться более сложным алгоритмом кластеризации с лучшим количественным показателем зависимости качества аппроксимации от количества кластеров (например, смесь Гауссовых распределений, см. раздел «Заглянем глубже: смеси Гауссовых распределений» данной главы) или с возможностью выбора приемлемого количества кластеров (например, методы DBSCAN, сдвиг среднего или распространения аффинности (affinity propagation), находящиеся в подмодуле sklearn.cluster).

Применение метода k-средних ограничивается случаем линейных границ кластеров. Базовое допущение модели k-средних (точки должны быть ближе к центру их собственного кластера, чем других) означает, что этот алгоритм зачастую будет неэффективен в случае сложной геометрии кластеров.

В частности, границы между кластерами в методе k-средних всегда будут линейными, а значит, он будет плохо работать в случае более сложных границ.

Рассмотрим следующие данные и найденные для них при обычном подходе метода k-средних метки кластеров (рис. 5.116):