---
source_image: page_387.png
page_number: 387
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 25.33
tokens: 7416
characters: 1635
timestamp: 2025-12-24T01:01:14.515438
finish_reason: stop
---

Кластеризация: определение меток для немаркированных данных

Классификация и регрессия, которые мы только что рассмотрели, представляют собой примеры алгоритмов обучения с учителем, в которых создается модель с целью предсказания меток для новых данных. Обучение без учителя касается моделей для описания данных безотносительно каких-либо известных меток.

Часто встречающийся случай машинного обучения без учителя — кластеризация, при которой данные автоматически распределяются по некоторому количеству отдельных групп. Например, наши двумерные данные могли бы оказаться такими, как показаны на рис. 5.8.

Исходные данные

![Двумерная диаграмма точек, разделённых на группы](../images/chapter_5/cluster_data.png)

Признак 1
Признак 2

Рис. 5.8. Пример данных для кластеризации

Визуально очевидно, что каждая из этих точек относится к одной из нескольких групп. При таких входных данных модель кластеризации определит на основе внутренней их структуры, какие точки объединены одной группой. Воспользовавшись очень быстрым и интуитивно понятным алгоритмом кластеризации методом \( k \)-средних (см. раздел «Заглянем глубже: кластеризация методом k-средних» данной главы), мы получаем показанные на рис. 5.9 кластеры.

Метод \( k \)-средних выполняет обучение модели, состоящей из \( k \)-центров кластеров. Наилучшими считаются те центры, для которых расстояние от точек до соответствующих им центров минимально. В случае двух измерений эта задача может показаться тривиальной, но по мере усложнения данных и увеличения их объема подобные алгоритмы кластеризации можно использовать для извлечения из набора данных полезной информации.