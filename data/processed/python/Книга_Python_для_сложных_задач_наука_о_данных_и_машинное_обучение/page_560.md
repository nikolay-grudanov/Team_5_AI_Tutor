---
source_image: page_560.png
page_number: 560
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 29.96
tokens: 7533
characters: 2163
timestamp: 2025-12-24T01:05:44.209062
finish_reason: stop
---

self.logpriors_ = [np.log(Xi.shape[0] / X.shape[0])
    for Xi in training_sets]
return self

В нем мы находим в обучающих данных уникальные классы, обучаем модель KernelDensity для всех классов и вычисляем априорные вероятности на основе количеств исходных выборок. Наконец, метод fit() должен всегда возвращать объект self, чтобы можно было связывать команды в цепочку. Например:

label = model.fit(X, y).predict(X)

Обратите внимание, что все сохраняемые результаты обучения сохраняются с подчеркиванием в конце названия (например, self.logpriors_). Такие условные обозначения используются в библиотеке Scikit-Learn, чтобы можно было быстро просмотреть список членов оценивателя (с помощью TAB-автодополнения оболочки IPython) и выяснить, какие именно члены были обучены на обучающих данных.

Наконец, у нас имеется логика для предсказания меток новых данных:

def predict_proba(self, X):
    logprobs = np.vstack([model.score_samples(X)
        for model in self.models_]).T
    result = np.exp(logprobs + self.logpriors_)
    return result / result.sum(1, keepdims=True)

def predict(self, X):
    return self.classes_[np.argmax(self.predict_proba(X), 1)]

Поскольку мы имеем дело с вероятностным классификатором, мы сначала реализовали метод predict_proba(), возвращающий массив формы [n_samples, n_classes] вероятностей классов. Элемент [i, j] этого массива представляет собой апостериорную вероятность того, что выборка i — член класса j, вычисленная путем умножения функции правдоподобия на априорную вероятность и нормализации.

Наконец, эти вероятности используются в методе predict(), который возвращает класс с максимальной вероятностью.

Использование пользовательского оценивателя

Воспользуемся этим пользовательским оценивателем для решения задачи классификации рукописных цифр. Мы загрузим цифры и вычислим оценку эффективности модели для диапазона вариантов ширины ядра с помощью метаоценивателя GridSearchCV (см. более подробную информацию по этому вопросу в разделе «Гиперпараметры и проверка модели» данной главы):

In[17]: from sklearn.datasets import load_digits
    from sklearn.grid_search import GridSearchCV

    digits = load_digits()