---
source_image: page_547.png
page_number: 547
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 34.20
tokens: 7574
characters: 2165
timestamp: 2025-12-24T01:05:27.610609
finish_reason: stop
---

Резюмируем сделанное: мы смоделировали распределение для заданной выборки рукописных цифр таким образом, что смогли сгенерировать совершенно новые выборки цифр на основе этих данных: это рукописные цифры, не встречающиеся в исходном наборе данных, но отражающие общие признаки входных данных, смоделированные моделью смеси распределений. Подобная порождающая модель цифр может оказаться очень удобной в качестве компонента байесовского порождающего классификатора.

Заглянем глубже: ядерная оценка плотности распределения

В предыдущем разделе мы рассмотрели смеси Гауссовых распределений (GMM), представляющие собой своеобразный гибрид оценивателя для кластеризации и оценивателя плотности. Напомню, что оцениватель плотности — алгоритм, выдающий для D-мерного набора данных оценку D-мерного распределения вероятности, из которого взята эта выборка данных. Для этого алгоритм GMM представляет плотность распределения в виде взвешенной суммы Гауссовых распределений. Ядерная оценка плотности распределения (KDE) — в некотором смысле алгоритм, доводящий идею смеси Гауссовых функций до логического предела: в нем используется смесь, состоящая из одной Гауссовой компоненты для каждой точки, что приводит к непараметрическому оценивателю плотности. В этом разделе мы рассмотрим обоснования и сферы использования метода KDE. Начнем с обычных импортов:

In[1]: %matplotlib inline
    import matplotlib.pyplot as plt
    import seaborn as sns; sns.set()
    import numpy as np

Обоснование метода KDE: гистограммы

Оцениватель плотности — алгоритм, предназначенный для моделирования распределения вероятностей, на основе которого был сгенерирован набор данных. Вероятно, вы уже хорошо знакомы с одним простым оценивателем плотности для одномерных данных — гистограммой. Гистограмма делит данные на дискретные интервалы значений, подсчитывает число точек, попадающих в каждый из интервалов, после чего визуализирует результат интуитивно понятным образом.

Для примера сгенерируем данные на основе двух нормальных распределений:

In[2]:
    def make_data(N, f=0.3, rseed=1):
        rand = np.random.RandomState(rseed)
        x = rand.randn(N)
        x[int(f * N):] += 5