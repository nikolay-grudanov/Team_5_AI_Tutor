---
source_image: page_398.png
page_number: 398
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 39.62
tokens: 7561
characters: 2085
timestamp: 2025-12-24T01:01:44.817619
finish_reason: stop
---

традиции все параметры модели, полученные в процессе выполнения команды fit(), содержат в конце названия знак подчеркивания. Например, в данной линейной модели:

In[10]: model.coef_

Out[10]: array([ 1.9776566])

In[11]: model.intercept_

Out[11]: -0.90331072553111635

Эти два параметра представляют собой угловой коэффициент и точку пересечения с осью координат для простой линейной аппроксимации наших данных. Сравнивая с описанием данных, видим, что они очень близки к исходному угловому коэффициенту, равному 2, и точке пересечения, равной −1.

Часто возникает вопрос относительно погрешностей в подобных внутренних параметрах модели. В целом библиотека Scikit-Learn не предоставляет инструментов, позволяющих делать выводы непосредственно из внутренних параметров модели: интерпретация параметров скорее вопрос статистического моделирования, а не машинного обучения. Машинное обучение концентрируется в основном на том, что предсказывает модель. Для тех, кто хочет узнать больше о смысле подбираемых параметров модели, существуют другие инструменты, включая пакет StatsModels языка Python (http://statsmodels.sourceforge.net/).

5. Предсказание меток для новых данных.
После обучения модели главная задача машинного обучения с учителем заключается в вычислении с ее помощью значений для новых данных, не являющихся частью обучающей последовательности. Сделать это в библиотеке Scikit-Learn можно посредством метода predict(). В этом примере наши новые данные будут сеткой x-значений и нас будет интересовать, какие y-значения предсказывает модель:

In[12]: xfit = np.linspace(-1, 11)

Как и ранее, эти x-значения требуется преобразовать в матрицу признаков [n_samples, n_features], после чего можно подать их на вход модели:

In[13]: Xfit = xfit[:, np.newaxis]
        yfit = model.predict(Xfit)

Наконец, визуализируем результаты, нарисовав сначала график исходных данных, а затем обученную модель (рис. 5.15):

In[14]: plt.scatter(x, y)
        plt.plot(xfit, yfit);

Обычно эффективность модели оценивают, сравнивая ее результаты с эталоном, как мы увидим в следующем примере.