---
source_image: page_424.png
page_number: 424
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 26.87
tokens: 7406
characters: 1550
timestamp: 2025-12-24T01:02:12.160631
finish_reason: stop
---

color='gray',
    linestyle='dashed')
ax[i].set_ylim(0, 1)
ax[i].set_xlim(N[0], N[-1])
ax[i].set_xlabel('training size') # Размерность обучения
ax[i].set_ylabel('score')
ax[i].set_title('degree = {0}'.format(degree), size=14)
ax[i].legend(loc='best')

![Кривые обучения для модели низкой (слева) и высокой сложности (справа)](https://i.imgur.com/3Q5z5QG.png)

Рис. 5.33. Кривые обучения для модели низкой (слева) и высокой сложности (справа)

Это ценный показатель, поскольку он наглядно демонстрирует нам реакцию нашей модели на увеличение объема обучающих данных. В частности, после того момента, когда кривая обучения уже сошлась к какому-то значению (то есть когда кривые обучения и проверки уже близки друг к другу), добавление дополнительных обучающих данных не улучшит аппроксимацию существенно! Эта ситуация отражена на левом рисунке с кривой обучения для модели второй степени.

Единственный способ улучшения оценки уже сошедшейся кривой — использовать другую (обычно более сложную) модель. Это видно на правом рисунке: перейдя к более сложной модели, мы улучшаем оценку для точки сходимости (отмеченную штриховой линией) за счет более высокой дисперсии модели (соответствующей расстоянию между оценками эффективности для обучения и проверки). Если бы нам пришлось добавить еще больше точек, кривая обучения для более сложной из этих моделей все равно в итоге бы сошлась.

Построение графика кривой обучения для конкретных модели и набора данных облегчает принятие решения о том, как продвинуться еще дальше на пути улучшения анализа данных.