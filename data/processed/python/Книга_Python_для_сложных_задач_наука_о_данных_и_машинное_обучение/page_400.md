---
source_image: page_400.png
page_number: 400
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 35.67
tokens: 7580
characters: 2286
timestamp: 2025-12-24T01:01:45.240945
finish_reason: stop
---

model.fit(Xtrain, ytrain)        # 3. Обучаем модель на данных
y_model = model.predict(Xtest)   # 4. Предсказываем значения
                                # для новых данных

Воспользуемся утилитой accuracy_score для выяснения того, какая часть предсказанных меток соответствует истинному значению:

In[17]: from sklearn.metrics import accuracy_score
    accuracy_score(ytest, y_model)

Out[17]: 0.97368421052631582

Как видим, точность превышает 97 %, поэтому для этого конкретного набора данных даже очень наивный алгоритм классификации оказывается эффективным!

Пример обучения без учителя: понижение размерности набора данных Iris

В качестве примера задачи обучения без учителя рассмотрим задачу понижения размерности набора данных Iris с целью упрощения его визуализации. Напомню, что данные Iris четырехмерны: для каждой выборки зафиксированы четыре признака.

Задача понижения размерности заключается в выяснении, существует ли подходящее представление более низкой размерности, сохраняющее существенные признаки данных. Зачастую понижение размерности используется для облегчения визуализации данных, в конце концов, гораздо проще строить график данных в двух измерениях, чем в четырех или более!

В этом разделе мы будем использовать метод главных компонент (PCA; см. раздел «Заглянем глубже: метод главных компонент» данной главы), представляющий собой быстрый линейный метод понижения размерности. Наша модель должна будет возвращать две компоненты, то есть двумерное представление данных.

Следуя вышеописанной последовательности шагов, получаем:

In[18]:
from sklearn.decomposition import PCA  # 1. Выбираем класс модели
model = PCA(n_components=2)            # 2. Создаем экземпляр модели
                                       # с гиперпараметрами
model.fit(X_iris)                      # 3. Обучаем модель на данных. Обратите внимание, что у мы не указываем!
X_2D = model.transform(X_iris)         # 4. Преобразуем данные в двумерные

Построим график полученных результатов. Сделать это быстрее всего можно, вставив результаты в исходный объект DataFrame Iris и воспользовавшись функцией lmplot для отображения результатов:

In[19]: iris['PCA1'] = X_2D[:, 0]
        iris['PCA2'] = X_2D[:, 1]
        sns.lmplot("PCA1", "PCA2", hue='species', data=iris, fit_reg=False);