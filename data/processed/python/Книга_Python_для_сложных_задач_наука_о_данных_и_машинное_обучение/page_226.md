---
source_image: page_226.png
page_number: 226
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 25.41
tokens: 7502
characters: 1955
timestamp: 2025-12-24T00:57:10.730580
finish_reason: stop
---

библиотеки Pandas (http://pandas.pydata.org/pandas-docs/stable/text.html) или заглянуть в раздел «Дополнительные источники информации» данной главы.

Пример: база данных рецептов

Описанные векторизованные строковые операции оказываются наиболее полезными при очистке сильно зашумленных реальных данных. Здесь мы рассмотрим пример такой очистки, воспользовавшись полученной из множества различных интернет-источников базой данных рецептов. Наша цель — разбор рецептов на списки ингредиентов, чтобы можно было быстро найти рецепт, исходя из имеющихся в распоряжении ингредиентов.

Используемые для компиляции сценарии можно найти по адресу https://github.com/fictivekin/openrecipes, как и ссылку на актуальную версию базы.

По состоянию на весну 2016 года размер базы данных составляет около 30 Мбайт, ее можно скачать и разархивировать с помощью следующих команд:

In[17]: # !curl -O
    # http://openrecipes.s3.amazonaws.com/20131812-recipeitems.json.gz
    # !gunzip 20131812-recipeitems.json.gz

База данных находится в формате JSON, так что можно попробовать воспользоваться функцией pd.read_json для ее чтения:

In[18]: try:
    recipes = pd.read_json('recipeitems-latest.json')
except ValueError as e:
    print("ValueError:", e)

ValueError: Trailing data

Упс! Мы получили ошибку ValueError с упоминанием наличия «хвостовых данных». Если поискать эту ошибку в Интернете, складывается впечатление, что она появляется из-за использования файла, в котором каждая строка сама по себе является корректным JSON, а весь файл в целом — нет. Рассмотрим, справедливо ли это объяснение:

In[19]: with open('recipeitems-latest.json') as f:
    line = f.readline()
    pd.read_json(line).shape

Out[19]: (2, 12)

Да, очевидно, каждая строка — корректный JSON, так что нам нужно соединить их все воедино. Один из способов сделать это — фактически сформировать строковое представление, содержащее все записи JSON, после чего загрузить все с помощью pd.read_json: