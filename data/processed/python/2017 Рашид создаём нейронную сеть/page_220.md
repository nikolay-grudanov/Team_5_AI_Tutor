---
source_image: page_220.png
page_number: 220
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 28.93
tokens: 6674
characters: 1693
timestamp: 2025-12-24T02:14:40.923689
finish_reason: stop
---

за исключением того, что в этом случае используется обратная функция активации. Если \( y = f(x) \) — функция активации для прямых сигналов, то ее обратная функция — \( x = g(y) \). Для логистической функции нахождение обратной функции сводится к простой алгебре:

\[
\begin{align*}
y &= 1/(1 + e^{-x}) \\
1 + e^{-x} &= 1/y \\
e^{-x} &= (1/y) - 1 = (1-y)/y \\
-x &= \ln[(1-y)/y] \\
x &= \ln[y/(1-y)]
\end{align*}
\]

Эта функция называется logit, и библиотека Python scipy.special предоставляет ее как scipy.special.logit(), точно так же, как и логистическую функцию scipy.special.expit().

Прежде чем использовать обратную функцию активации logit(), мы должны убедиться в допустимости сигналов. Что это означает? Вы помните, что сигмоида принимает любое значение и возвращает значение из диапазона от 0 до 1, исключая граничные значения. Обратная функция должна принимать значения из того же самого диапазона — от 0 до 1, исключая сами значения 0 и 1, — и возвращать значение, которое может быть любым положительным или отрицательным числом. Для этого мы просто берем все значения в слое, к которым собираемся применить функцию logit(), и приводим их к допустимому диапазону. В качестве такового я выбрал диапазон чисел от 0,01 до 0,99.

Соответствующий код доступен на сайте GitHub по следующему адресу:

https://github.com/makeyourownneuralnetwork/makeyourownneuralnetwork/blob/master/part3_neural_network_mnist_backquery.ipynb

Маркер "0"

Посмотрим, что произойдет, если выполнить обратный запрос для маркера "0", т.е. мы предоставляем выходным узлам значения, равные 0,01, за исключением первого узла, соответствующего маркеру "0", которому мы предоставляем значение 0,99. Иными словами,