---
source_image: page_123.png
page_number: 123
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 31.80
tokens: 6738
characters: 1689
timestamp: 2025-12-24T02:12:29.415813
finish_reason: stop
---

• Сумма \( \Sigma_j w_{jk} o_j \), передаваемая сигмоидам, равна \((2,0 * 0,4) + (3,0 * 0,5) = 2,3\).

• Тогда сигмоида \(1/(1 + e^{-2,3})\) равна 0,909. Следовательно, промежуточное выражение равно \(0,909 * (1 - 0,909) = 0,083\).

• Последняя часть — это просто сигнал \(o_j\), которым в данном случае является сигнал \(o_{j-1}\), так как нас интересует вес \(w_{11}\), где \(j=1\). Поэтому данная часть просто равна 0,4.

Перемножив все три части этого выражения и не забыв при этом о начальном знаке "минус", получаем значение \(-0,0265\).

При коэффициенте обучения, равном 0,1, изменение веса составит \(-0,1 * (-0,0265) = +0,002650\). Следовательно, новое значение \(w_{11}\), определяемое суммой первоначального значения и его изменения, составит \(2,0 + 0,00265 = 2,00265\).

Это довольно небольшое изменение, но после выполнения сотен или даже тысяч итераций весовые коэффициенты в конечном счете образуют устойчивую конфигурацию, которая в хорошо натренированной нейронной сети обеспечит получение выходных сигналов, согласующихся с тренировочными примерами.

Подготовка данных

В этом разделе мы обсудим, как лучше всего подготовить тренировочные данные и случайные начальные значения весовых коэффициентов и даже спланировать выходные значения таким образом, чтобы процесс обучения имел все шансы на успех.

Совершенно верно, вы все правильно прочитали! Не все попытки использования нейронных сетей заканчиваются успехом, и на то есть множество причин. Некоторые из них можно устранить за счет продуманного отбора тренировочных данных и начальных значений весовых коэффициентов, а также тщательного планирования схемы выходных сигналов. Рассмотрим все эти факторы по-очередно.