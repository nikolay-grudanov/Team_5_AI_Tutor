---
source_image: page_206.png
page_number: 206
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 36.40
tokens: 6792
characters: 2080
timestamp: 2025-12-24T02:14:30.955306
finish_reason: stop
---

Как нетрудно заметить, уменьшение коэффициента обучения действительно привело к улучшению эффективности при большом количестве эпох. Пиковому значению 0,9689 соответствует вероятность ошибок, равная 3%, что сравнимо с эталонными результатами, указанными на сайте Яна Лекуна по адресу http://yann.lecun.com/exdb/mnist/.

Интуиция подсказывает нам, что если мы планируем использовать метод градиентного спуска при значительно большем количестве эпох, то уменьшение коэффициента обучения (более короткие шаги) в целом приведет к выбору лучших маршрутов минимизации ошибок. Вероятно, 5 эпох — это оптимальное количество для тестирования нашей нейронной сети с набором данных MNIST. Вновь обращаю ваше внимание на то, что мы сделали это довольно ненаучным способом. Правильно было бы выполнить эксперимент по нескольку раз для каждого сочетания значений коэффициента обучения и количества эпох с целью минимизации влияния фактора случайности, присущего методу градиентного спуска.

Изменение конфигурации сети

Один из факторов, влияние которых мы еще не исследовали, хотя, возможно, и должны были сделать это раньше, — конфигурация нейронной сети. Необходимо попробовать изменить количество узлов скрытого промежуточного слоя. Давным-давно мы установили его равным 100.

Прежде чем приступить к экспериментам с различными количествами скрытых узлов, давайте подумаем, что при этом может случиться. Скрытый слой как раз и является тем слоем, в котором происходит обучение. Вспомните, что узлы входного слоя принимают входные сигналы, а узлы выходного выдают ответ сети. Собственно, скрытый слой (или слои) должен научить сеть превращать входные сигналы в ответ. Именно в нем происходит обучение. На самом деле все обучение основано на значениях весовых коэффициентов до и после скрытого слоя, но вы понимаете, что я имею в виду.

Согласитесь, что если бы у нас было слишком мало скрытых узлов, скажем, три, то мы не имели бы никаких шансов обучить сеть чему-либо, научить ее преобразовывать все входные сигналы в корректные выходные сигналы. Это все равно что пытаться перевезти десять