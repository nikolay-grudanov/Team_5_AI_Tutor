---
source_image: page_090.png
page_number: 90
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 30.51
tokens: 6721
characters: 1730
timestamp: 2025-12-24T02:11:46.116829
finish_reason: stop
---

Ошибка может формироваться на обоих узлах — фактически эта ситуация очень похожа на ту, которая возникает, когда сеть еще не обучалась. Вы видите, что для коррекции весов внутренних связей нужна информация об ошибках в обоих узлах. Мы можем использовать прежний подход и распределять ошибку выходного узла между связанными с ним узлами пропорционально весовым коэффициентам соответствующих связей.

В действительности тот факт, что сейчас имеется более чем один выходной узел, ничего не меняет. Мы просто повторяем для второго узла те же действия, которые уже выполняли для первого. Почему все так просто? Эта простота объясняется тем, что связи одного выходного узла не зависят от связей другого. Между этими двумя наборами связей отсутствует какая-либо зависимость.

Вернемся к диаграмме, на которой ошибка на первом выходном узле обозначена как \( e_1 \). Не забывайте, что это разность между желаемым значением, предоставляемым тренировочными данными \( t_1 \), и фактическим выходным значением \( o_1 \). Таким образом, \( e_1 = (t_1 - o_1) \). Ошибка на втором выходном узле обозначена как \( e_2 \).

На диаграмме видно, что ошибка \( e_1 \) распределяется пропорционально весам связей, обозначенным как \( w_{11} \) и \( w_{21} \). Точно так же ошибка \( e_2 \) должна распределяться пропорционально весам \( w_{12} \) и \( w_{22} \).

Чтобы у вас не возникало никаких сомнений в правильности получаемых результатов, запишем эти доли в явном виде. Ошибка \( e_1 \) информирует о величинах поправок для весов \( w_{11} \) и \( w_{21} \). При ее распределении между узлами доля \( e_1 \), информация о которой используется для обновления \( w_{11} \), определяется следующим выражением:

\[
\frac{w_{11}}{w_{11} + w_{21}}
\]