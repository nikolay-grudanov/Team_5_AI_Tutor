---
source_image: page_174.png
page_number: 174
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 27.27
tokens: 6699
characters: 1828
timestamp: 2025-12-24T02:13:36.042828
finish_reason: stop
---

Операция += означает увеличение переменной, указанной слева от знака равенства, на значение, указанное справа от него. Поэтому x+=3 означает, что x увеличивается на 3. Это просто сокращенная запись инструкции x=x+3. Аналогичный способ записи допускается и для других арифметических операций. Например, x/=3 означает деление x на 3.

Код для уточнения весовых коэффициентов связей между входным и скрытым слоями будет очень похож на этот. Мы воспользуемся симметрией выражений и просто перепишем код, заменяя в нем имена переменных таким образом, чтобы они относились к предыдущим слоям. Ниже приведен суммарный код для двух наборов весовых коэффициентов, отдельные элементы которого выделены цветом таким образом, чтобы сходные и различающиеся участки кода можно было легко заметить.

# обновить весовые коэффициенты связей между скрытым и выходным слоями
self.who += self.lr * numpy.dot((output_errors * final_outputs * (1.0 - final_outputs)), numpy.transpose(hidden_outputs))

# обновить весовые коэффициенты связей между входным и скрытым слоями
self.wih += self.lr * numpy.dot((hidden_errors * hidden_outputs * (1.0 - hidden_outputs)), numpy.transpose(inputs))

Вот и все!
Даже не верится, что вся та работа, для выполнения которой нам потребовалось множество вычислений, и все те усилия, которые мы вложили в разработку матричного подхода и способа минимизации ошибок сети методом градиентного спуска, свелись к паре строк кода! Отчасти мы обязаны этим языку Python, но фактически это закономерный результат нашего упорного труда, вложенного в упрощение того, что легко могло стать сложным и приобрести устрашающий вид.

Полный код нейронной сети

Мы завершили разработку класса нейронной сети. Он приведен ниже для справки, и вы можете получить его в любой момент, воспользовавшись следующей ссылкой на GitHub — крупнейшем