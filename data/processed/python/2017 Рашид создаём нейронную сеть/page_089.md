---
source_image: page_089.png
page_number: 89
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 20.70
tokens: 6496
characters: 1168
timestamp: 2025-12-24T02:11:36.272226
finish_reason: stop
---

связями пропорционально их вкладам, размер которых определяется весами соответствующих связей.

Как вы могли заметить, мы используем весовые коэффициенты в двух целях. Во-первых, они учитываются при расчете распространения сигналов по нейронной сети от входного слоя до выходного. Мы интенсивно использовали их ранее именно в таком качестве. Во-вторых, мы используем веса для распространения ошибки в обратном направлении — от выходного слоя вглубь сети. Думаю, вы не будете удивлены, узнав, что этот метод называется обратным распространением ошибки (обратной связью) в процессе обучения нейронной сети.

Если бы выходной слой имел два узла, мы повторили бы те же действия и для второго узла. Второй выходной узел будет характеризоваться собственной ошибкой, распределяемой аналогичным образом между соответствующим количеством входных узлов. Теперь продолжим наше рассмотрение.

Обратное распространение ошибок от большего количества выходных узлов

На следующей диаграмме отображена простая сеть с двумя входными узлами, но на этот раз с двумя выходными узлами.

![Диаграмма нейронной сети с двумя входными и двумя выходными узлами](https://i.imgur.com/3Q5z5QG.png)