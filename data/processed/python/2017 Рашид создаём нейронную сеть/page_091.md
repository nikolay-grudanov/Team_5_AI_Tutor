---
source_image: page_091.png
page_number: 91
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 32.65
tokens: 6745
characters: 1754
timestamp: 2025-12-24T02:11:48.400419
finish_reason: stop
---

Доля \( e_1 \), используемая для обновления \( w_{21} \), определяется аналогичным выражением:

\[
\frac{w_{21}}{w_{11} + w_{21}}
\]

Возможно, эти выражения несколько смущают вас, поэтому рассмотрим их более подробно. За всеми этими символами стоит очень простая идея, которая заключается в том, что узлы, сделавшие больший вклад в ошибочный ответ, получают больший сигнал об ошибке, тогда как узлы, сделавшие меньший вклад, получают меньший сигнал.

Если \( w_{11} \) в два раза превышает \( w_{21} \) (скажем, \( w_{11} = 6 \), а \( w_{21} = 3 \)), то доля \( e_1 \), используемая для обновления \( w_{11} \), составляет \( 6/(6+3) = 6/9 = 2/3 \). Тогда для другого, меньшего веса \( w_{21} \) должно остаться \( 1/3 \) \( e_1 \), что можно подтвердить с помощью выражения \( 3/(6+3) = 3/9 \), результат которого действительно равен \( 1/3 \).

Как и следовало ожидать, при равных весах будут равны и соответствующие доли. Давайте в этом убедимся. Пусть \( w_{11} = 4 \) и \( w_{21} = 4 \), тогда в обоих случаях доля будет составлять \( 4/(4+4) = 4/8 = 1/2 \).

Прежде чем продолжить, сделаем паузу и вернемся на шаг назад, чтобы оценить то, что мы уже успели сделать. Мы знали, что при определении величины поправок для некоторых внутренних параметров сети, в данном случае — весов связей, необходимо использовать величину ошибки. Вы видели, как это делается для весов, которые сглаживают входные сигналы последнего, выходного слоя нейронной сети. Вы также видели, что увеличение количества выходных узлов не усложняет задачу, поскольку мы повторяем одни и те же действия для каждого выходного узла. Замечательно!

Но как быть, если количество слоев превышает два? Как обновлять веса связей для слоев, далеко отстоящих от последнего, выходного слоя?