---
source_image: page_167.png
page_number: 167
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 29.37
tokens: 6734
characters: 2075
timestamp: 2025-12-24T02:13:27.109250
finish_reason: stop
---

неоднократно ссылаться на нее, точно так же, как на функцию query(). Такая организация программы означает, что в случае внесения изменений нам придется сделать это только в одном месте, а не везде в коде, где используется функция активации.

Ниже приведен код, определяющий функцию активации, который мы используем в разделе инициализации нейронной сети.

# использование сигмоиды в качестве функции активации
self.activation_function = lambda x: scipy.special.expit(x)

Что делает этот код? Он не похож ни на что, с чем мы прежде сталкивались. Что это за lambda? Не стоит пугаться, здесь нет ничего страшного. Все, что мы сделали, — это создали функцию наподобие любой другой, только с использованием более короткого способа записи, называемого лямбда-выражением. Вместо привычного определения функции в форме def имя() мы использовали волшебное слово lambda, которое позволяет создавать функции быстрым и удобным способом, что называется, “на лету”. В данном случае функция принимает аргумент x и возвращает scipy.special.expit(), а это есть не что иное, как сигмоида. Функции, создаваемые с помощью лямбда-выражений, являются безымянными или, как предпочитают говорить опытные программисты, анонимными, но данной функции мы присвоили имя self.activation_function(). Это означает, что всякий раз, когда потребуется использовать функцию активации, ее нужно будет вызвать как self.activation_function().

Итак, возвращаясь к нашей задаче, мы применим функцию активации к сглаженным комбинированным входящим сигналам, поступающим на скрытые узлы. Соответствующий код совсем не сложен.

# рассчитать исходящие сигналы для скрытого слоя
hidden_outputs = self.activation_function(hidden_inputs)

Таким образом, сигналы, исходящие из скрытого слоя, описываются матрицей hidden_outputs.

Мы прошли промежуточный скрытый слой, а как быть с последним, выходным слоем? В действительности распространение сигнала от скрытого слоя до выходного ничем принципиально не отличается от предыдущего случая, поэтому способ расчета остается тем же, а значит, и код будет аналогичен предыдущему.