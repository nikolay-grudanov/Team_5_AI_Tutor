---
source_image: page_329.png
page_number: 329
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 32.43
tokens: 7835
characters: 1717
timestamp: 2025-12-24T02:49:06.482064
finish_reason: stop
---

In [61]: def peak_to_peak(arr):
    ....: return arr.max() - arr.min()

In [62]: grouped.agg(peak_to_peak)
Out[62]:
    key2   data1   data2
key1
a      1   1.598113   0.494031
b      1   2.521511   2.303410

Отметим, что некоторые методы, например describe, тоже работают, хотя, строго говоря, и не являются операциями агрегирования:

In [63]: grouped.describe()
Out[63]:
    key2
    count mean std min 25% 50% 75% max
key1
a  2.0  1.5  0.707107  1.0  1.25  1.5  1.75  2.0
b  2.0  1.5  0.707107  1.0  1.25  1.5  1.75  2.0
    data1
    count mean ...
key1
a  3.0  0.555881 ...
b  2.0  0.705025 ...

    data2
    75% max count mean std min 25%
key1
a  0.936175  1.393406  3.0  0.441920  0.283299  0.274992  0.278369
b  1.335403  1.965781  2.0 -0.144516  1.628757 -1.296221 -0.720368

    50% 75% max
key1
a  0.281746  0.525384  0.769023
b -0.144516  0.431337  1.007189
[2 rows x 24 columns]

Что здесь произошло, я объясню подробнее в разделе 10.3.

В общем случае пользовательские функции агрегирования работают гораздо медленнее оптимизированных функций из табл. 10.1. Это объясняется большими накладными расходами (на вызовы функций и реорганизацию данных) при построении промежуточных блоков данных, относящихся к каждой группе.

Применение функций, зависящих от столбца, и нескольких функций
Вернемся к набору данных о чаевых, который уже встречался нам ранее. Сначала загрузим набор функцией read_csv и добавим в него столбец процента чаевых tip_pct:

In [64]: tips = pd.read_csv("examples/tips.csv")

In [65]: tips.head()
Out[65]:
    total_bill   tip smoker  day   time  size
0   16.99       1.01 No     Sun   Dinner  2
1   10.34       1.66 No     Sun   Dinner  3
2   21.01       3.50 No     Sun   Dinner  3