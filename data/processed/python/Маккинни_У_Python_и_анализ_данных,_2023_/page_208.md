---
source_image: page_208.png
page_number: 208
model: model-run-olm-ocr
prompt_type: olmocr_technical
processing_time: 25.83
tokens: 7588
characters: 1609
timestamp: 2025-12-24T02:45:37.041885
finish_reason: stop
---

HDFStore поддерживает две схемы хранения: 'fixed' (по умолчанию) и 'table'. Последняя, вообще говоря, медленнее, но поддерживает запросы в специальном синтаксисе:

In [119]: store.put("obj2", frame, format="table")

In [120]: store.select("obj2", where=["index >= 10 and index <= 15"])
Out[120]:
    a
10  1.007189
11 -1.296221
12  0.274992
13  0.228913
14  1.352917
15  0.886429
In [121]: store.close()

Метод put — явный вариант синтаксиса store['obj2'] = frame, но он позволяет задавать и другие параметры, например формат хранения.

Функция pandas.read_hdf дает лаконичный способ доступа к этой функциональности:

In [122]: frame.to_hdf("examples/mydata.h5", "obj3", format="table")

In [123]: pd.read_hdf("examples/mydata.h5", "obj3", where=["index < 5"])
Out[123]:
    a
0  -0.204708
1   0.478943
2  -0.519439
3  -0.555730
4   1.965781

При желании можно удалить созданный HDF5-файл:

In [124]: import os

In [125]: os.remove("examples/mydata.h5")

Если вы работаете с данными, которые хранятся на удаленных серверах, например Amazon S3 или HDFS, то может оказаться более подходящим какой-нибудь другой двоичный формат, разработанный специально для распределенных хранилищ, например Apache Parquet (http://parquet.apache.org/).

Если вы собираетесь работать с очень большими объемами данных локально, то я рекомендую изучить PyTables и h5py и посмотреть, в какой мере они отвечают вашим потребностям. Поскольку многие задачи анализа данных ограничены прежде всего скоростью ввода-вывода (а не быстродействием процессора), использование средства типа HDF5 способно существенно ускорить работу приложения.