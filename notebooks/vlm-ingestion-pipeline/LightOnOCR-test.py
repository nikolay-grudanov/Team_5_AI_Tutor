"""
–ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ LightOnOCR —Å –∫–∞—Å—Ç–æ–º–Ω—ã–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–æ–º
"""

from transformers import AutoModel, AutoTokenizer, AutoImageProcessor
from PIL import Image
import torch
import sys

model_path = "models/LightOnOCR-1B-1025"

print("="*70)
print("üîß –ü–†–ê–í–ò–õ–¨–ù–ê–Ø –ó–ê–ì–†–£–ó–ö–ê LightOnOCR")
print("="*70)

try:
    # –®–∞–≥ 1: –ó–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å —Å trust_remote_code
    print(f"\nüì¶ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏...")
    model = AutoModel.from_pretrained(
        model_path,
        trust_remote_code=True,
        torch_dtype=torch.bfloat16,
        device_map="auto"
    )
    print(f"‚úÖ –ú–æ–¥–µ–ª—å: {type(model)}")
    
    # –®–∞–≥ 2: –ó–∞–≥—Ä—É–∑–∏—Ç—å —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä
    print(f"\nüì¶ –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞...")
    tokenizer = AutoTokenizer.from_pretrained(
        model_path,
        trust_remote_code=True
    )
    print(f"‚úÖ –¢–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä: {type(tokenizer)}")
    
    # –®–∞–≥ 3: –ó–∞–≥—Ä—É–∑–∏—Ç—å image processor
    print(f"\nüì¶ –ó–∞–≥—Ä—É–∑–∫–∞ image processor...")
    try:
        image_processor = AutoImageProcessor.from_pretrained(
            model_path,
            trust_remote_code=True
        )
        print(f"‚úÖ Image Processor: {type(image_processor)}")
    except Exception as e:
        print(f"‚ö†Ô∏è  AutoImageProcessor –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {e}")
        print(f"   –ü–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑ preprocessor_config.json...")
        
        # –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –≤—Ä—É—á–Ω—É—é
        from transformers import PreTrainedImageProcessor
        import json
        
        with open(f"{model_path}/preprocessor_config.json", "r") as f:
            config = json.load(f)
        
        print(f"   Preprocessor config: {config}")
    
    # –®–∞–≥ 4: –¢–ï–°–¢ - –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    print(f"\nüß™ –¢–ï–°–¢: –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è...")
    
    test_image = list(IMAGE_PATHS)[0]
    image = Image.open(test_image)
    print(f"   –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {test_image.name} ({image.size})")
    
    # –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å —Ä–∞–∑–Ω—ã–µ —Å–ø–æ—Å–æ–±—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏
    print(f"\n   –°–ø–æ—Å–æ–± 1: –ß–µ—Ä–µ–∑ –º–æ–¥–µ–ª—å –Ω–∞–ø—Ä—è–º—É—é...")
    if hasattr(model, 'forward'):
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å inputs
        # LightOnOCR –æ–∂–∏–¥–∞–µ—Ç pixel_values
        from torchvision import transforms
        
        # –ü—Ä–æ—Å—Ç–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        transform = transforms.Compose([
            transforms.Resize((512, 512)),
            transforms.ToTensor(),
            transforms.Normalize(
                mean=[0.48145466, 0.4578275, 0.40821073],
                std=[0.26862954, 0.26130258, 0.27577711]
            )
        ])
        
        pixel_values = transform(image).unsqueeze(0).to(model.device)
        print(f"   ‚úÖ pixel_values shape: {pixel_values.shape}")
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è
        with torch.no_grad():
            outputs = model.generate(
                pixel_values=pixel_values,
                max_new_tokens=512,
                temperature=0.2,
                top_p=0.9,
                do_sample=True
            )
        
        # –î–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ
        text = tokenizer.decode(outputs[0], skip_special_tokens=True)
        
        print(f"\nüìù –†–ï–ó–£–õ–¨–¢–ê–¢:")
        print(f"   –°–∏–º–≤–æ–ª–æ–≤: {len(text)}")
        print(f"\n{text[:500]}")
        
        if len(text) > 50:
            print(f"\nüéâ –£–°–ü–ï–•! –ú–æ–¥–µ–ª—å —Ä–∞—Å–ø–æ–∑–Ω–∞–ª–∞ —Ç–µ–∫—Å—Ç!")
        else:
            print(f"\n‚ö†Ô∏è  –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π")
    
except Exception as e:
    print(f"\n‚ùå –û–®–ò–ë–ö–ê: {e}")
    import traceback
    traceback.print_exc()

print(f"\n{'='*70}")

