





"""
============================================================================
–Ø–ß–ï–ô–ö–ê 1: –ò–ú–ü–û–†–¢–´ –ò –ù–ê–°–¢–†–û–ô–ö–ò
============================================================================
–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ OCR –º–æ–¥–µ–ª–µ–π —Å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π —á–µ—Ä–µ–∑ ThreadPoolExecutor
"""

# ============================================================================
# –°–¢–ê–ù–î–ê–†–¢–ù–´–ï –ë–ò–ë–õ–ò–û–¢–ï–ö–ò
# ============================================================================
import os
import sys
import json
import base64
import logging
import time
import csv
from pathlib import Path
from io import BytesIO
from datetime import datetime
from typing import List, Dict, Optional, Tuple, Any
from dataclasses import dataclass, field, asdict

# ============================================================================
# –ü–ê–†–ê–õ–õ–ï–õ–¨–ù–ê–Ø –û–ë–†–ê–ë–û–¢–ö–ê
# ============================================================================
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading

# ============================================================================
# –í–ù–ï–®–ù–ò–ï –ë–ò–ë–õ–ò–û–¢–ï–ö–ò
# ============================================================================
from PIL import Image
import requests
from tqdm import tqdm
from openai import OpenAI

# ============================================================================
# –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø –ò –ê–ù–ê–õ–ò–ó
# ============================================================================
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# ============================================================================
# –ù–ê–°–¢–†–û–ô–ö–ê –õ–û–ì–ò–†–û–í–ê–ù–ò–Ø
# ============================================================================
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('ocr_processing.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

# ============================================================================
# –ì–õ–û–ë–ê–õ–¨–ù–´–ï –ü–ï–†–ï–ú–ï–ù–ù–´–ï
# ============================================================================
# –î–æ–±–∞–≤–∏—Ç—å –∫–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞ –≤ PYTHONPATH
PROJECT_ROOT = Path.cwd().resolve()
if PROJECT_ROOT.name != "Team_5_AI_Tutor":
    PROJECT_ROOT = PROJECT_ROOT.parents[1]
sys.path.insert(0, str(PROJECT_ROOT))

DATA_DIR = PROJECT_ROOT / "data"
IMAGES_DIR = PROJECT_ROOT / "notebooks" / "vlm-ingestion-pipeline" / "test_images"
OUTPUT_DIR = DATA_DIR / "test_results"

# –°–æ–∑–¥–∞—ë–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")


print("‚úÖ –Ø—á–µ–π–∫–∞ 1: –ò–º–ø–æ—Ä—Ç—ã –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
print(f"   üìÇ –ö–æ—Ä–Ω–µ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {PROJECT_ROOT}")
print(f"   üìÇ –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏: {IMAGES_DIR}")
print(f"   üìÇ –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {OUTPUT_DIR}")



"""
============================================================================
–Ø–ß–ï–ô–ö–ê 2: –°–¢–†–£–ö–¢–£–†–´ –î–ê–ù–ù–´–•
============================================================================
"""

@dataclass
class OCRResult:
    """
    –†–µ–∑—É–ª—å—Ç–∞—Ç OCR –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.
    
    Thread-safety: ‚úÖ Immutable –ø–æ—Å–ª–µ —Å–æ–∑–¥–∞–Ω–∏—è
    """
    model_name: str           # –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ (HunyuanOCR, Qwen3-VL, –∏ —Ç.–¥.)
    folder_name: str          # –ù–∞–∑–≤–∞–Ω–∏–µ –ø–∞–ø–∫–∏/–∫–Ω–∏–≥–∏
    filename: str             # –ò–º—è —Ñ–∞–π–ª–∞ (page_001.png)
    page_number: int          # –ù–æ–º–µ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    text: str                 # –†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
    tokens: int               # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤
    processing_time: float    # –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ (—Å–µ–∫—É–Ω–¥—ã)
    text_length: int          # –î–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞ (—Å–∏–º–≤–æ–ª–æ–≤)
    timestamp: str            # ISO timestamp
    error: Optional[str] = None  # –¢–µ–∫—Å—Ç –æ—à–∏–±–∫–∏ (–µ—Å–ª–∏ –µ—Å—Ç—å)
    
    def __post_init__(self):
        """–ê–≤—Ç–æ–∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–æ–ª–µ–π"""
        if not self.timestamp:
            self.timestamp = datetime.now().isoformat()
        if self.text_length == 0:
            self.text_length = len(self.text)


@dataclass
class ModelStats:
    """
    –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ä–∞–±–æ—Ç—ã –º–æ–¥–µ–ª–∏.
    
    Thread-safety: ‚úÖ –°–æ–∑–¥–∞—ë—Ç—Å—è –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –≤—Å–µ—Ö –ø–æ—Ç–æ–∫–æ–≤
    """
    model_name: str
    total_images: int
    folders_processed: int
    total_time: float
    avg_time_per_image: float
    total_tokens: int
    total_chars: int
    success_rate: float
    errors: int
    throughput: float  # images per second


@dataclass
class FolderStats:
    """
    –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –æ–¥–Ω–æ–π –ø–∞–ø–∫–µ/–∫–Ω–∏–≥–µ.
    
    Thread-safety: ‚úÖ –°–æ–∑–¥–∞—ë—Ç—Å—è –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –≤—Å–µ—Ö –ø–æ—Ç–æ–∫–æ–≤
    """
    folder_name: str
    total_images: int
    total_time: float
    avg_time_per_image: float
    total_chars: int
    avg_chars_per_image: float
    success_rate: float


# –ì–ª–æ–±–∞–ª—å–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
ALL_RESULTS = {}      # {model_name: [OCRResult, ...]}
FOLDER_GROUPS = {}    # {folder_name: [image_paths, ...]}
IMAGE_PATHS = []      # –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –ø—É—Ç–µ–π –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º

print("‚úÖ –Ø—á–µ–π–∫–∞ 2: –°—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã")
print("   - OCRResult: —Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
print("   - ModelStats: —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –º–æ–¥–µ–ª–∏")
print("   - FolderStats: —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø–∞–ø–∫–µ")



"""
============================================================================
–Ø–ß–ï–ô–ö–ê 3: –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –ú–û–î–ï–õ–ï–ô
============================================================================
"""

MODELS_CONFIG = {
    "HunyuanOCR": {
        "enabled": True,
        "port": 8000,
        "model_path": "/models/HunyuanOCR",
        "prompts": {
            "simple": "OCR this text. Extract all text accurately.",
            "detailed": "Please extract all text from this image, preserving the original formatting, structure all formulas, symbols, equations and code blocs.",
            "math": "OCR this image containing mathematical text. Preserve all formulas, symbols, and equations."
        }
    },
    "Qwen3-VL-8B-Instruct": {
        "enabled": False,
        "port": 8001,
        "model_path": "/models/Qwen3-VL-8B-Instruct",
        "prompts": {
            "simple": "OCR this text.",
            "detailed": "Extract all text from this image.",
            "math": "OCR mathematical content from this image."
        }
    },
    "LightOnOCR-1B-1025": {
        "enabled": True,
        "port": 8000,
        "model_path": "/models/LightOnOCR-1B-1025",
        "prompts": {
            "simple": "OCR",
            "detailed": "Extract text",
            "math": "OCR math"
        }
    },
    "olmOCR-2-7B-1025-FP8": {
        "enabled": True,
        "port": 8000,
        "model_path": "/models/olmOCR-2-7B-1025-FP8",
        "prompts": {
            "simple": "OCR",
            "detailed": "Extract text",
            "math": "OCR math"
        }
    }
}

# –¢–∏–ø –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
PROMPT_TYPE = "simple"

print("‚úÖ –Ø—á–µ–π–∫–∞ 3: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
print(f"   –ê–∫—Ç–∏–≤–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π: {sum(1 for m in MODELS_CONFIG.values() if m['enabled'])}")
print(f"   –¢–∏–ø –ø—Ä–æ–º–ø—Ç–∞: {PROMPT_TYPE}")



"""
============================================================================
–Ø–ß–ï–ô–ö–ê 4: –ó–ê–ì–†–£–ó–ö–ê –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–ô
============================================================================
"""

def load_images_from_directory(images_dir: Path) -> Tuple[List[Path], Dict[str, List[Path]]]:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏, –≥—Ä—É–ø–ø–∏—Ä—É—è –ø–æ –ø–∞–ø–∫–∞–º.
    
    Returns:
        (image_paths, folder_groups)
    """
    image_paths = []
    folder_groups = {}
    
    # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã
    image_extensions = {'.png', '.jpg', '.jpeg', '.webp', '.bmp'}
    
    # –†–µ–∫—É—Ä—Å–∏–≤–Ω—ã–π –æ–±—Ö–æ–¥
    for folder in sorted(images_dir.iterdir()):
        if not folder.is_dir():
            continue
        
        folder_name = folder.name
        folder_images = []
        
        for img_file in sorted(folder.iterdir()):
            if img_file.suffix.lower() in image_extensions:
                image_paths.append(img_file)
                folder_images.append(img_file)
        
        if folder_images:
            folder_groups[folder_name] = folder_images
            print(f"  üìÇ {folder_name}: {len(folder_images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
    
    return image_paths, folder_groups


# –ó–∞–≥—Ä—É–∑–∫–∞
print("üîç –ü–æ–∏—Å–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π...")
IMAGE_PATHS, FOLDER_GROUPS = load_images_from_directory(IMAGES_DIR)

print(f"\n‚úÖ –Ø—á–µ–π–∫–∞ 4: –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
print(f"   –í—Å–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(IMAGE_PATHS)}")
print(f"   –ü–∞–ø–æ–∫: {len(FOLDER_GROUPS)}")



"""
============================================================================
–Ø–ß–ï–ô–ö–ê 5: –§–£–ù–ö–¶–ò–ò –°–û–•–†–ê–ù–ï–ù–ò–Ø –†–ï–ó–£–õ–¨–¢–ê–¢–û–í
============================================================================
"""

def save_results_to_files(
    results: List[OCRResult],
    output_dir: Path,
    model_name: str
) -> Dict[str, Path]:
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö.
    
    Thread-safety: ‚úÖ –í—ã–∑—ã–≤–∞–µ—Ç—Å—è –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –≤—Å–µ—Ö –ø–æ—Ç–æ–∫–æ–≤
    """
    saved_files = {}
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ –ø–∞–ø–∫–∞–º
    folder_groups = {}
    for result in results:
        if result.folder_name not in folder_groups:
            folder_groups[result.folder_name] = []
        folder_groups[result.folder_name].append(result)
    
    # 1. MARKDOWN —Ñ–∞–π–ª—ã –ø–æ –ø–∞–ø–∫–∞–º
    for folder_name, folder_results in folder_groups.items():
        md_path = output_dir / f"{model_name}_{folder_name}_{timestamp}.md"
        
        with open(md_path, 'w', encoding='utf-8') as f:
            f.write(f"# OCR –†–µ–∑—É–ª—å—Ç–∞—Ç—ã: {folder_name}\n\n")
            f.write(f"–ú–æ–¥–µ–ª—å: {model_name}\n")
            f.write(f"–î–∞—Ç–∞: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"{'='*80}\n\n")
            
            for result in sorted(folder_results, key=lambda r: r.page_number):
                f.write(f"\n{'‚îÄ'*80}\n")
                f.write(f"–°–¢–†–ê–ù–ò–¶–ê {result.page_number}\n")
                f.write(f"–§–∞–π–ª: {result.filename}\n")
                f.write(f"–í—Ä–µ–º—è: {result.processing_time:.2f}—Å\n")
                f.write(f"–°–∏–º–≤–æ–ª–æ–≤: {result.text_length}\n")
                
                if result.error:
                    f.write(f"‚ùå –û–®–ò–ë–ö–ê: {result.error}\n")
                else:
                    f.write(f"{'‚îÄ'*80}\n\n")
                    f.write(result.text)
                    f.write(f"\n\n")
        
        saved_files[f"md_{folder_name}"] = md_path
    
    # 2. JSON —Ñ–∞–π–ª (–ø–æ–ª–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã)
    json_path = output_dir / f"{model_name}_results_{timestamp}.json"
    json_data = [asdict(r) for r in results]
    
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(json_data, f, ensure_ascii=False, indent=2)
    
    saved_files['json'] = json_path
    
    # 3. CSV —Ñ–∞–π–ª (—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞)
    csv_path = output_dir / f"{model_name}_stats_{timestamp}.csv"
    
    with open(csv_path, 'w', encoding='utf-8', newline='') as f:
        fieldnames = [
            'folder_name', 'filename', 'page_number', 'text_length',
            'tokens', 'processing_time', 'error'
        ]
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        
        for result in results:
            writer.writerow({
                'folder_name': result.folder_name,
                'filename': result.filename,
                'page_number': result.page_number,
                'text_length': result.text_length,
                'tokens': result.tokens,
                'processing_time': result.processing_time,
                'error': result.error or ''
            })
    
    saved_files['csv'] = csv_path
    
    return saved_files


print("‚úÖ –Ø—á–µ–π–∫–∞ 5: –§—É–Ω–∫—Ü–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã")



"""
============================================================================
–Ø–ß–ï–ô–ö–ê 6: –§–£–ù–ö–¶–ò–ò –°–¢–ê–¢–ò–°–¢–ò–ö–ò
============================================================================
"""

def calculate_model_stats(results: List[OCRResult]) -> ModelStats:
    """
    –í—ã—á–∏—Å–ª—è–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –¥–ª—è –º–æ–¥–µ–ª–∏.
    
    Thread-safety: ‚úÖ –í—ã–∑—ã–≤–∞–µ—Ç—Å—è –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –≤—Å–µ—Ö –ø–æ—Ç–æ–∫–æ–≤
    """
    if not results:
        return ModelStats(
            model_name="Unknown",
            total_images=0,
            folders_processed=0,
            total_time=0,
            avg_time_per_image=0,
            total_tokens=0,
            total_chars=0,
            success_rate=0,
            errors=0,
            throughput=0
        )
    
    model_name = results[0].model_name
    total_time = sum(r.processing_time for r in results)
    total_tokens = sum(r.tokens for r in results)
    total_chars = sum(r.text_length for r in results)
    
    # –£—Å–ø–µ—à–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (–±–µ–∑ –æ—à–∏–±–æ–∫)
    success_count = sum(1 for r in results if not r.error)
    success_rate = (success_count / len(results)) * 100 if results else 0
    
    # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—à–∏–±–æ–∫
    errors = sum(1 for r in results if r.error)
    
    # –ü–∞–ø–∫–∏
    folders = set(r.folder_name for r in results)
    
    return ModelStats(
        model_name=model_name,
        total_images=len(results),
        folders_processed=len(folders),
        total_time=total_time,
        avg_time_per_image=total_time / len(results) if results else 0,
        total_tokens=total_tokens,
        total_chars=total_chars,
        success_rate=success_rate,
        errors=errors,
        throughput=len(results) / total_time if total_time > 0 else 0
    )


def calculate_folder_stats(results: List[OCRResult], folder_name: str) -> Optional[FolderStats]:
    """
    –í—ã—á–∏—Å–ª—è–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –¥–ª—è –æ–¥–Ω–æ–π –ø–∞–ø–∫–∏.
    
    Thread-safety: ‚úÖ –í—ã–∑—ã–≤–∞–µ—Ç—Å—è –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –ø–æ—Ç–æ–∫–æ–≤
    """
    folder_results = [r for r in results if r.folder_name == folder_name]
    
    if not folder_results:
        return None
    
    total_time = sum(r.processing_time for r in folder_results)
    total_chars = sum(r.text_length for r in folder_results)
    
    # –£—Å–ø–µ—à–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    success_count = sum(1 for r in folder_results if not r.error)
    success_rate = (success_count / len(folder_results)) * 100 if folder_results else 0
    
    return FolderStats(
        folder_name=folder_name,
        total_images=len(folder_results),
        total_time=total_time,
        avg_time_per_image=total_time / len(folder_results) if folder_results else 0,
        total_chars=total_chars,
        avg_chars_per_image=total_chars / len(folder_results) if folder_results else 0,
        success_rate=success_rate
    )


print("‚úÖ –Ø—á–µ–π–∫–∞ 6: –§—É–Ω–∫—Ü–∏–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã")



"""
============================================================================
–Ø–ß–ï–ô–ö–ê 7: –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò
============================================================================
"""

def check_model_availability(port: int, timeout: int = 5) -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å vLLM —Å–µ—Ä–≤–µ—Ä–∞.
    
    Thread-safety: ‚úÖ –ë–µ–∑–æ–ø–∞—Å–Ω–∞ (—Ç–æ–ª—å–∫–æ —á—Ç–µ–Ω–∏–µ)
    """
    try:
        response = requests.get(
            f"http://localhost:{port}/v1/models",
            timeout=timeout
        )
        return response.status_code == 200
    except Exception as e:
        logger.error(f"–ü–æ—Ä—Ç {port} –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
        return False


def image_to_base64(image: Image.Image, max_size: int = 1920) -> str:
    """
    –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç PIL Image –≤ base64 —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º resize.
    
    Thread-safety: ‚úÖ –ë–µ–∑–æ–ø–∞—Å–Ω–∞ (—Ä–∞–±–æ—Ç–∞–µ—Ç —Å –∫–æ–ø–∏–µ–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è)
    """
    # Resize –µ—Å–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–µ
    if max(image.size) > max_size:
        ratio = max_size / max(image.size)
        new_size = (int(image.width * ratio), int(image.height * ratio))
        image = image.resize(new_size, Image.Resampling.LANCZOS)
    
    buffered = BytesIO()
    
    # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Ñ–æ—Ä–º–∞—Ç–∞
    if image.mode in ('RGBA', 'LA', 'P'):
        image.save(buffered, format="PNG", optimize=True)
    else:
        if image.mode != 'RGB':
            image = image.convert('RGB')
        image.save(buffered, format="JPEG", quality=95, optimize=True)
    
    return base64.b64encode(buffered.getvalue()).decode()


print("‚úÖ –Ø—á–µ–π–∫–∞ 7: –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã")



"""
============================================================================
–Ø–ß–ï–ô–ö–ê 8: –ü–ê–†–ê–õ–õ–ï–õ–¨–ù–ê–Ø –û–ë–†–ê–ë–û–¢–ö–ê
============================================================================
"""

def ocr_single_image(
    img_path: Path,
    folder_name: str,
    model_name: str,
    model_config: Dict[str, Any],
    prompt_type: str,
    page_num: int
) -> OCRResult:
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–¥–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —á–µ—Ä–µ–∑ OCR API.
    
    WORKER –§–£–ù–ö–¶–ò–Ø –¥–ª—è ThreadPoolExecutor
    
    Thread-safety: ‚úÖ –ü–æ–ª–Ω–æ—Å—Ç—å—é –±–µ–∑–æ–ø–∞—Å–Ω–∞
    """
    start_time = time.time()
    
    try:
        # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        image = Image.open(img_path)
        
        # 2. –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ base64
        image_base64 = image_to_base64(image, max_size=1920)
        
        # 3. –°–æ–∑–¥–∞–Ω–∏–µ API –∫–ª–∏–µ–Ω—Ç–∞
        client = OpenAI(
            base_url=f"http://localhost:{model_config['port']}/v1",
            api_key="EMPTY",
            timeout=180
        )
        
        # 4. –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞
        # ‚ö° –°–ü–ï–¶–ò–ê–õ–¨–ù–ê–Ø –õ–û–ì–ò–ö–ê –î–õ–Ø LightOnOCR
        if model_name == "LightOnOCR-1B-1025":
            # LightOnOCR: –¢–û–õ–¨–ö–û –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, –ë–ï–ó —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞
            messages = [
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/png;base64,{image_base64}"
                            }
                        }
                    ]
                }
            ]
            
            # 5. –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è LightOnOCR
            response = client.chat.completions.create(
                model=model_config["model_path"],
                messages=messages,
                temperature=0.2,
                top_p=0.9,
                max_tokens=model_config.get("safe_max_tokens", 4000)
            )
            
        else:
            # –î—Ä—É–≥–∏–µ –º–æ–¥–µ–ª–∏: —Å —Ç–µ–∫—Å—Ç–æ–≤—ã–º –ø—Ä–æ–º–ø—Ç–æ–º
            messages = [
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": model_config["prompts"][prompt_type]
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/png;base64,{image_base64}"
                            }
                        }
                    ]
                }
            ]
            
            # 5. –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –¥—Ä—É–≥–∏—Ö –º–æ–¥–µ–ª–µ–π
            response = client.chat.completions.create(
                model=model_config["model_path"],
                messages=messages,
                temperature=0.0,
                max_tokens=model_config.get("safe_max_tokens", 4000)
            )
        
        
        # 6. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        text = response.choices[0].message.content
        tokens = response.usage.total_tokens if response.usage else 0
        
        processing_time = time.time() - start_time
        
        # 7. –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        return OCRResult(
            model_name=model_name,
            folder_name=folder_name,
            filename=img_path.name,
            page_number=page_num,
            text=text,
            tokens=tokens,
            processing_time=processing_time,
            text_length=len(text),
            timestamp=datetime.now().isoformat(),
            error=None
        )
        
    except Exception as e:
        processing_time = time.time() - start_time
        logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {img_path.name}: {e}")
        
        return OCRResult(
            model_name=model_name,
            folder_name=folder_name,
            filename=img_path.name,
            page_number=page_num,
            text="",
            tokens=0,
            processing_time=processing_time,
            text_length=0,
            timestamp=datetime.now().isoformat(),
            error=str(e)
        )


def ocr_single_image_wrapper(args: Tuple) -> OCRResult:
    """Wrapper –¥–ª—è —Ä–∞—Å–ø–∞–∫–æ–≤–∫–∏ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤"""
    return ocr_single_image(*args)


def test_model_parallel(
    model_name: str,
    max_workers: int = 4
) -> Optional[List[OCRResult]]:
    """
    ‚ö°‚ö°‚ö° –ü–ê–†–ê–õ–õ–ï–õ–¨–ù–û–ï –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ú–û–î–ï–õ–ò ‚ö°‚ö°‚ö°
    """
    
    # –í–∞–ª–∏–¥–∞—Ü–∏—è
    if 'IMAGE_PATHS' not in globals() or not IMAGE_PATHS:
        print(f"‚ùå –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã! –ó–∞–ø—É—Å—Ç–∏—Ç–µ –Ø—á–µ–π–∫—É 4")
        return None
    
    if model_name not in MODELS_CONFIG:
        print(f"‚ùå –ú–æ–¥–µ–ª—å {model_name} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ MODELS_CONFIG")
        return None
    
    model_config = MODELS_CONFIG[model_name]
    
    if not model_config["enabled"]:
        print(f"‚è∏Ô∏è  {model_name} –æ—Ç–∫–ª—é—á–µ–Ω–∞ –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
        return None
    
    if not check_model_availability(model_config["port"]):
        print(f"‚ùå {model_name} –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ –Ω–∞ –ø–æ—Ä—Ç—É {model_config['port']}")
        return None
    
    # –ó–∞–≥–æ–ª–æ–≤–æ–∫
    print(f"{'='*70}")
    print(f"üöÄ –ü–ê–†–ê–õ–õ–ï–õ–¨–ù–û–ï –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï: {model_name}")
    print(f"{'='*70}")
    print(f"‚úÖ –ú–æ–¥–µ–ª—å –¥–æ—Å—Ç—É–ø–Ω–∞ –Ω–∞ –ø–æ—Ä—Ç—É {model_config['port']}")
    print(f"üìù –ü—Ä–æ–º–ø—Ç: {model_config['prompts'][PROMPT_TYPE]}")
    print(f"üìä –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(IMAGE_PATHS)}")
    print(f"‚ö° –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –ø–æ—Ç–æ–∫–æ–≤: {max_workers}")
    print(f"{'='*70}\n")
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∑–∞–¥–∞—á
    tasks = []
    for folder_name, folder_paths in FOLDER_GROUPS.items():
        for page_num, img_path in enumerate(folder_paths, 1):
            task = (
                img_path,
                folder_name,
                model_name,
                model_config,
                PROMPT_TYPE,
                page_num
            )
            tasks.append(task)
    
    print(f"üì¶ –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ –∑–∞–¥–∞—á: {len(tasks)}")
    print(f"   Worker –±—É–¥–µ—Ç –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å: {len(tasks) / max_workers:.1f} –∑–∞–¥–∞—á –≤ —Å—Ä–µ–¥–Ω–µ–º")
    print(f"\n{'‚îÄ'*70}\n")
    
    # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
    start_time = time.time()
    results = []
    
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_task = {
            executor.submit(ocr_single_image_wrapper, task): task
            for task in tasks
        }
        
        with tqdm(total=len(tasks), desc=f"‚ö° {model_name}", unit="img") as pbar:
            for future in as_completed(future_to_task):
                task = future_to_task[future]
                
                try:
                    result = future.result()
                    results.append(result)
                    
                    status = "‚úÖ" if not result.error else "‚ùå"
                    pbar.set_postfix({
                        '—Ñ–∞–π–ª': result.filename[:20],
                        '–≤—Ä–µ–º—è': f"{result.processing_time:.1f}—Å",
                        '—Å–∏–º–≤–æ–ª–æ–≤': result.text_length,
                        '—Å—Ç–∞—Ç—É—Å': status
                    })
                    
                except Exception as exc:
                    logger.error(f"Worker exception: {exc}")
                    img_path = task[0]
                    results.append(OCRResult(
                        model_name=model_name,
                        folder_name=task[1],
                        filename=img_path.name,
                        page_number=task[5],
                        text="",
                        tokens=0,
                        processing_time=0,
                        text_length=0,
                        timestamp=datetime.now().isoformat(),
                        error=f"Worker exception: {exc}"
                    ))
                
                pbar.update(1)
    
    total_time = time.time() - start_time
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    ALL_RESULTS[model_name] = results
    
    print(f"\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")
    saved_files = save_results_to_files(results, OUTPUT_DIR, model_name)
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    stats = calculate_model_stats(results)
    
    # –í—ã–≤–æ–¥ –æ—Ç—á—ë—Ç–∞
    print(f"\n{'='*70}")
    print(f"üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê {model_name}")
    print(f"{'='*70}")
    print(f"  –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π:      {stats.total_images}")
    print(f"  –ü–∞–ø–æ–∫:            {stats.folders_processed}")
    print(f"  –û–±—â–µ–µ –≤—Ä–µ–º—è:      {stats.total_time:.1f}—Å ({stats.total_time/60:.1f} –º–∏–Ω)")
    print(f"  Throughput:       {stats.throughput:.2f} –∏–∑–æ–±—Ä/—Å")
    print(f"  –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è:    {stats.avg_time_per_image:.2f}—Å/–∏–∑–æ–±—Ä")
    
    # –û—Ü–µ–Ω–∫–∞ —É—Å–∫–æ—Ä–µ–Ω–∏—è
    theoretical_speedup = max_workers / 1.5
    actual_speedup = (stats.avg_time_per_image * len(results)) / stats.total_time
    print(f"  –£—Å–∫–æ—Ä–µ–Ω–∏–µ:        {actual_speedup:.1f}x (—Ç–µ–æ—Ä. {theoretical_speedup:.1f}x) ‚ö°")
    
    print(f"  –¢–æ–∫–µ–Ω–æ–≤:          {stats.total_tokens:,}")
    print(f"  –°–∏–º–≤–æ–ª–æ–≤:         {stats.total_chars:,}")
    print(f"  –£—Å–ø–µ—à–Ω–æ:          {stats.success_rate:.1f}%")
    
    if stats.errors > 0:
        print(f"  ‚ö†Ô∏è  –û—à–∏–±–æ–∫:       {stats.errors}")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø–∞–ø–∫–∞–º
    if len(FOLDER_GROUPS) > 1:
        print(f"\nüìÇ –ü–æ –ø–∞–ø–∫–∞–º:")
        for folder_name in FOLDER_GROUPS.keys():
            folder_stats = calculate_folder_stats(results, folder_name)
            if folder_stats:
                print(f"  {folder_name}: {folder_stats.total_images} –∏–∑–æ–±—Ä, "
                      f"{folder_stats.avg_time_per_image:.2f}—Å/–∏–∑–æ–±—Ä, "
                      f"{folder_stats.avg_chars_per_image:.0f} —Å–∏–º–≤/–∏–∑–æ–±—Ä")
    
    # –°–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
    print(f"\nüíæ –§–∞–π–ª—ã: {len(saved_files)}")
    for key, filepath in saved_files.items():
        print(f"  üìÑ {filepath.name}")
    
    print(f"\n{'='*70}")
    print(f"‚úÖ –ó–ê–í–ï–†–®–ï–ù–û!")
    print(f"{'='*70}\n")
    
    return results


def test_model(model_name: str, max_workers: int = 4):
    """–ê–ª–∏–∞—Å —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –≤—ã–±–æ—Ä–æ–º workers"""
    if 'IMAGE_PATHS' in globals():
        num_images = len(IMAGE_PATHS)
        if num_images <= 4:
            max_workers = 2
        elif num_images <= 12:
            max_workers = 4
        else:
            max_workers = 8
    
    return test_model_parallel(model_name, max_workers=max_workers)


print("‚úÖ –Ø—á–µ–π–∫–∞ 8: –§—É–Ω–∫—Ü–∏–∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã")
print("   - ocr_single_image() - worker —Ñ—É–Ω–∫—Ü–∏—è")
print("   - test_model_parallel() - –≥–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è")
print("   - test_model() - –∞–ª–∏–∞—Å —Å –∞–≤—Ç–æ-–≤—ã–±–æ—Ä–æ–º workers")






test_model_parallel("HunyuanOCR", max_workers=1)





test_model_parallel("HunyuanOCR", max_workers=1)


test_model_parallel("HunyuanOCR", max_workers=1)


test_model_parallel("LightOnOCR-1B-1025", max_workers=1)


from openai import OpenAI
from PIL import Image
import base64
from io import BytesIO

def image_to_base64(image, max_size=1920):
    if max(image.size) > max_size:
        image.thumbnail((max_size, max_size), Image.Resampling.LANCZOS)
    buffer = BytesIO()
    image.save(buffer, format="PNG")
    return base64.b64encode(buffer.getvalue()).decode()

# 1. –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
test_image_path = list(IMAGE_PATHS)[0]
print(f"üì∑ –¢–µ—Å—Ç–æ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {test_image_path.name}")

image = Image.open(test_image_path)
image_base64 = image_to_base64(image)

print(f"‚úÖ Base64 –¥–ª–∏–Ω–∞: {len(image_base64):,} —Å–∏–º–≤–æ–ª–æ–≤")
print(f"‚úÖ –†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {image.size}")

# 2. API –∫–ª–∏–µ–Ω—Ç
client = OpenAI(
    base_url="http://localhost:8000/v1",
    api_key="EMPTY",
    timeout=180
)

# 3. –¢–ï–°–¢ 1: –ë–µ–∑ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞ (–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Å–ø–æ—Å–æ–±)
print("\n" + "="*70)
print("–¢–ï–°–¢ 1: –ë–ï–ó —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞ (–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –¥–ª—è LightOnOCR)")
print("="*70)

messages_correct = [
    {
        "role": "user",
        "content": [
            {
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/png;base64,{image_base64}"
                }
            }
        ]
    }
]

try:
    response = client.chat.completions.create(
        model="/models/LightOnOCR-1B-1025",
        messages=messages_correct,
        temperature=0.2,
        top_p=0.9,
        max_tokens=4000
    )
    
    text = response.choices[0].message.content
    print(f"\n‚úÖ –†–ï–ó–£–õ–¨–¢–ê–¢:")
    print(f"   –°–∏–º–≤–æ–ª–æ–≤: {len(text)}")
    print(f"   –¢–æ–∫–µ–Ω–æ–≤: {response.usage.total_tokens if response.usage else 'N/A'}")
    print(f"\nüìù –¢–ï–ö–°–¢ (–ø–µ—Ä–≤—ã–µ 500 —Å–∏–º–≤–æ–ª–æ–≤):")
    print(text[:500])
    
except Exception as e:
    print(f"‚ùå –û–®–ò–ë–ö–ê: {e}")

# 4. –¢–ï–°–¢ 2: –° —Ç–µ–∫—Å—Ç–æ–≤—ã–º –ø—Ä–æ–º–ø—Ç–æ–º (–Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Å–ø–æ—Å–æ–±)
print("\n" + "="*70)
print("–¢–ï–°–¢ 2: –° —Ç–µ–∫—Å—Ç–æ–≤—ã–º –ø—Ä–æ–º–ø—Ç–æ–º (–º–æ–∂–µ—Ç –Ω–µ —Ä–∞–±–æ—Ç–∞—Ç—å)")
print("="*70)

messages_wrong = [
    {
        "role": "user",
        "content": [
            {
                "type": "text",
                "text": "Transcribe the text in this image."
            },
            {
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/png;base64,{image_base64}"
                }
            }
        ]
    }
]

try:
    response = client.chat.completions.create(
        model="/models/LightOnOCR-1B-1025",
        messages=messages_wrong,
        temperature=0.2,
        top_p=0.9,
        max_tokens=4000
    )
    
    text = response.choices[0].message.content
    print(f"\n‚úÖ –†–ï–ó–£–õ–¨–¢–ê–¢:")
    print(f"   –°–∏–º–≤–æ–ª–æ–≤: {len(text)}")
    print(f"   –¢–æ–∫–µ–Ω–æ–≤: {response.usage.total_tokens if response.usage else 'N/A'}")
    print(f"\nüìù –¢–ï–ö–°–¢ (–ø–µ—Ä–≤—ã–µ 500 —Å–∏–º–≤–æ–ª–æ–≤):")
    print(text[:500])
    
except Exception as e:
    print(f"‚ùå –û–®–ò–ë–ö–ê: {e}")



get_ipython().getoutput("curl http://localhost:8000/v1/models")


# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —á—Ç–æ base64 –Ω–µ –æ–±—Ä–µ–∑–∞–Ω
image = Image.open(test_image_path)
buffer = BytesIO()
image.save(buffer, format="PNG")
image_bytes = buffer.getvalue()

print(f"–û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {len(image_bytes):,} –±–∞–π—Ç")
print(f"Base64 —Ä–∞–∑–º–µ—Ä: {len(image_base64):,} —Å–∏–º–≤–æ–ª–æ–≤")
print(f"–û–∂–∏–¥–∞–µ–º—ã–π Base64: {len(image_bytes) * 4 / 3:.0f} —Å–∏–º–≤–æ–ª–æ–≤")



# –ó–∞–ø—É—Å—Ç–∏—Ç–µ –≤ –Ω–æ–≤–æ–π —è—á–µ–π–∫–µ Jupyter
from transformers import AutoProcessor
import torch

model_path = PROJECT_ROOT / "models" / "LightOnOCR-1B-1025"

try:
    processor = AutoProcessor.from_pretrained(
        model_path,
        trust_remote_code=True
    )
    print("‚úÖ Processor –∑–∞–≥—Ä—É–∂–µ–Ω —É—Å–ø–µ—à–Ω–æ")
    print(f"üìä –¢–∏–ø: {type(processor)}")
    print(f"üìä –ê—Ç—Ä–∏–±—É—Ç—ã: {dir(processor)}")
    
    # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å image_processor
    if hasattr(processor, 'image_processor'):
        print(f"‚úÖ Image processor –Ω–∞–π–¥–µ–Ω: {type(processor.image_processor)}")
    else:
        print(f"‚ùå Image processor –û–¢–°–£–¢–°–¢–í–£–ï–¢!")
        
except Exception as e:
    print(f"‚ùå –û–®–ò–ë–ö–ê –∑–∞–≥—Ä—É–∑–∫–∏ processor: {e}")



# –ü—Ä–æ–≤–µ—Ä–∫–∞ —á—Ç–æ –º–æ–¥–µ–ª—å –≤–æ–æ–±—â–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –ª–æ–∫–∞–ª—å–Ω–æ
from transformers import AutoModelForVision2Seq, AutoProcessor
from PIL import Image
import torch

model_path = PROJECT_ROOT / "models" / "LightOnOCR-1B-1025"

print("üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –Ω–∞–ø—Ä—è–º—É—é (–±–µ–∑ vLLM)...")

try:
    # –ó–∞–≥—Ä—É–∑–∫–∞
    processor = AutoProcessor.from_pretrained(
        model_path,
        trust_remote_code=True
    )
    
    model = AutoModelForVision2Seq.from_pretrained(
        model_path,
        trust_remote_code=True,
        torch_dtype=torch.bfloat16,
        device_map="cuda:0"  # –∏–ª–∏ "cpu" –µ—Å–ª–∏ –Ω–µ—Ç GPU
    )
    
    print("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
    
    # –¢–µ—Å—Ç–æ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    test_image = list(IMAGE_PATHS)[0]
    image = Image.open(test_image)
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞
    inputs = processor(images=image, return_tensors="pt").to(model.device)
    
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è
    with torch.no_grad():
        outputs = model.generate(
            **inputs,
            max_new_tokens=512,
            temperature=0.2,
            top_p=0.9
        )
    
    # –î–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ
    text = processor.batch_decode(outputs, skip_special_tokens=True)[0]
    
    print(f"\nüìù –†–ï–ó–£–õ–¨–¢–ê–¢:")
    print(f"   –°–∏–º–≤–æ–ª–æ–≤: {len(text)}")
    print(f"\n{text[:500]}")
    
except Exception as e:
    print(f"‚ùå –û–®–ò–ë–ö–ê: {e}")
    import traceback
    traceback.print_exc()



"""
–ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ LightOnOCR —Å –∫–∞—Å—Ç–æ–º–Ω—ã–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–æ–º
"""

from transformers import AutoModel, AutoTokenizer, AutoImageProcessor
from PIL import Image
import torch
import sys

model_path = PROJECT_ROOT / "models" / "LightOnOCR-1B-1025"

print("="*70)
print("üîß –ü–†–ê–í–ò–õ–¨–ù–ê–Ø –ó–ê–ì–†–£–ó–ö–ê LightOnOCR")
print("="*70)

try:
    # –®–∞–≥ 1: –ó–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å —Å trust_remote_code
    print(f"\nüì¶ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏...")
    model = AutoModel.from_pretrained(
        model_path,
        trust_remote_code=True,
        torch_dtype=torch.bfloat16,
        device_map="auto"
    )
    print(f"‚úÖ –ú–æ–¥–µ–ª—å: {type(model)}")
    
    # –®–∞–≥ 2: –ó–∞–≥—Ä—É–∑–∏—Ç—å —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä
    print(f"\nüì¶ –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞...")
    tokenizer = AutoTokenizer.from_pretrained(
        model_path,
        trust_remote_code=True
    )
    print(f"‚úÖ –¢–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä: {type(tokenizer)}")
    
    # –®–∞–≥ 3: –ó–∞–≥—Ä—É–∑–∏—Ç—å image processor
    print(f"\nüì¶ –ó–∞–≥—Ä—É–∑–∫–∞ image processor...")
    try:
        image_processor = AutoImageProcessor.from_pretrained(
            model_path,
            trust_remote_code=True
        )
        print(f"‚úÖ Image Processor: {type(image_processor)}")
    except Exception as e:
        print(f"‚ö†Ô∏è  AutoImageProcessor –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {e}")
        print(f"   –ü–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑ preprocessor_config.json...")
        
        # –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –≤—Ä—É—á–Ω—É—é
        from transformers import PreTrainedImageProcessor
        import json
        
        with open(f"{model_path}/preprocessor_config.json", "r") as f:
            config = json.load(f)
        
        print(f"   Preprocessor config: {config}")
    
    # –®–∞–≥ 4: –¢–ï–°–¢ - –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    print(f"\nüß™ –¢–ï–°–¢: –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è...")
    
    test_image = list(IMAGE_PATHS)[0]
    image = Image.open(test_image)
    print(f"   –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {test_image.name} ({image.size})")
    
    # –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å —Ä–∞–∑–Ω—ã–µ —Å–ø–æ—Å–æ–±—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏
    print(f"\n   –°–ø–æ—Å–æ–± 1: –ß–µ—Ä–µ–∑ –º–æ–¥–µ–ª—å –Ω–∞–ø—Ä—è–º—É—é...")
    if hasattr(model, 'forward'):
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å inputs
        # LightOnOCR –æ–∂–∏–¥–∞–µ—Ç pixel_values
        from torchvision import transforms
        
        # –ü—Ä–æ—Å—Ç–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        transform = transforms.Compose([
            transforms.Resize((512, 512)),
            transforms.ToTensor(),
            transforms.Normalize(
                mean=[0.48145466, 0.4578275, 0.40821073],
                std=[0.26862954, 0.26130258, 0.27577711]
            )
        ])
        
        pixel_values = transform(image).unsqueeze(0).to(model.device)
        print(f"   ‚úÖ pixel_values shape: {pixel_values.shape}")
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è
        with torch.no_grad():
            outputs = model.generate(
                pixel_values=pixel_values,
                max_new_tokens=512,
                temperature=0.2,
                top_p=0.9,
                do_sample=True
            )
        
        # –î–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ
        text = tokenizer.decode(outputs[0], skip_special_tokens=True)
        
        print(f"\nüìù –†–ï–ó–£–õ–¨–¢–ê–¢:")
        print(f"   –°–∏–º–≤–æ–ª–æ–≤: {len(text)}")
        print(f"\n{text[:500]}")
        
        if len(text) > 50:
            print(f"\nüéâ –£–°–ü–ï–•! –ú–æ–¥–µ–ª—å —Ä–∞—Å–ø–æ–∑–Ω–∞–ª–∞ —Ç–µ–∫—Å—Ç!")
        else:
            print(f"\n‚ö†Ô∏è  –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π")
    
except Exception as e:
    print(f"\n‚ùå –û–®–ò–ë–ö–ê: {e}")
    import traceback
    traceback.print_exc()

print(f"\n{'='*70}")



test_model_parallel("olmOCR-2-7B-1025-FP8", max_workers=1)
